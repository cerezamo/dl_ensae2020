{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copie de Untitled9.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOpcr9uHJnAI6IFrOsKrngh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cerezamo/dl_ensae2020/blob/master/TEST_USPS_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3WozZiVqzTe",
        "colab_type": "text"
      },
      "source": [
        "# Deep Learning - CycleGAN - ENSAE 2020 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSTMrsRArdZM",
        "colab_type": "text"
      },
      "source": [
        "## From MNIST to USPS "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l11pGx3YrZ33",
        "colab_type": "text"
      },
      "source": [
        "### Import packages "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fo2xoAWXbQNk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from torch import optim\n",
        "import torchvision.utils as utils\n",
        "import torch.nn.functional as F\n",
        "import torch.utils as tutils\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Nzv4stxsPBE",
        "colab_type": "text"
      },
      "source": [
        "This code is adapted from [yunjey](https://github.com/yunjey/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VkJhQlnyd1pf",
        "colab_type": "text"
      },
      "source": [
        "### Download and construct loaders for USPS and Mnist"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-iq6gXIr53M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "batch_size = 64\n",
        "image_size = 32\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMntxDhzaCsX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_loader_mnist(image_size,batch_size):\n",
        "  transform = transforms.Compose([\n",
        "                    transforms.Resize(image_size),\n",
        "                    transforms.ToTensor(),\n",
        "                    transforms.Normalize((0.5,), (0.5,))\n",
        "                    ])\n",
        "  \n",
        "  mnist_train = datasets.MNIST(root='content/',download=True, transform = transform,train=True)\n",
        "  mnist_test = datasets.MNIST(root='content/',download=True, transform = transform,train=False)\n",
        "\n",
        "  train_loader = torch.utils.data.DataLoader(dataset=mnist_train,\n",
        "                                             batch_size=batch_size,\n",
        "                                             shuffle=True)\n",
        "  \n",
        "  test_loader = torch.utils.data.DataLoader(dataset=mnist_test,\n",
        "                                             batch_size=batch_size,\n",
        "                                             shuffle=False)\n",
        "  \n",
        "  return train_loader, test_loader "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBjkiheLeG5B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_loader_usps(image_size,batch_size):\n",
        "  transform = transforms.Compose([\n",
        "                    transforms.Resize(image_size),\n",
        "                    transforms.ToTensor(),\n",
        "                    transforms.Normalize((0.5,), (0.5,))\n",
        "                    ])\n",
        "  \n",
        "  usps_train = datasets.USPS(root='content/',download=True, transform = transform,train=True)\n",
        "  usps_test = datasets.USPS(root='content/',download=True, transform = transform,train=False)\n",
        "\n",
        "  train_loader = torch.utils.data.DataLoader(dataset=usps_train,\n",
        "                                             batch_size=batch_size,\n",
        "                                             shuffle=True)\n",
        "  \n",
        "  test_loader = torch.utils.data.DataLoader(dataset=usps_test,\n",
        "                                             batch_size=batch_size,\n",
        "                                             shuffle=False)\n",
        "  \n",
        "  return train_loader, test_loader "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NS9TtewDd0-7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "M_train_loader, M_test_loader =get_loader_mnist(32,64)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWVC0H3Oaijj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "U_train_loader, U_test_loader =get_loader_usps(32,64)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dc6q_rHdlhUd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "examples_mnist = enumerate(M_train_loader)\n",
        "batch_idx, (example_data_mnist, example_targets_mnist) = next(examples_mnist)\n",
        "\n",
        "examples_usps = enumerate(U_train_loader)\n",
        "batch_idx, (example_data_usps, example_targets_usps) = next(examples_usps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUMuqDB5lo9z",
        "colab_type": "code",
        "outputId": "b47a81eb-c49c-421b-fdc7-5f1059c3a4c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "example_data_usps.shape, example_data_mnist.shape # 64 per batch, size 32x32  # 64 per batch, size 32x32 "
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([64, 1, 32, 32]), torch.Size([64, 1, 32, 32]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n46JB-OHl4TU",
        "colab_type": "code",
        "outputId": "e150d813-032e-47ae-82a0-add816f474d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig = plt.figure()\n",
        "for i in range(6):\n",
        "  plt.subplot(1,6,i+1)\n",
        "  plt.tight_layout()\n",
        "  plt.imshow(example_data_mnist[i][0], cmap='gray', interpolation='none')\n",
        "  plt.title(\"Labels: {}\".format(example_targets_mnist[i]))\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "fig"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 6 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 6 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qn0disVBmcT-",
        "colab_type": "code",
        "outputId": "d2dcdfd7-3586-49f5-83bc-1f0ecbc74ee5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 149
        }
      },
      "source": [
        "\n",
        "fig = plt.figure()\n",
        "for i in range(6):\n",
        "  plt.subplot(1,6,i+1)\n",
        "  plt.tight_layout()\n",
        "  plt.imshow(example_data_usps[i][0], cmap='gray', interpolation='none')\n",
        "  plt.title(\"Label: {}\".format(example_targets_usps[i]))\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "fig"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 6 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 6 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgPmv5meb_cP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1d6c19a7-b6f5-4500-d192-ccdd686b8cdb"
      },
      "source": [
        "example_data_mnist.size()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 1, 32, 32])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLv4o0Kec7z5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbl9ZuYKnWzS",
        "colab_type": "text"
      },
      "source": [
        "Helper functions (taken from github Cycle gan) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGPVAZ0FtUvx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6O_Sr4Eem6cq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def deconv(c_in, c_out, k_size, stride=2, pad=1, batch_norm=True):\n",
        "    \"\"\"Custom deconvolutional layer for simplicity.\"\"\"\n",
        "    layers = []\n",
        "    layers.append(nn.ConvTranspose2d(c_in, c_out, k_size, stride, pad, bias=False))\n",
        "    if batch_norm:\n",
        "        layers.append(nn.BatchNorm2d(c_out))\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "def conv(c_in, c_out, k_size, stride=2, pad=1, batch_norm=True):\n",
        "    \"\"\"Custom convolutional layer for simplicity.\"\"\"\n",
        "    layers = []\n",
        "    layers.append(nn.Conv2d(c_in, c_out, k_size, stride, pad, bias=False))\n",
        "    if batch_norm:\n",
        "        layers.append(nn.BatchNorm2d(c_out))\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "# Batch norm True False (last layer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lryI_Qeft8cV",
        "colab_type": "text"
      },
      "source": [
        "Construction of the two discriminators "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKaAbO-Nm6fG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class D_MNIST(nn.Module):\n",
        "    \"\"\"Discriminator for mnist.\"\"\"\n",
        "    def __init__(self, conv_dim=64, use_labels=False):\n",
        "        super(D_MNIST, self).__init__()\n",
        "        self.conv1 = conv(1, conv_dim, 4, bn=False)\n",
        "        self.conv2 = conv(conv_dim, conv_dim*2, 4)\n",
        "        self.conv3 = conv(conv_dim*2, conv_dim*4, 4)\n",
        "        n_out = 11 if use_labels else 1\n",
        "        self.fc = conv(conv_dim*4, n_out, 4, 1, 0, False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.leaky_relu(self.conv1(x), 0.05)    # (?, 64, 16, 16)\n",
        "        out = F.leaky_relu(self.conv2(out), 0.05)  # (?, 128, 8, 8)\n",
        "        out = F.leaky_relu(self.conv3(out), 0.05)  # (?, 256, 4, 4)\n",
        "        out = self.fc(out).squeeze()\n",
        "        return out\n",
        "\n",
        "class D_USPS(nn.Module):\n",
        "    \"\"\"Discriminator for svhn.\"\"\"\n",
        "    def __init__(self, conv_dim=64, use_labels=False):\n",
        "        super(D_USPS, self).__init__()\n",
        "        self.conv1 = conv(1, conv_dim, 4, bn=False) #1\n",
        "        self.conv2 = conv(conv_dim, conv_dim*2, 4)\n",
        "        self.conv3 = conv(conv_dim*2, conv_dim*4, 4)\n",
        "        n_out = 11 if use_labels else 1\n",
        "        self.fc = conv(conv_dim*4, n_out, 4, 1, 0, False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.leaky_relu(self.conv1(x), 0.05)    # (?, 64, 16, 16)\n",
        "        out = F.leaky_relu(self.conv2(out), 0.05)  # (?, 128, 8, 8)\n",
        "        out = F.leaky_relu(self.conv3(out), 0.05)  # (?, 256, 4, 4)\n",
        "        out = self.fc(out).squeeze()\n",
        "        return out\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3SROYfqxu-m8",
        "colab_type": "text"
      },
      "source": [
        "Creating the two generators "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtpzQyJM185W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def deconv(c_in, c_out, k_size, stride=2, pad=1, bn=True):\n",
        "    \"\"\"Custom deconvolutional layer \"\"\"\n",
        "    layers = []\n",
        "    layers.append(nn.ConvTranspose2d(c_in, c_out, k_size, stride, pad, bias=False))\n",
        "    if bn:\n",
        "        layers.append(nn.BatchNorm2d(c_out))\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "def conv(c_in, c_out, k_size, stride=2, pad=1, bn=True):\n",
        "    \"\"\"Custom convolutional layer \"\"\"\n",
        "    layers = []\n",
        "    layers.append(nn.Conv2d(c_in, c_out, k_size, stride, pad, bias=False))\n",
        "    if bn:\n",
        "        layers.append(nn.BatchNorm2d(c_out))\n",
        "    return nn.Sequential(*layers)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WU30ammS0vCP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class G_MNIST_USPS(nn.Module):\n",
        "    \"\"\"Generator for transfering from mnist to usps\"\"\"\n",
        "    def __init__(self, conv_dim=64):\n",
        "        super(G_MNIST_USPS, self).__init__()\n",
        "        # encoding blocks\n",
        "        self.conv1 = conv(1, conv_dim, 4)\n",
        "        self.conv2 = conv(conv_dim, conv_dim*2, 4)\n",
        "\n",
        "        # residual blocks\n",
        "        self.conv3 = conv(conv_dim*2, conv_dim*2, 3, 1, 1)\n",
        "        self.conv4 = conv(conv_dim*2, conv_dim*2, 3, 1, 1)\n",
        "\n",
        "        # decoding blocks\n",
        "        self.deconv1 = deconv(conv_dim*2, conv_dim, 4)\n",
        "        self.deconv2 = deconv(conv_dim, 1, 4, bn=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.leaky_relu(self.conv1(x), 0.05)      # (?, 64, 16, 16)\n",
        "        out = F.leaky_relu(self.conv2(out), 0.05)    # (?, 128, 8, 8)\n",
        "\n",
        "        out = F.leaky_relu(self.conv3(out), 0.05)    # ( \" )\n",
        "        out = F.leaky_relu(self.conv4(out), 0.05)    # ( \" )\n",
        "\n",
        "        out = F.leaky_relu(self.deconv1(out), 0.05)  # (?, 64, 16, 16)\n",
        "        out = F.tanh(self.deconv2(out))              # (?, 3, 32, 32)\n",
        "        return out\n",
        "\n",
        "class G_USPS_MNIST(nn.Module):\n",
        "    \"\"\"Generator for transfering from usps to mnist\"\"\"\n",
        "    def __init__(self, conv_dim=64):\n",
        "        super(G_USPS_MNIST, self).__init__()\n",
        "        # encoding blocks\n",
        "        self.conv1 = conv(1, conv_dim, 4)\n",
        "        self.conv2 = conv(conv_dim, conv_dim*2, 4)\n",
        "\n",
        "        # residual blocks\n",
        "        self.conv3 = conv(conv_dim*2, conv_dim*2, 3, 1, 1)\n",
        "        self.conv4 = conv(conv_dim*2, conv_dim*2, 3, 1, 1)\n",
        "\n",
        "        # decoding blocks\n",
        "        self.deconv1 = deconv(conv_dim*2, conv_dim, 4)\n",
        "        self.deconv2 = deconv(conv_dim, 1, 4, bn=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.leaky_relu(self.conv1(x), 0.05)      # (?, 64, 16, 16)\n",
        "        out = F.leaky_relu(self.conv2(out), 0.05)    # (?, 128, 8, 8)\n",
        "\n",
        "        out = F.leaky_relu(self.conv3(out), 0.05)    # ( \" )\n",
        "        out = F.leaky_relu(self.conv4(out), 0.05)    # ( \" )\n",
        "\n",
        "        out = F.leaky_relu(self.deconv1(out), 0.05)  # (?, 64, 16, 16)\n",
        "        out = torch.tanh(self.deconv2(out))              # (?, 1, 32, 32)\n",
        "        return out\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_bxYEIkPrMn",
        "colab_type": "text"
      },
      "source": [
        "Building model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pd6SynLQQTHG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def print_models(G_MtoU, G_UtoM, D_M, D_U):\n",
        "    \"\"\"Prints model information for the generators and discriminators.\n",
        "    \"\"\"\n",
        "    print(\"                 G_MtoU                \")\n",
        "    print(\"---------------------------------------\")\n",
        "    print(G_MtoU)\n",
        "    print(\"---------------------------------------\")\n",
        "\n",
        "    print(\"                 G_UtoM                \")\n",
        "    print(\"---------------------------------------\")\n",
        "    print(G_UtoM)\n",
        "    print(\"---------------------------------------\")\n",
        "\n",
        "    print(\"                  D_M                  \")\n",
        "    print(\"---------------------------------------\")\n",
        "    print(D_M)\n",
        "    print(\"---------------------------------------\")\n",
        "\n",
        "    print(\"                  D_U                  \")\n",
        "    print(\"---------------------------------------\")\n",
        "    print(D_U)\n",
        "    print(\"---------------------------------------\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXd4mpXsPqSF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model():\n",
        "  G_MtoU = G_MNIST_USPS()\n",
        "  G_UtoM = G_USPS_MNIST()\n",
        "  D_M = D_MNIST()\n",
        "  D_U = D_USPS()\n",
        "\n",
        "  print_models(G_MtoU, G_UtoM, D_M, D_U)\n",
        "\n",
        "  if torch.cuda.is_available():\n",
        "      G_MtoU.cuda()\n",
        "      G_UtoM.cuda()\n",
        "      D_M.cuda()\n",
        "      D_U.cuda()\n",
        "      print('Models moved to GPU.')\n",
        "  return G_MtoU,G_UtoM, D_M, D_U"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6qi6MbnPqU2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAe8wnLPPqa8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_samples(iteration, fixed_U, fixed_M, G_UtoM, G_MtoU):\n",
        "    \"\"\"Saves samples from both generators M->U and U->M.\n",
        "    \"\"\"\n",
        "    import os\n",
        "    import imageio\n",
        "    fake_M = G_UtoM(fixed_U)\n",
        "    fake_U = G_MtoU(fixed_M)\n",
        "\n",
        "    M, fake_M = to_data(fixed_M), to_data(fake_M)\n",
        "    U, fake_U = to_data(fixed_U), to_data(fake_U)\n",
        "\n",
        "    merged = merge_images(M, fake_U)\n",
        "    path = os.path.join('/content/', 'sample-{:06d}-X-Y.png'.format(iteration))\n",
        "    imageio.imwrite(path, merged)\n",
        "    print('Saved {}'.format(path))\n",
        "\n",
        "    merged = merge_images(U, fake_M)\n",
        "    path = os.path.join('/content/', 'sample-{:06d}-Y-X.png'.format(iteration))\n",
        "    imageio.imwrite(path, merged)\n",
        "    print('Saved {}'.format(path))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_heIWaZsPqXw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9Yt42NGm6mS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def merge_images(sources, targets, k=10):\n",
        "    \"\"\"Creates a grid consisting of pairs of columns, where the first column in\n",
        "    each pair contains images source images and the second column in each pair\n",
        "    contains images generated by the CycleGAN from the corresponding images in\n",
        "    the first column.\n",
        "    \"\"\"\n",
        "    _, _, h, w = sources.shape\n",
        "    row = int(np.sqrt(64))\n",
        "    merged = np.zeros([3, row*h, row*w*2])\n",
        "    for idx, (s, t) in enumerate(zip(sources, targets)):\n",
        "        i = idx // row\n",
        "        j = idx % row\n",
        "        merged[:, i*h:(i+1)*h, (j*2)*h:(j*2+1)*h] = s\n",
        "        merged[:, i*h:(i+1)*h, (j*2+1)*h:(j*2+2)*h] = t\n",
        "    return merged.transpose(1, 2, 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2wljkASOSQB",
        "colab_type": "text"
      },
      "source": [
        "Helper functions "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTF243GGm6oy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def to_var(x):\n",
        "    \"\"\"Converts numpy to variable.\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        x = x.cuda()\n",
        "    return Variable(x)\n",
        "\n",
        "\n",
        "def to_data(x):\n",
        "    \"\"\"Converts variable to numpy.\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        x = x.cpu()\n",
        "    return x.data.numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVvh5v9LvxXm",
        "colab_type": "text"
      },
      "source": [
        "### Training loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EINZpHSigoPG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6CJ0Ms4dRKdF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def training_loop(M_train_loader, U_train_loader, M_test_loader, U_test_loader, sample_every=1000,  lr=0.0002, train_iters=20000, log_step = 10, batch_size=64, use_cycle_consistency_loss=True):\n",
        "  # Create generators and discriminators\n",
        "  G_MtoU, G_UtoM, D_M, D_U = create_model()\n",
        "\n",
        "  g_params = list(G_MtoU.parameters()) + list(G_UtoM.parameters())  # Get generator parameters\n",
        "  d_params = list(D_M.parameters()) + list(D_U.parameters())  # Get discriminator parameters\n",
        "\n",
        "  # Create optimizers for the generators and discriminators\n",
        "  g_optimizer = optim.Adam(g_params, lr)\n",
        "  d_optimizer = optim.Adam(d_params, lr)\n",
        "\n",
        "  iter_M = iter(M_train_loader)\n",
        "  iter_U = iter(U_train_loader)\n",
        "\n",
        "  test_iter_M = iter(M_test_loader)\n",
        "  test_iter_U = iter(U_test_loader)\n",
        "\n",
        "  # Get some fixed data from domains X and Y for sampling. These are images that are held\n",
        "  # constant throughout training, that allow us to inspect the model's performance.\n",
        "  fixed_M = to_var(test_iter_M.next()[0])\n",
        "  fixed_U = to_var(test_iter_U.next()[0])\n",
        "\n",
        "  iter_per_epoch = min(len(iter_M), len(iter_U))\n",
        "\n",
        "\n",
        "\n",
        "  for iteration in range(1, train_iters+1):\n",
        "\n",
        "      # Reset data_iter for each epoch\n",
        "      if iteration % iter_per_epoch == 0:\n",
        "          iter_M = iter(M_train_loader)\n",
        "          iter_U = iter(U_train_loader)\n",
        "\n",
        "      images_M, labels_M = iter_M.next()\n",
        "      images_M, labels_M = to_var(images_M), to_var(labels_M).long().squeeze()\n",
        "\n",
        "      images_U, labels_U = iter_U.next()\n",
        "      images_U, labels_U = to_var(images_U), to_var(labels_U).long().squeeze()\n",
        "\n",
        "\n",
        "      # ============================================\n",
        "      #            TRAIN THE DISCRIMINATORS\n",
        "      # ============================================\n",
        "\n",
        "      # Train with real images\n",
        "      d_optimizer.zero_grad()\n",
        "\n",
        "      # Compute the discriminator losses on real images\n",
        "      out_M = D_M(images_M) # discriminator mnist true\n",
        "      D_M_loss = torch.mean((out_M-1)**2) \n",
        "      out_U = D_U(images_U)\n",
        "      D_U_loss = torch.mean((out_U-1)**2)\n",
        "\n",
        "      d_real_loss = D_M_loss + D_U_loss\n",
        "      d_real_loss.backward()\n",
        "      d_optimizer.step()\n",
        "\n",
        "      # Train with fake images\n",
        "      d_optimizer.zero_grad()\n",
        "\n",
        "      # Generate fake images that look like domain MNIST based on real images in domain USPS\n",
        "      fake_M = G_UtoM(images_U)\n",
        "\n",
        "      # Compute the loss for D_M\n",
        "      out_M = D_M(fake_M)\n",
        "      D_M_loss = torch.mean((out_M-1)**2) \n",
        "\n",
        "      # 4. Generate fake images that look like domain U based on real images in domain M\n",
        "      fake_U = G_MtoU(images_M)\n",
        "\n",
        "      # 5. Compute the loss for D_U\n",
        "      out_U = D_U(fake_U)\n",
        "      D_U_loss = torch.mean((out_U-1)**2) \n",
        "\n",
        "      d_fake_loss = D_M_loss + D_U_loss\n",
        "      d_fake_loss.backward()\n",
        "      d_optimizer.step()\n",
        "\n",
        "\n",
        "\n",
        "      # =========================================\n",
        "      #            TRAIN THE GENERATORS\n",
        "      # =========================================\n",
        "\n",
        "      ## U--M-->U \n",
        "\n",
        "      g_optimizer.zero_grad()\n",
        "\n",
        "      # 1. Generate fake images that look like domain M based on real images in domain U\n",
        "      fake_M = G_UtoM(images_U)\n",
        "      out = D_M(fake_M)\n",
        "\n",
        "      # 2. Compute the generator loss based on domain M\n",
        "\n",
        "      g_loss = torch.mean((out-1)**2)\n",
        "\n",
        "      if use_cycle_consistency_loss:\n",
        "          reconstructed_U = G_MtoU(fake_M)\n",
        "          # 3. Compute the cycle consistency loss (the reconstruction loss)\n",
        "          cycle_consistency_loss = torch.mean((images_U - reconstructed_U)**2)\n",
        "          g_loss += cycle_consistency_loss\n",
        "\n",
        "      g_loss.backward()\n",
        "      g_optimizer.step()\n",
        "\n",
        "      ## M--U-->M \n",
        "\n",
        "      g_optimizer.zero_grad()\n",
        "\n",
        "      # 1. Generate fake images that look like domain U based on real images in domain M\n",
        "      fake_U = G_MtoU(images_M)\n",
        "      out = D_U(fake_U)\n",
        "\n",
        "      # 2. Compute the generator loss based on domain U\n",
        "      g_loss = torch.mean((out-1)**2)\n",
        "\n",
        "      if use_cycle_consistency_loss:\n",
        "          reconstructed_M = G_UtoM(fake_U)\n",
        "          # 3. Compute the cycle consistency loss (the reconstruction loss)\n",
        "          cycle_consistency_loss = torch.mean((images_M - reconstructed_M)**2)\n",
        "          g_loss += cycle_consistency_loss\n",
        "\n",
        "      g_loss.backward()\n",
        "      g_optimizer.step()\n",
        "\n",
        "\n",
        "      # Print the log info\n",
        "      if iteration % log_step == 0:\n",
        "          print('Iteration [{:5d}/{:5d}] | d_real_loss: {:6.4f} | d_U_loss: {:6.4f} | d_M_loss: {:6.4f} | '\n",
        "                'd_fake_loss: {:6.4f} | g_loss: {:6.4f}'.format(\n",
        "                  iteration, train_iters, d_real_loss.item(), D_U_loss.item(),\n",
        "                  D_M_loss.item(), d_fake_loss.item(), g_loss.item()))\n",
        "\n",
        "\n",
        "      # Save the generated samples\n",
        "      if iteration % sample_every == 0:\n",
        "          save_samples(iteration, fixed_U, fixed_M, G_UtoM, G_MtoU)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpMhowQMRKgq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6f89193b-a784-44e1-f581-a220d13ae933"
      },
      "source": [
        "training_loop(M_train_loader, U_train_loader, M_test_loader, U_test_loader, sample_every=1000,  lr=0.0002, train_iters=20000, log_step = 10,  use_cycle_consistency_loss=True)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                 G_MtoU                \n",
            "---------------------------------------\n",
            "G_MNIST_USPS(\n",
            "  (conv1): Sequential(\n",
            "    (0): Conv2d(1, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (conv2): Sequential(\n",
            "    (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (conv3): Sequential(\n",
            "    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (conv4): Sequential(\n",
            "    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (deconv1): Sequential(\n",
            "    (0): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (deconv2): Sequential(\n",
            "    (0): ConvTranspose2d(64, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "  )\n",
            ")\n",
            "---------------------------------------\n",
            "                 G_UtoM                \n",
            "---------------------------------------\n",
            "G_USPS_MNIST(\n",
            "  (conv1): Sequential(\n",
            "    (0): Conv2d(1, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (conv2): Sequential(\n",
            "    (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (conv3): Sequential(\n",
            "    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (conv4): Sequential(\n",
            "    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (deconv1): Sequential(\n",
            "    (0): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (deconv2): Sequential(\n",
            "    (0): ConvTranspose2d(64, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "  )\n",
            ")\n",
            "---------------------------------------\n",
            "                  D_M                  \n",
            "---------------------------------------\n",
            "D_MNIST(\n",
            "  (conv1): Sequential(\n",
            "    (0): Conv2d(1, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "  )\n",
            "  (conv2): Sequential(\n",
            "    (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (conv3): Sequential(\n",
            "    (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (fc): Sequential(\n",
            "    (0): Conv2d(256, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
            "  )\n",
            ")\n",
            "---------------------------------------\n",
            "                  D_U                  \n",
            "---------------------------------------\n",
            "D_USPS(\n",
            "  (conv1): Sequential(\n",
            "    (0): Conv2d(1, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "  )\n",
            "  (conv2): Sequential(\n",
            "    (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (conv3): Sequential(\n",
            "    (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (fc): Sequential(\n",
            "    (0): Conv2d(256, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
            "  )\n",
            ")\n",
            "---------------------------------------\n",
            "Models moved to GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration [   10/20000] | d_real_loss: 0.6263 | d_Y_loss: 0.0634 | d_X_loss: 0.0726 | d_fake_loss: 0.1360 | g_loss: 0.7087\n",
            "Iteration [   20/20000] | d_real_loss: 0.0740 | d_Y_loss: 0.0238 | d_X_loss: 0.0557 | d_fake_loss: 0.0795 | g_loss: 0.3436\n",
            "Iteration [   30/20000] | d_real_loss: 0.0402 | d_Y_loss: 0.0123 | d_X_loss: 0.0258 | d_fake_loss: 0.0382 | g_loss: 0.2352\n",
            "Iteration [   40/20000] | d_real_loss: 0.0184 | d_Y_loss: 0.0113 | d_X_loss: 0.0156 | d_fake_loss: 0.0269 | g_loss: 0.1904\n",
            "Iteration [   50/20000] | d_real_loss: 0.0199 | d_Y_loss: 0.0080 | d_X_loss: 0.0157 | d_fake_loss: 0.0236 | g_loss: 0.1627\n",
            "Iteration [   60/20000] | d_real_loss: 0.0154 | d_Y_loss: 0.0110 | d_X_loss: 0.0132 | d_fake_loss: 0.0243 | g_loss: 0.1412\n",
            "Iteration [   70/20000] | d_real_loss: 0.0153 | d_Y_loss: 0.0157 | d_X_loss: 0.0092 | d_fake_loss: 0.0249 | g_loss: 0.1261\n",
            "Iteration [   80/20000] | d_real_loss: 0.0163 | d_Y_loss: 0.0076 | d_X_loss: 0.0161 | d_fake_loss: 0.0237 | g_loss: 0.1130\n",
            "Iteration [   90/20000] | d_real_loss: 0.0137 | d_Y_loss: 0.0071 | d_X_loss: 0.0094 | d_fake_loss: 0.0165 | g_loss: 0.0931\n",
            "Iteration [  100/20000] | d_real_loss: 0.0137 | d_Y_loss: 0.0052 | d_X_loss: 0.0090 | d_fake_loss: 0.0142 | g_loss: 0.0816\n",
            "Iteration [  110/20000] | d_real_loss: 0.0117 | d_Y_loss: 0.0063 | d_X_loss: 0.0109 | d_fake_loss: 0.0172 | g_loss: 0.0756\n",
            "Iteration [  120/20000] | d_real_loss: 0.0075 | d_Y_loss: 0.0067 | d_X_loss: 0.0082 | d_fake_loss: 0.0148 | g_loss: 0.0655\n",
            "Iteration [  130/20000] | d_real_loss: 0.0093 | d_Y_loss: 0.0057 | d_X_loss: 0.0094 | d_fake_loss: 0.0152 | g_loss: 0.0594\n",
            "Iteration [  140/20000] | d_real_loss: 0.0078 | d_Y_loss: 0.0060 | d_X_loss: 0.0074 | d_fake_loss: 0.0134 | g_loss: 0.0553\n",
            "Iteration [  150/20000] | d_real_loss: 0.0111 | d_Y_loss: 0.0032 | d_X_loss: 0.0062 | d_fake_loss: 0.0094 | g_loss: 0.0440\n",
            "Iteration [  160/20000] | d_real_loss: 0.0067 | d_Y_loss: 0.0055 | d_X_loss: 0.0074 | d_fake_loss: 0.0129 | g_loss: 0.0424\n",
            "Iteration [  170/20000] | d_real_loss: 0.0066 | d_Y_loss: 0.0043 | d_X_loss: 0.0064 | d_fake_loss: 0.0106 | g_loss: 0.0371\n",
            "Iteration [  180/20000] | d_real_loss: 0.0077 | d_Y_loss: 0.0047 | d_X_loss: 0.0049 | d_fake_loss: 0.0096 | g_loss: 0.0411\n",
            "Iteration [  190/20000] | d_real_loss: 0.0118 | d_Y_loss: 0.0030 | d_X_loss: 0.0045 | d_fake_loss: 0.0076 | g_loss: 0.0342\n",
            "Iteration [  200/20000] | d_real_loss: 0.0063 | d_Y_loss: 0.0028 | d_X_loss: 0.0096 | d_fake_loss: 0.0123 | g_loss: 0.0310\n",
            "Iteration [  210/20000] | d_real_loss: 0.0079 | d_Y_loss: 0.0027 | d_X_loss: 0.0066 | d_fake_loss: 0.0093 | g_loss: 0.0303\n",
            "Iteration [  220/20000] | d_real_loss: 0.0079 | d_Y_loss: 0.0040 | d_X_loss: 0.0038 | d_fake_loss: 0.0078 | g_loss: 0.0326\n",
            "Iteration [  230/20000] | d_real_loss: 0.0054 | d_Y_loss: 0.0034 | d_X_loss: 0.0027 | d_fake_loss: 0.0062 | g_loss: 0.0264\n",
            "Iteration [  240/20000] | d_real_loss: 0.0055 | d_Y_loss: 0.0023 | d_X_loss: 0.0041 | d_fake_loss: 0.0064 | g_loss: 0.0255\n",
            "Iteration [  250/20000] | d_real_loss: 0.0043 | d_Y_loss: 0.0013 | d_X_loss: 0.0049 | d_fake_loss: 0.0062 | g_loss: 0.0228\n",
            "Iteration [  260/20000] | d_real_loss: 0.0049 | d_Y_loss: 0.0030 | d_X_loss: 0.0040 | d_fake_loss: 0.0070 | g_loss: 0.0258\n",
            "Iteration [  270/20000] | d_real_loss: 0.0044 | d_Y_loss: 0.0013 | d_X_loss: 0.0025 | d_fake_loss: 0.0038 | g_loss: 0.0227\n",
            "Iteration [  280/20000] | d_real_loss: 0.0060 | d_Y_loss: 0.0048 | d_X_loss: 0.0035 | d_fake_loss: 0.0083 | g_loss: 0.0240\n",
            "Iteration [  290/20000] | d_real_loss: 0.0096 | d_Y_loss: 0.0028 | d_X_loss: 0.0040 | d_fake_loss: 0.0068 | g_loss: 0.0238\n",
            "Iteration [  300/20000] | d_real_loss: 0.0049 | d_Y_loss: 0.0049 | d_X_loss: 0.0029 | d_fake_loss: 0.0078 | g_loss: 0.0210\n",
            "Iteration [  310/20000] | d_real_loss: 0.0048 | d_Y_loss: 0.0026 | d_X_loss: 0.0034 | d_fake_loss: 0.0060 | g_loss: 0.0255\n",
            "Iteration [  320/20000] | d_real_loss: 0.0054 | d_Y_loss: 0.0017 | d_X_loss: 0.0024 | d_fake_loss: 0.0041 | g_loss: 0.0200\n",
            "Iteration [  330/20000] | d_real_loss: 0.0046 | d_Y_loss: 0.0018 | d_X_loss: 0.0035 | d_fake_loss: 0.0053 | g_loss: 0.0198\n",
            "Iteration [  340/20000] | d_real_loss: 0.0069 | d_Y_loss: 0.0015 | d_X_loss: 0.0029 | d_fake_loss: 0.0045 | g_loss: 0.0176\n",
            "Iteration [  350/20000] | d_real_loss: 0.0065 | d_Y_loss: 0.0018 | d_X_loss: 0.0024 | d_fake_loss: 0.0042 | g_loss: 0.0175\n",
            "Iteration [  360/20000] | d_real_loss: 0.0047 | d_Y_loss: 0.0012 | d_X_loss: 0.0024 | d_fake_loss: 0.0036 | g_loss: 0.0182\n",
            "Iteration [  370/20000] | d_real_loss: 0.0049 | d_Y_loss: 0.0015 | d_X_loss: 0.0031 | d_fake_loss: 0.0046 | g_loss: 0.0164\n",
            "Iteration [  380/20000] | d_real_loss: 0.0045 | d_Y_loss: 0.0011 | d_X_loss: 0.0013 | d_fake_loss: 0.0024 | g_loss: 0.0171\n",
            "Iteration [  390/20000] | d_real_loss: 0.0058 | d_Y_loss: 0.0015 | d_X_loss: 0.0015 | d_fake_loss: 0.0030 | g_loss: 0.0183\n",
            "Iteration [  400/20000] | d_real_loss: 0.0030 | d_Y_loss: 0.0014 | d_X_loss: 0.0020 | d_fake_loss: 0.0033 | g_loss: 0.0164\n",
            "Iteration [  410/20000] | d_real_loss: 0.0049 | d_Y_loss: 0.0023 | d_X_loss: 0.0029 | d_fake_loss: 0.0052 | g_loss: 0.0163\n",
            "Iteration [  420/20000] | d_real_loss: 0.0060 | d_Y_loss: 0.0011 | d_X_loss: 0.0014 | d_fake_loss: 0.0025 | g_loss: 0.0153\n",
            "Iteration [  430/20000] | d_real_loss: 0.0042 | d_Y_loss: 0.0018 | d_X_loss: 0.0020 | d_fake_loss: 0.0038 | g_loss: 0.0183\n",
            "Iteration [  440/20000] | d_real_loss: 0.0045 | d_Y_loss: 0.0015 | d_X_loss: 0.0027 | d_fake_loss: 0.0042 | g_loss: 0.0144\n",
            "Iteration [  450/20000] | d_real_loss: 0.0046 | d_Y_loss: 0.0013 | d_X_loss: 0.0015 | d_fake_loss: 0.0028 | g_loss: 0.0151\n",
            "Iteration [  460/20000] | d_real_loss: 0.0051 | d_Y_loss: 0.0016 | d_X_loss: 0.0017 | d_fake_loss: 0.0033 | g_loss: 0.0143\n",
            "Iteration [  470/20000] | d_real_loss: 0.0038 | d_Y_loss: 0.0010 | d_X_loss: 0.0018 | d_fake_loss: 0.0028 | g_loss: 0.0153\n",
            "Iteration [  480/20000] | d_real_loss: 0.0028 | d_Y_loss: 0.0014 | d_X_loss: 0.0026 | d_fake_loss: 0.0040 | g_loss: 0.0151\n",
            "Iteration [  490/20000] | d_real_loss: 0.0023 | d_Y_loss: 0.0017 | d_X_loss: 0.0014 | d_fake_loss: 0.0032 | g_loss: 0.0136\n",
            "Iteration [  500/20000] | d_real_loss: 0.0028 | d_Y_loss: 0.0071 | d_X_loss: 0.0012 | d_fake_loss: 0.0083 | g_loss: 0.0135\n",
            "Iteration [  510/20000] | d_real_loss: 0.0022 | d_Y_loss: 0.0009 | d_X_loss: 0.0014 | d_fake_loss: 0.0023 | g_loss: 0.0140\n",
            "Iteration [  520/20000] | d_real_loss: 0.0027 | d_Y_loss: 0.0014 | d_X_loss: 0.0026 | d_fake_loss: 0.0039 | g_loss: 0.0137\n",
            "Iteration [  530/20000] | d_real_loss: 0.0037 | d_Y_loss: 0.0008 | d_X_loss: 0.0036 | d_fake_loss: 0.0044 | g_loss: 0.0119\n",
            "Iteration [  540/20000] | d_real_loss: 0.0071 | d_Y_loss: 0.0005 | d_X_loss: 0.0019 | d_fake_loss: 0.0024 | g_loss: 0.0118\n",
            "Iteration [  550/20000] | d_real_loss: 0.0023 | d_Y_loss: 0.0016 | d_X_loss: 0.0020 | d_fake_loss: 0.0036 | g_loss: 0.0120\n",
            "Iteration [  560/20000] | d_real_loss: 0.0021 | d_Y_loss: 0.0013 | d_X_loss: 0.0015 | d_fake_loss: 0.0028 | g_loss: 0.0115\n",
            "Iteration [  570/20000] | d_real_loss: 0.0031 | d_Y_loss: 0.0013 | d_X_loss: 0.0017 | d_fake_loss: 0.0030 | g_loss: 0.0126\n",
            "Iteration [  580/20000] | d_real_loss: 0.0029 | d_Y_loss: 0.0008 | d_X_loss: 0.0017 | d_fake_loss: 0.0025 | g_loss: 0.0126\n",
            "Iteration [  590/20000] | d_real_loss: 0.0027 | d_Y_loss: 0.0012 | d_X_loss: 0.0017 | d_fake_loss: 0.0029 | g_loss: 0.0124\n",
            "Iteration [  600/20000] | d_real_loss: 0.0022 | d_Y_loss: 0.0019 | d_X_loss: 0.0026 | d_fake_loss: 0.0045 | g_loss: 0.0123\n",
            "Iteration [  610/20000] | d_real_loss: 0.0032 | d_Y_loss: 0.0010 | d_X_loss: 0.0012 | d_fake_loss: 0.0022 | g_loss: 0.0123\n",
            "Iteration [  620/20000] | d_real_loss: 0.0040 | d_Y_loss: 0.0038 | d_X_loss: 0.0016 | d_fake_loss: 0.0054 | g_loss: 0.0131\n",
            "Iteration [  630/20000] | d_real_loss: 0.0028 | d_Y_loss: 0.0010 | d_X_loss: 0.0024 | d_fake_loss: 0.0034 | g_loss: 0.0116\n",
            "Iteration [  640/20000] | d_real_loss: 0.0040 | d_Y_loss: 0.0005 | d_X_loss: 0.0009 | d_fake_loss: 0.0014 | g_loss: 0.0108\n",
            "Iteration [  650/20000] | d_real_loss: 0.0025 | d_Y_loss: 0.0008 | d_X_loss: 0.0013 | d_fake_loss: 0.0021 | g_loss: 0.0158\n",
            "Iteration [  660/20000] | d_real_loss: 0.0028 | d_Y_loss: 0.0009 | d_X_loss: 0.0011 | d_fake_loss: 0.0021 | g_loss: 0.0117\n",
            "Iteration [  670/20000] | d_real_loss: 0.0035 | d_Y_loss: 0.0013 | d_X_loss: 0.0008 | d_fake_loss: 0.0022 | g_loss: 0.0113\n",
            "Iteration [  680/20000] | d_real_loss: 0.0023 | d_Y_loss: 0.0012 | d_X_loss: 0.0010 | d_fake_loss: 0.0021 | g_loss: 0.0109\n",
            "Iteration [  690/20000] | d_real_loss: 0.0029 | d_Y_loss: 0.0012 | d_X_loss: 0.0010 | d_fake_loss: 0.0022 | g_loss: 0.0111\n",
            "Iteration [  700/20000] | d_real_loss: 0.0031 | d_Y_loss: 0.0019 | d_X_loss: 0.0015 | d_fake_loss: 0.0033 | g_loss: 0.0106\n",
            "Iteration [  710/20000] | d_real_loss: 0.0031 | d_Y_loss: 0.0111 | d_X_loss: 0.0012 | d_fake_loss: 0.0122 | g_loss: 0.0112\n",
            "Iteration [  720/20000] | d_real_loss: 0.0030 | d_Y_loss: 0.0011 | d_X_loss: 0.0007 | d_fake_loss: 0.0018 | g_loss: 0.0107\n",
            "Iteration [  730/20000] | d_real_loss: 0.0041 | d_Y_loss: 0.0007 | d_X_loss: 0.0009 | d_fake_loss: 0.0016 | g_loss: 0.0129\n",
            "Iteration [  740/20000] | d_real_loss: 0.0024 | d_Y_loss: 0.0012 | d_X_loss: 0.0014 | d_fake_loss: 0.0027 | g_loss: 0.0106\n",
            "Iteration [  750/20000] | d_real_loss: 0.0064 | d_Y_loss: 0.0010 | d_X_loss: 0.0011 | d_fake_loss: 0.0020 | g_loss: 0.0117\n",
            "Iteration [  760/20000] | d_real_loss: 0.0037 | d_Y_loss: 0.0009 | d_X_loss: 0.0008 | d_fake_loss: 0.0017 | g_loss: 0.0104\n",
            "Iteration [  770/20000] | d_real_loss: 0.0022 | d_Y_loss: 0.0008 | d_X_loss: 0.0010 | d_fake_loss: 0.0018 | g_loss: 0.0096\n",
            "Iteration [  780/20000] | d_real_loss: 0.0017 | d_Y_loss: 0.0024 | d_X_loss: 0.0007 | d_fake_loss: 0.0030 | g_loss: 0.0102\n",
            "Iteration [  790/20000] | d_real_loss: 0.0021 | d_Y_loss: 0.0020 | d_X_loss: 0.0017 | d_fake_loss: 0.0037 | g_loss: 0.0104\n",
            "Iteration [  800/20000] | d_real_loss: 0.0019 | d_Y_loss: 0.0007 | d_X_loss: 0.0013 | d_fake_loss: 0.0020 | g_loss: 0.0104\n",
            "Iteration [  810/20000] | d_real_loss: 0.0019 | d_Y_loss: 0.0006 | d_X_loss: 0.0008 | d_fake_loss: 0.0014 | g_loss: 0.0096\n",
            "Iteration [  820/20000] | d_real_loss: 0.0016 | d_Y_loss: 0.0019 | d_X_loss: 0.0014 | d_fake_loss: 0.0033 | g_loss: 0.0107\n",
            "Iteration [  830/20000] | d_real_loss: 0.0028 | d_Y_loss: 0.0009 | d_X_loss: 0.0014 | d_fake_loss: 0.0023 | g_loss: 0.0097\n",
            "Iteration [  840/20000] | d_real_loss: 0.0021 | d_Y_loss: 0.0014 | d_X_loss: 0.0018 | d_fake_loss: 0.0032 | g_loss: 0.0088\n",
            "Iteration [  850/20000] | d_real_loss: 0.0032 | d_Y_loss: 0.0008 | d_X_loss: 0.0013 | d_fake_loss: 0.0021 | g_loss: 0.0094\n",
            "Iteration [  860/20000] | d_real_loss: 0.0018 | d_Y_loss: 0.0016 | d_X_loss: 0.0009 | d_fake_loss: 0.0024 | g_loss: 0.0092\n",
            "Iteration [  870/20000] | d_real_loss: 0.0028 | d_Y_loss: 0.0029 | d_X_loss: 0.0016 | d_fake_loss: 0.0045 | g_loss: 0.0116\n",
            "Iteration [  880/20000] | d_real_loss: 0.0021 | d_Y_loss: 0.0017 | d_X_loss: 0.0013 | d_fake_loss: 0.0030 | g_loss: 0.0090\n",
            "Iteration [  890/20000] | d_real_loss: 0.0022 | d_Y_loss: 0.0020 | d_X_loss: 0.0014 | d_fake_loss: 0.0034 | g_loss: 0.0101\n",
            "Iteration [  900/20000] | d_real_loss: 0.0031 | d_Y_loss: 0.0010 | d_X_loss: 0.0015 | d_fake_loss: 0.0024 | g_loss: 0.0086\n",
            "Iteration [  910/20000] | d_real_loss: 0.0024 | d_Y_loss: 0.0043 | d_X_loss: 0.0017 | d_fake_loss: 0.0061 | g_loss: 0.0097\n",
            "Iteration [  920/20000] | d_real_loss: 0.0019 | d_Y_loss: 0.0027 | d_X_loss: 0.0009 | d_fake_loss: 0.0035 | g_loss: 0.0086\n",
            "Iteration [  930/20000] | d_real_loss: 0.0020 | d_Y_loss: 0.0015 | d_X_loss: 0.0004 | d_fake_loss: 0.0019 | g_loss: 0.0103\n",
            "Iteration [  940/20000] | d_real_loss: 0.0019 | d_Y_loss: 0.0005 | d_X_loss: 0.0006 | d_fake_loss: 0.0010 | g_loss: 0.0087\n",
            "Iteration [  950/20000] | d_real_loss: 0.0021 | d_Y_loss: 0.0025 | d_X_loss: 0.0010 | d_fake_loss: 0.0035 | g_loss: 0.0083\n",
            "Iteration [  960/20000] | d_real_loss: 0.0018 | d_Y_loss: 0.0011 | d_X_loss: 0.0007 | d_fake_loss: 0.0018 | g_loss: 0.0076\n",
            "Iteration [  970/20000] | d_real_loss: 0.0019 | d_Y_loss: 0.0030 | d_X_loss: 0.0009 | d_fake_loss: 0.0039 | g_loss: 0.0080\n",
            "Iteration [  980/20000] | d_real_loss: 0.0015 | d_Y_loss: 0.0011 | d_X_loss: 0.0013 | d_fake_loss: 0.0024 | g_loss: 0.0079\n",
            "Iteration [  990/20000] | d_real_loss: 0.0031 | d_Y_loss: 0.0020 | d_X_loss: 0.0008 | d_fake_loss: 0.0028 | g_loss: 0.0104\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float64 to uint8. Range [-1.0, 0.9990254640579224]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration [ 1000/20000] | d_real_loss: 0.0018 | d_Y_loss: 0.0020 | d_X_loss: 0.0005 | d_fake_loss: 0.0025 | g_loss: 0.0086\n",
            "Saved /content/sample-001000-X-Y.png\n",
            "Saved /content/sample-001000-Y-X.png\n",
            "Iteration [ 1010/20000] | d_real_loss: 0.0025 | d_Y_loss: 0.0022 | d_X_loss: 0.0007 | d_fake_loss: 0.0029 | g_loss: 0.0080\n",
            "Iteration [ 1020/20000] | d_real_loss: 0.0023 | d_Y_loss: 0.0003 | d_X_loss: 0.0016 | d_fake_loss: 0.0019 | g_loss: 0.0093\n",
            "Iteration [ 1030/20000] | d_real_loss: 0.0014 | d_Y_loss: 0.0004 | d_X_loss: 0.0017 | d_fake_loss: 0.0021 | g_loss: 0.0072\n",
            "Iteration [ 1040/20000] | d_real_loss: 0.0018 | d_Y_loss: 0.0012 | d_X_loss: 0.0010 | d_fake_loss: 0.0022 | g_loss: 0.0087\n",
            "Iteration [ 1050/20000] | d_real_loss: 0.0028 | d_Y_loss: 0.0010 | d_X_loss: 0.0016 | d_fake_loss: 0.0026 | g_loss: 0.0082\n",
            "Iteration [ 1060/20000] | d_real_loss: 0.0016 | d_Y_loss: 0.0009 | d_X_loss: 0.0007 | d_fake_loss: 0.0016 | g_loss: 0.0087\n",
            "Iteration [ 1070/20000] | d_real_loss: 0.0019 | d_Y_loss: 0.0024 | d_X_loss: 0.0009 | d_fake_loss: 0.0033 | g_loss: 0.0075\n",
            "Iteration [ 1080/20000] | d_real_loss: 0.0015 | d_Y_loss: 0.0003 | d_X_loss: 0.0009 | d_fake_loss: 0.0011 | g_loss: 0.0078\n",
            "Iteration [ 1090/20000] | d_real_loss: 0.0012 | d_Y_loss: 0.0003 | d_X_loss: 0.0008 | d_fake_loss: 0.0011 | g_loss: 0.0089\n",
            "Iteration [ 1100/20000] | d_real_loss: 0.0015 | d_Y_loss: 0.0004 | d_X_loss: 0.0018 | d_fake_loss: 0.0023 | g_loss: 0.0072\n",
            "Iteration [ 1110/20000] | d_real_loss: 0.0021 | d_Y_loss: 0.0003 | d_X_loss: 0.0010 | d_fake_loss: 0.0013 | g_loss: 0.0074\n",
            "Iteration [ 1120/20000] | d_real_loss: 0.0044 | d_Y_loss: 0.0005 | d_X_loss: 0.0008 | d_fake_loss: 0.0013 | g_loss: 0.0085\n",
            "Iteration [ 1130/20000] | d_real_loss: 0.0029 | d_Y_loss: 0.0022 | d_X_loss: 0.0010 | d_fake_loss: 0.0032 | g_loss: 0.0079\n",
            "Iteration [ 1140/20000] | d_real_loss: 0.0023 | d_Y_loss: 0.0140 | d_X_loss: 0.0016 | d_fake_loss: 0.0156 | g_loss: 0.0113\n",
            "Iteration [ 1150/20000] | d_real_loss: 0.0026 | d_Y_loss: 0.0007 | d_X_loss: 0.0018 | d_fake_loss: 0.0024 | g_loss: 0.0078\n",
            "Iteration [ 1160/20000] | d_real_loss: 0.0020 | d_Y_loss: 0.0005 | d_X_loss: 0.0012 | d_fake_loss: 0.0016 | g_loss: 0.0099\n",
            "Iteration [ 1170/20000] | d_real_loss: 0.0056 | d_Y_loss: 0.0003 | d_X_loss: 0.0011 | d_fake_loss: 0.0014 | g_loss: 0.0082\n",
            "Iteration [ 1180/20000] | d_real_loss: 0.0027 | d_Y_loss: 0.0004 | d_X_loss: 0.0009 | d_fake_loss: 0.0012 | g_loss: 0.0066\n",
            "Iteration [ 1190/20000] | d_real_loss: 0.0013 | d_Y_loss: 0.0009 | d_X_loss: 0.0017 | d_fake_loss: 0.0026 | g_loss: 0.0071\n",
            "Iteration [ 1200/20000] | d_real_loss: 0.0022 | d_Y_loss: 0.0020 | d_X_loss: 0.0005 | d_fake_loss: 0.0025 | g_loss: 0.0075\n",
            "Iteration [ 1210/20000] | d_real_loss: 0.0016 | d_Y_loss: 0.0020 | d_X_loss: 0.0006 | d_fake_loss: 0.0026 | g_loss: 0.0074\n",
            "Iteration [ 1220/20000] | d_real_loss: 0.0019 | d_Y_loss: 0.0010 | d_X_loss: 0.0013 | d_fake_loss: 0.0023 | g_loss: 0.0072\n",
            "Iteration [ 1230/20000] | d_real_loss: 0.0015 | d_Y_loss: 0.0007 | d_X_loss: 0.0008 | d_fake_loss: 0.0014 | g_loss: 0.0069\n",
            "Iteration [ 1240/20000] | d_real_loss: 0.0033 | d_Y_loss: 0.0011 | d_X_loss: 0.0006 | d_fake_loss: 0.0018 | g_loss: 0.0074\n",
            "Iteration [ 1250/20000] | d_real_loss: 0.0019 | d_Y_loss: 0.0006 | d_X_loss: 0.0006 | d_fake_loss: 0.0012 | g_loss: 0.0065\n",
            "Iteration [ 1260/20000] | d_real_loss: 0.0023 | d_Y_loss: 0.0055 | d_X_loss: 0.0004 | d_fake_loss: 0.0060 | g_loss: 0.0067\n",
            "Iteration [ 1270/20000] | d_real_loss: 0.0027 | d_Y_loss: 0.0013 | d_X_loss: 0.0009 | d_fake_loss: 0.0022 | g_loss: 0.0067\n",
            "Iteration [ 1280/20000] | d_real_loss: 0.0025 | d_Y_loss: 0.0027 | d_X_loss: 0.0008 | d_fake_loss: 0.0035 | g_loss: 0.0085\n",
            "Iteration [ 1290/20000] | d_real_loss: 0.0021 | d_Y_loss: 0.0020 | d_X_loss: 0.0015 | d_fake_loss: 0.0035 | g_loss: 0.0067\n",
            "Iteration [ 1300/20000] | d_real_loss: 0.0015 | d_Y_loss: 0.0047 | d_X_loss: 0.0021 | d_fake_loss: 0.0068 | g_loss: 0.0074\n",
            "Iteration [ 1310/20000] | d_real_loss: 0.0020 | d_Y_loss: 0.0004 | d_X_loss: 0.0010 | d_fake_loss: 0.0013 | g_loss: 0.0065\n",
            "Iteration [ 1320/20000] | d_real_loss: 0.0028 | d_Y_loss: 0.0023 | d_X_loss: 0.0019 | d_fake_loss: 0.0041 | g_loss: 0.0060\n",
            "Iteration [ 1330/20000] | d_real_loss: 0.0021 | d_Y_loss: 0.0009 | d_X_loss: 0.0010 | d_fake_loss: 0.0019 | g_loss: 0.0075\n",
            "Iteration [ 1340/20000] | d_real_loss: 0.0033 | d_Y_loss: 0.0006 | d_X_loss: 0.0015 | d_fake_loss: 0.0022 | g_loss: 0.0088\n",
            "Iteration [ 1350/20000] | d_real_loss: 0.0015 | d_Y_loss: 0.0016 | d_X_loss: 0.0006 | d_fake_loss: 0.0022 | g_loss: 0.0066\n",
            "Iteration [ 1360/20000] | d_real_loss: 0.0027 | d_Y_loss: 0.0007 | d_X_loss: 0.0011 | d_fake_loss: 0.0018 | g_loss: 0.0062\n",
            "Iteration [ 1370/20000] | d_real_loss: 0.0018 | d_Y_loss: 0.0003 | d_X_loss: 0.0010 | d_fake_loss: 0.0013 | g_loss: 0.0084\n",
            "Iteration [ 1380/20000] | d_real_loss: 0.0016 | d_Y_loss: 0.0004 | d_X_loss: 0.0012 | d_fake_loss: 0.0017 | g_loss: 0.0063\n",
            "Iteration [ 1390/20000] | d_real_loss: 0.0039 | d_Y_loss: 0.0033 | d_X_loss: 0.0012 | d_fake_loss: 0.0045 | g_loss: 0.0060\n",
            "Iteration [ 1400/20000] | d_real_loss: 0.0023 | d_Y_loss: 0.0004 | d_X_loss: 0.0007 | d_fake_loss: 0.0011 | g_loss: 0.0058\n",
            "Iteration [ 1410/20000] | d_real_loss: 0.0023 | d_Y_loss: 0.0038 | d_X_loss: 0.0009 | d_fake_loss: 0.0048 | g_loss: 0.0067\n",
            "Iteration [ 1420/20000] | d_real_loss: 0.0016 | d_Y_loss: 0.0006 | d_X_loss: 0.0007 | d_fake_loss: 0.0013 | g_loss: 0.0066\n",
            "Iteration [ 1430/20000] | d_real_loss: 0.0016 | d_Y_loss: 0.0010 | d_X_loss: 0.0022 | d_fake_loss: 0.0031 | g_loss: 0.0065\n",
            "Iteration [ 1440/20000] | d_real_loss: 0.0018 | d_Y_loss: 0.0003 | d_X_loss: 0.0012 | d_fake_loss: 0.0015 | g_loss: 0.0053\n",
            "Iteration [ 1450/20000] | d_real_loss: 0.0061 | d_Y_loss: 0.0009 | d_X_loss: 0.0012 | d_fake_loss: 0.0021 | g_loss: 0.0059\n",
            "Iteration [ 1460/20000] | d_real_loss: 0.0033 | d_Y_loss: 0.0078 | d_X_loss: 0.0012 | d_fake_loss: 0.0090 | g_loss: 0.0066\n",
            "Iteration [ 1470/20000] | d_real_loss: 0.0026 | d_Y_loss: 0.0015 | d_X_loss: 0.0007 | d_fake_loss: 0.0022 | g_loss: 0.0072\n",
            "Iteration [ 1480/20000] | d_real_loss: 0.0027 | d_Y_loss: 0.0010 | d_X_loss: 0.0009 | d_fake_loss: 0.0019 | g_loss: 0.0065\n",
            "Iteration [ 1490/20000] | d_real_loss: 0.0014 | d_Y_loss: 0.0025 | d_X_loss: 0.0007 | d_fake_loss: 0.0031 | g_loss: 0.0055\n",
            "Iteration [ 1500/20000] | d_real_loss: 0.0048 | d_Y_loss: 0.0034 | d_X_loss: 0.0052 | d_fake_loss: 0.0085 | g_loss: 0.0074\n",
            "Iteration [ 1510/20000] | d_real_loss: 0.0021 | d_Y_loss: 0.0014 | d_X_loss: 0.0023 | d_fake_loss: 0.0036 | g_loss: 0.0061\n",
            "Iteration [ 1520/20000] | d_real_loss: 0.0016 | d_Y_loss: 0.0004 | d_X_loss: 0.0013 | d_fake_loss: 0.0017 | g_loss: 0.0065\n",
            "Iteration [ 1530/20000] | d_real_loss: 0.0024 | d_Y_loss: 0.0019 | d_X_loss: 0.0007 | d_fake_loss: 0.0026 | g_loss: 0.0060\n",
            "Iteration [ 1540/20000] | d_real_loss: 0.0048 | d_Y_loss: 0.0003 | d_X_loss: 0.0009 | d_fake_loss: 0.0013 | g_loss: 0.0060\n",
            "Iteration [ 1550/20000] | d_real_loss: 0.0034 | d_Y_loss: 0.0005 | d_X_loss: 0.0005 | d_fake_loss: 0.0010 | g_loss: 0.0063\n",
            "Iteration [ 1560/20000] | d_real_loss: 0.0018 | d_Y_loss: 0.0006 | d_X_loss: 0.0010 | d_fake_loss: 0.0016 | g_loss: 0.0059\n",
            "Iteration [ 1570/20000] | d_real_loss: 0.0032 | d_Y_loss: 0.0003 | d_X_loss: 0.0004 | d_fake_loss: 0.0007 | g_loss: 0.0055\n",
            "Iteration [ 1580/20000] | d_real_loss: 0.0028 | d_Y_loss: 0.0005 | d_X_loss: 0.0003 | d_fake_loss: 0.0008 | g_loss: 0.0065\n",
            "Iteration [ 1590/20000] | d_real_loss: 0.0013 | d_Y_loss: 0.0007 | d_X_loss: 0.0013 | d_fake_loss: 0.0020 | g_loss: 0.0057\n",
            "Iteration [ 1600/20000] | d_real_loss: 0.0013 | d_Y_loss: 0.0005 | d_X_loss: 0.0005 | d_fake_loss: 0.0010 | g_loss: 0.0056\n",
            "Iteration [ 1610/20000] | d_real_loss: 0.0013 | d_Y_loss: 0.0013 | d_X_loss: 0.0006 | d_fake_loss: 0.0019 | g_loss: 0.0054\n",
            "Iteration [ 1620/20000] | d_real_loss: 0.0024 | d_Y_loss: 0.0003 | d_X_loss: 0.0007 | d_fake_loss: 0.0010 | g_loss: 0.0056\n",
            "Iteration [ 1630/20000] | d_real_loss: 0.0024 | d_Y_loss: 0.0012 | d_X_loss: 0.0034 | d_fake_loss: 0.0046 | g_loss: 0.0057\n",
            "Iteration [ 1640/20000] | d_real_loss: 0.0022 | d_Y_loss: 0.0016 | d_X_loss: 0.0019 | d_fake_loss: 0.0035 | g_loss: 0.0055\n",
            "Iteration [ 1650/20000] | d_real_loss: 0.0019 | d_Y_loss: 0.0005 | d_X_loss: 0.0007 | d_fake_loss: 0.0012 | g_loss: 0.0053\n",
            "Iteration [ 1660/20000] | d_real_loss: 0.0016 | d_Y_loss: 0.0007 | d_X_loss: 0.0006 | d_fake_loss: 0.0013 | g_loss: 0.0085\n",
            "Iteration [ 1670/20000] | d_real_loss: 0.0020 | d_Y_loss: 0.0006 | d_X_loss: 0.0005 | d_fake_loss: 0.0010 | g_loss: 0.0055\n",
            "Iteration [ 1680/20000] | d_real_loss: 0.0017 | d_Y_loss: 0.0019 | d_X_loss: 0.0022 | d_fake_loss: 0.0041 | g_loss: 0.0059\n",
            "Iteration [ 1690/20000] | d_real_loss: 0.0019 | d_Y_loss: 0.0022 | d_X_loss: 0.0018 | d_fake_loss: 0.0040 | g_loss: 0.0061\n",
            "Iteration [ 1700/20000] | d_real_loss: 0.0013 | d_Y_loss: 0.0009 | d_X_loss: 0.0010 | d_fake_loss: 0.0019 | g_loss: 0.0056\n",
            "Iteration [ 1710/20000] | d_real_loss: 0.0031 | d_Y_loss: 0.0009 | d_X_loss: 0.0004 | d_fake_loss: 0.0013 | g_loss: 0.0059\n",
            "Iteration [ 1720/20000] | d_real_loss: 0.0033 | d_Y_loss: 0.0121 | d_X_loss: 0.0006 | d_fake_loss: 0.0128 | g_loss: 0.0061\n",
            "Iteration [ 1730/20000] | d_real_loss: 0.0010 | d_Y_loss: 0.0026 | d_X_loss: 0.0009 | d_fake_loss: 0.0035 | g_loss: 0.0067\n",
            "Iteration [ 1740/20000] | d_real_loss: 0.0034 | d_Y_loss: 0.0004 | d_X_loss: 0.0008 | d_fake_loss: 0.0012 | g_loss: 0.0048\n",
            "Iteration [ 1750/20000] | d_real_loss: 0.0041 | d_Y_loss: 0.0010 | d_X_loss: 0.0012 | d_fake_loss: 0.0022 | g_loss: 0.0052\n",
            "Iteration [ 1760/20000] | d_real_loss: 0.0024 | d_Y_loss: 0.0004 | d_X_loss: 0.0004 | d_fake_loss: 0.0008 | g_loss: 0.0060\n",
            "Iteration [ 1770/20000] | d_real_loss: 0.0014 | d_Y_loss: 0.0012 | d_X_loss: 0.0007 | d_fake_loss: 0.0019 | g_loss: 0.0055\n",
            "Iteration [ 1780/20000] | d_real_loss: 0.0009 | d_Y_loss: 0.0020 | d_X_loss: 0.0006 | d_fake_loss: 0.0026 | g_loss: 0.0065\n",
            "Iteration [ 1790/20000] | d_real_loss: 0.0011 | d_Y_loss: 0.0007 | d_X_loss: 0.0001 | d_fake_loss: 0.0009 | g_loss: 0.0058\n",
            "Iteration [ 1800/20000] | d_real_loss: 0.0021 | d_Y_loss: 0.0010 | d_X_loss: 0.0006 | d_fake_loss: 0.0016 | g_loss: 0.0052\n",
            "Iteration [ 1810/20000] | d_real_loss: 0.0029 | d_Y_loss: 0.0004 | d_X_loss: 0.0007 | d_fake_loss: 0.0012 | g_loss: 0.0059\n",
            "Iteration [ 1820/20000] | d_real_loss: 0.0038 | d_Y_loss: 0.0120 | d_X_loss: 0.0012 | d_fake_loss: 0.0132 | g_loss: 0.0052\n",
            "Iteration [ 1830/20000] | d_real_loss: 0.0062 | d_Y_loss: 0.0006 | d_X_loss: 0.0005 | d_fake_loss: 0.0011 | g_loss: 0.0059\n",
            "Iteration [ 1840/20000] | d_real_loss: 0.0018 | d_Y_loss: 0.0006 | d_X_loss: 0.0006 | d_fake_loss: 0.0013 | g_loss: 0.0063\n",
            "Iteration [ 1850/20000] | d_real_loss: 0.0018 | d_Y_loss: 0.0003 | d_X_loss: 0.0036 | d_fake_loss: 0.0039 | g_loss: 0.0056\n",
            "Iteration [ 1860/20000] | d_real_loss: 0.0038 | d_Y_loss: 0.0011 | d_X_loss: 0.0010 | d_fake_loss: 0.0021 | g_loss: 0.0053\n",
            "Iteration [ 1870/20000] | d_real_loss: 0.0013 | d_Y_loss: 0.0025 | d_X_loss: 0.0007 | d_fake_loss: 0.0031 | g_loss: 0.0049\n",
            "Iteration [ 1880/20000] | d_real_loss: 0.0038 | d_Y_loss: 0.0018 | d_X_loss: 0.0005 | d_fake_loss: 0.0023 | g_loss: 0.0055\n",
            "Iteration [ 1890/20000] | d_real_loss: 0.0018 | d_Y_loss: 0.0003 | d_X_loss: 0.0023 | d_fake_loss: 0.0027 | g_loss: 0.0056\n",
            "Iteration [ 1900/20000] | d_real_loss: 0.0010 | d_Y_loss: 0.0022 | d_X_loss: 0.0009 | d_fake_loss: 0.0031 | g_loss: 0.0057\n",
            "Iteration [ 1910/20000] | d_real_loss: 0.0023 | d_Y_loss: 0.0004 | d_X_loss: 0.0006 | d_fake_loss: 0.0010 | g_loss: 0.0051\n",
            "Iteration [ 1920/20000] | d_real_loss: 0.0022 | d_Y_loss: 0.0013 | d_X_loss: 0.0005 | d_fake_loss: 0.0019 | g_loss: 0.0052\n",
            "Iteration [ 1930/20000] | d_real_loss: 0.0025 | d_Y_loss: 0.0007 | d_X_loss: 0.0005 | d_fake_loss: 0.0012 | g_loss: 0.0045\n",
            "Iteration [ 1940/20000] | d_real_loss: 0.0010 | d_Y_loss: 0.0002 | d_X_loss: 0.0005 | d_fake_loss: 0.0007 | g_loss: 0.0076\n",
            "Iteration [ 1950/20000] | d_real_loss: 0.0018 | d_Y_loss: 0.0003 | d_X_loss: 0.0006 | d_fake_loss: 0.0009 | g_loss: 0.0047\n",
            "Iteration [ 1960/20000] | d_real_loss: 0.0032 | d_Y_loss: 0.0037 | d_X_loss: 0.0003 | d_fake_loss: 0.0040 | g_loss: 0.0052\n",
            "Iteration [ 1970/20000] | d_real_loss: 0.0025 | d_Y_loss: 0.0013 | d_X_loss: 0.0005 | d_fake_loss: 0.0018 | g_loss: 0.0054\n",
            "Iteration [ 1980/20000] | d_real_loss: 0.0022 | d_Y_loss: 0.0006 | d_X_loss: 0.0004 | d_fake_loss: 0.0010 | g_loss: 0.0047\n",
            "Iteration [ 1990/20000] | d_real_loss: 0.0024 | d_Y_loss: 0.0021 | d_X_loss: 0.0016 | d_fake_loss: 0.0037 | g_loss: 0.0058\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float64 to uint8. Range [-1.0, 0.996366560459137]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration [ 2000/20000] | d_real_loss: 0.0022 | d_Y_loss: 0.0026 | d_X_loss: 0.0010 | d_fake_loss: 0.0036 | g_loss: 0.0047\n",
            "Saved /content/sample-002000-X-Y.png\n",
            "Saved /content/sample-002000-Y-X.png\n",
            "Iteration [ 2010/20000] | d_real_loss: 0.0018 | d_Y_loss: 0.0011 | d_X_loss: 0.0004 | d_fake_loss: 0.0016 | g_loss: 0.0046\n",
            "Iteration [ 2020/20000] | d_real_loss: 0.0029 | d_Y_loss: 0.0007 | d_X_loss: 0.0011 | d_fake_loss: 0.0018 | g_loss: 0.0055\n",
            "Iteration [ 2030/20000] | d_real_loss: 0.0011 | d_Y_loss: 0.0002 | d_X_loss: 0.0003 | d_fake_loss: 0.0006 | g_loss: 0.0052\n",
            "Iteration [ 2040/20000] | d_real_loss: 0.0010 | d_Y_loss: 0.0014 | d_X_loss: 0.0007 | d_fake_loss: 0.0022 | g_loss: 0.0052\n",
            "Iteration [ 2050/20000] | d_real_loss: 0.0017 | d_Y_loss: 0.0009 | d_X_loss: 0.0009 | d_fake_loss: 0.0018 | g_loss: 0.0047\n",
            "Iteration [ 2060/20000] | d_real_loss: 0.0017 | d_Y_loss: 0.0033 | d_X_loss: 0.0011 | d_fake_loss: 0.0044 | g_loss: 0.0054\n",
            "Iteration [ 2070/20000] | d_real_loss: 0.0020 | d_Y_loss: 0.0003 | d_X_loss: 0.0018 | d_fake_loss: 0.0022 | g_loss: 0.0053\n",
            "Iteration [ 2080/20000] | d_real_loss: 0.0031 | d_Y_loss: 0.0041 | d_X_loss: 0.0011 | d_fake_loss: 0.0052 | g_loss: 0.0054\n",
            "Iteration [ 2090/20000] | d_real_loss: 0.0018 | d_Y_loss: 0.0036 | d_X_loss: 0.0019 | d_fake_loss: 0.0054 | g_loss: 0.0048\n",
            "Iteration [ 2100/20000] | d_real_loss: 0.0018 | d_Y_loss: 0.0009 | d_X_loss: 0.0007 | d_fake_loss: 0.0016 | g_loss: 0.0048\n",
            "Iteration [ 2110/20000] | d_real_loss: 0.0010 | d_Y_loss: 0.0011 | d_X_loss: 0.0010 | d_fake_loss: 0.0021 | g_loss: 0.0048\n",
            "Iteration [ 2120/20000] | d_real_loss: 0.0015 | d_Y_loss: 0.0011 | d_X_loss: 0.0017 | d_fake_loss: 0.0028 | g_loss: 0.0051\n",
            "Iteration [ 2130/20000] | d_real_loss: 0.0016 | d_Y_loss: 0.0016 | d_X_loss: 0.0006 | d_fake_loss: 0.0022 | g_loss: 0.0045\n",
            "Iteration [ 2140/20000] | d_real_loss: 0.0010 | d_Y_loss: 0.0010 | d_X_loss: 0.0005 | d_fake_loss: 0.0015 | g_loss: 0.0050\n",
            "Iteration [ 2150/20000] | d_real_loss: 0.0012 | d_Y_loss: 0.0002 | d_X_loss: 0.0013 | d_fake_loss: 0.0015 | g_loss: 0.0045\n",
            "Iteration [ 2160/20000] | d_real_loss: 0.0013 | d_Y_loss: 0.0004 | d_X_loss: 0.0019 | d_fake_loss: 0.0022 | g_loss: 0.0046\n",
            "Iteration [ 2170/20000] | d_real_loss: 0.0015 | d_Y_loss: 0.0004 | d_X_loss: 0.0005 | d_fake_loss: 0.0009 | g_loss: 0.0046\n",
            "Iteration [ 2180/20000] | d_real_loss: 0.0006 | d_Y_loss: 0.0019 | d_X_loss: 0.0008 | d_fake_loss: 0.0027 | g_loss: 0.0046\n",
            "Iteration [ 2190/20000] | d_real_loss: 0.0012 | d_Y_loss: 0.0027 | d_X_loss: 0.0003 | d_fake_loss: 0.0031 | g_loss: 0.0049\n",
            "Iteration [ 2200/20000] | d_real_loss: 0.0008 | d_Y_loss: 0.0002 | d_X_loss: 0.0003 | d_fake_loss: 0.0005 | g_loss: 0.0043\n",
            "Iteration [ 2210/20000] | d_real_loss: 0.0014 | d_Y_loss: 0.0018 | d_X_loss: 0.0016 | d_fake_loss: 0.0034 | g_loss: 0.0045\n",
            "Iteration [ 2220/20000] | d_real_loss: 0.0028 | d_Y_loss: 0.0018 | d_X_loss: 0.0021 | d_fake_loss: 0.0039 | g_loss: 0.0049\n",
            "Iteration [ 2230/20000] | d_real_loss: 0.0009 | d_Y_loss: 0.0003 | d_X_loss: 0.0004 | d_fake_loss: 0.0007 | g_loss: 0.0047\n",
            "Iteration [ 2240/20000] | d_real_loss: 0.0020 | d_Y_loss: 0.0002 | d_X_loss: 0.0012 | d_fake_loss: 0.0014 | g_loss: 0.0041\n",
            "Iteration [ 2250/20000] | d_real_loss: 0.0024 | d_Y_loss: 0.0011 | d_X_loss: 0.0004 | d_fake_loss: 0.0015 | g_loss: 0.0046\n",
            "Iteration [ 2260/20000] | d_real_loss: 0.0012 | d_Y_loss: 0.0010 | d_X_loss: 0.0003 | d_fake_loss: 0.0012 | g_loss: 0.0051\n",
            "Iteration [ 2270/20000] | d_real_loss: 0.0013 | d_Y_loss: 0.0002 | d_X_loss: 0.0007 | d_fake_loss: 0.0009 | g_loss: 0.0042\n",
            "Iteration [ 2280/20000] | d_real_loss: 0.0012 | d_Y_loss: 0.0016 | d_X_loss: 0.0026 | d_fake_loss: 0.0042 | g_loss: 0.0050\n",
            "Iteration [ 2290/20000] | d_real_loss: 0.0020 | d_Y_loss: 0.0003 | d_X_loss: 0.0011 | d_fake_loss: 0.0014 | g_loss: 0.0057\n",
            "Iteration [ 2300/20000] | d_real_loss: 0.0044 | d_Y_loss: 0.0006 | d_X_loss: 0.0042 | d_fake_loss: 0.0048 | g_loss: 0.0046\n",
            "Iteration [ 2310/20000] | d_real_loss: 0.0045 | d_Y_loss: 0.0016 | d_X_loss: 0.0011 | d_fake_loss: 0.0027 | g_loss: 0.0047\n",
            "Iteration [ 2320/20000] | d_real_loss: 0.0020 | d_Y_loss: 0.0025 | d_X_loss: 0.0011 | d_fake_loss: 0.0036 | g_loss: 0.0050\n",
            "Iteration [ 2330/20000] | d_real_loss: 0.0019 | d_Y_loss: 0.0008 | d_X_loss: 0.0010 | d_fake_loss: 0.0017 | g_loss: 0.0045\n",
            "Iteration [ 2340/20000] | d_real_loss: 0.0026 | d_Y_loss: 0.0012 | d_X_loss: 0.0038 | d_fake_loss: 0.0050 | g_loss: 0.0044\n",
            "Iteration [ 2350/20000] | d_real_loss: 0.0054 | d_Y_loss: 0.0003 | d_X_loss: 0.0012 | d_fake_loss: 0.0016 | g_loss: 0.0055\n",
            "Iteration [ 2360/20000] | d_real_loss: 0.0030 | d_Y_loss: 0.0017 | d_X_loss: 0.0004 | d_fake_loss: 0.0021 | g_loss: 0.0045\n",
            "Iteration [ 2370/20000] | d_real_loss: 0.0015 | d_Y_loss: 0.0006 | d_X_loss: 0.0007 | d_fake_loss: 0.0013 | g_loss: 0.0058\n",
            "Iteration [ 2380/20000] | d_real_loss: 0.0025 | d_Y_loss: 0.0006 | d_X_loss: 0.0016 | d_fake_loss: 0.0021 | g_loss: 0.0044\n",
            "Iteration [ 2390/20000] | d_real_loss: 0.0062 | d_Y_loss: 0.0016 | d_X_loss: 0.0008 | d_fake_loss: 0.0024 | g_loss: 0.0055\n",
            "Iteration [ 2400/20000] | d_real_loss: 0.0019 | d_Y_loss: 0.0002 | d_X_loss: 0.0013 | d_fake_loss: 0.0015 | g_loss: 0.0039\n",
            "Iteration [ 2410/20000] | d_real_loss: 0.0010 | d_Y_loss: 0.0002 | d_X_loss: 0.0007 | d_fake_loss: 0.0010 | g_loss: 0.0043\n",
            "Iteration [ 2420/20000] | d_real_loss: 0.0030 | d_Y_loss: 0.0015 | d_X_loss: 0.0006 | d_fake_loss: 0.0021 | g_loss: 0.0048\n",
            "Iteration [ 2430/20000] | d_real_loss: 0.0027 | d_Y_loss: 0.0063 | d_X_loss: 0.0004 | d_fake_loss: 0.0067 | g_loss: 0.0047\n",
            "Iteration [ 2440/20000] | d_real_loss: 0.0017 | d_Y_loss: 0.0024 | d_X_loss: 0.0002 | d_fake_loss: 0.0026 | g_loss: 0.0062\n",
            "Iteration [ 2450/20000] | d_real_loss: 0.0019 | d_Y_loss: 0.0006 | d_X_loss: 0.0006 | d_fake_loss: 0.0012 | g_loss: 0.0038\n",
            "Iteration [ 2460/20000] | d_real_loss: 0.0014 | d_Y_loss: 0.0003 | d_X_loss: 0.0002 | d_fake_loss: 0.0006 | g_loss: 0.0039\n",
            "Iteration [ 2470/20000] | d_real_loss: 0.0016 | d_Y_loss: 0.0004 | d_X_loss: 0.0009 | d_fake_loss: 0.0014 | g_loss: 0.0044\n",
            "Iteration [ 2480/20000] | d_real_loss: 0.0015 | d_Y_loss: 0.0003 | d_X_loss: 0.0005 | d_fake_loss: 0.0008 | g_loss: 0.0037\n",
            "Iteration [ 2490/20000] | d_real_loss: 0.0041 | d_Y_loss: 0.0002 | d_X_loss: 0.0009 | d_fake_loss: 0.0011 | g_loss: 0.0040\n",
            "Iteration [ 2500/20000] | d_real_loss: 0.0010 | d_Y_loss: 0.0002 | d_X_loss: 0.0003 | d_fake_loss: 0.0005 | g_loss: 0.0039\n",
            "Iteration [ 2510/20000] | d_real_loss: 0.0008 | d_Y_loss: 0.0005 | d_X_loss: 0.0005 | d_fake_loss: 0.0011 | g_loss: 0.0048\n",
            "Iteration [ 2520/20000] | d_real_loss: 0.0008 | d_Y_loss: 0.0001 | d_X_loss: 0.0004 | d_fake_loss: 0.0005 | g_loss: 0.0045\n",
            "Iteration [ 2530/20000] | d_real_loss: 0.0008 | d_Y_loss: 0.0002 | d_X_loss: 0.0003 | d_fake_loss: 0.0005 | g_loss: 0.0044\n",
            "Iteration [ 2540/20000] | d_real_loss: 0.0019 | d_Y_loss: 0.0090 | d_X_loss: 0.0005 | d_fake_loss: 0.0095 | g_loss: 0.0052\n",
            "Iteration [ 2550/20000] | d_real_loss: 0.0010 | d_Y_loss: 0.0014 | d_X_loss: 0.0002 | d_fake_loss: 0.0016 | g_loss: 0.0047\n",
            "Iteration [ 2560/20000] | d_real_loss: 0.0035 | d_Y_loss: 0.0007 | d_X_loss: 0.0006 | d_fake_loss: 0.0014 | g_loss: 0.0042\n",
            "Iteration [ 2570/20000] | d_real_loss: 0.0018 | d_Y_loss: 0.0004 | d_X_loss: 0.0012 | d_fake_loss: 0.0016 | g_loss: 0.0044\n",
            "Iteration [ 2580/20000] | d_real_loss: 0.0036 | d_Y_loss: 0.0024 | d_X_loss: 0.0006 | d_fake_loss: 0.0030 | g_loss: 0.0046\n",
            "Iteration [ 2590/20000] | d_real_loss: 0.0033 | d_Y_loss: 0.0022 | d_X_loss: 0.0006 | d_fake_loss: 0.0029 | g_loss: 0.0041\n",
            "Iteration [ 2600/20000] | d_real_loss: 0.0017 | d_Y_loss: 0.0010 | d_X_loss: 0.0005 | d_fake_loss: 0.0015 | g_loss: 0.0065\n",
            "Iteration [ 2610/20000] | d_real_loss: 0.0014 | d_Y_loss: 0.0013 | d_X_loss: 0.0017 | d_fake_loss: 0.0029 | g_loss: 0.0046\n",
            "Iteration [ 2620/20000] | d_real_loss: 0.0012 | d_Y_loss: 0.0013 | d_X_loss: 0.0004 | d_fake_loss: 0.0017 | g_loss: 0.0054\n",
            "Iteration [ 2630/20000] | d_real_loss: 0.0006 | d_Y_loss: 0.0006 | d_X_loss: 0.0006 | d_fake_loss: 0.0013 | g_loss: 0.0066\n",
            "Iteration [ 2640/20000] | d_real_loss: 0.0014 | d_Y_loss: 0.0020 | d_X_loss: 0.0009 | d_fake_loss: 0.0029 | g_loss: 0.0053\n",
            "Iteration [ 2650/20000] | d_real_loss: 0.0031 | d_Y_loss: 0.0010 | d_X_loss: 0.0007 | d_fake_loss: 0.0017 | g_loss: 0.0039\n",
            "Iteration [ 2660/20000] | d_real_loss: 0.0012 | d_Y_loss: 0.0004 | d_X_loss: 0.0007 | d_fake_loss: 0.0012 | g_loss: 0.0041\n",
            "Iteration [ 2670/20000] | d_real_loss: 0.0018 | d_Y_loss: 0.0004 | d_X_loss: 0.0002 | d_fake_loss: 0.0007 | g_loss: 0.0037\n",
            "Iteration [ 2680/20000] | d_real_loss: 0.0008 | d_Y_loss: 0.0003 | d_X_loss: 0.0006 | d_fake_loss: 0.0009 | g_loss: 0.0037\n",
            "Iteration [ 2690/20000] | d_real_loss: 0.0007 | d_Y_loss: 0.0006 | d_X_loss: 0.0002 | d_fake_loss: 0.0008 | g_loss: 0.0036\n",
            "Iteration [ 2700/20000] | d_real_loss: 0.0006 | d_Y_loss: 0.0003 | d_X_loss: 0.0001 | d_fake_loss: 0.0004 | g_loss: 0.0055\n",
            "Iteration [ 2710/20000] | d_real_loss: 0.0006 | d_Y_loss: 0.0001 | d_X_loss: 0.0001 | d_fake_loss: 0.0002 | g_loss: 0.0048\n",
            "Iteration [ 2720/20000] | d_real_loss: 0.0008 | d_Y_loss: 0.0001 | d_X_loss: 0.0002 | d_fake_loss: 0.0003 | g_loss: 0.0034\n",
            "Iteration [ 2730/20000] | d_real_loss: 0.0010 | d_Y_loss: 0.0008 | d_X_loss: 0.0004 | d_fake_loss: 0.0012 | g_loss: 0.0037\n",
            "Iteration [ 2740/20000] | d_real_loss: 0.0007 | d_Y_loss: 0.0005 | d_X_loss: 0.0003 | d_fake_loss: 0.0008 | g_loss: 0.0046\n",
            "Iteration [ 2750/20000] | d_real_loss: 0.0029 | d_Y_loss: 0.0002 | d_X_loss: 0.0040 | d_fake_loss: 0.0041 | g_loss: 0.0036\n",
            "Iteration [ 2760/20000] | d_real_loss: 0.0072 | d_Y_loss: 0.0002 | d_X_loss: 0.0014 | d_fake_loss: 0.0017 | g_loss: 0.0043\n",
            "Iteration [ 2770/20000] | d_real_loss: 0.0034 | d_Y_loss: 0.0003 | d_X_loss: 0.0006 | d_fake_loss: 0.0009 | g_loss: 0.0041\n",
            "Iteration [ 2780/20000] | d_real_loss: 0.0015 | d_Y_loss: 0.0014 | d_X_loss: 0.0003 | d_fake_loss: 0.0017 | g_loss: 0.0040\n",
            "Iteration [ 2790/20000] | d_real_loss: 0.0014 | d_Y_loss: 0.0012 | d_X_loss: 0.0003 | d_fake_loss: 0.0015 | g_loss: 0.0039\n",
            "Iteration [ 2800/20000] | d_real_loss: 0.0029 | d_Y_loss: 0.0035 | d_X_loss: 0.0003 | d_fake_loss: 0.0038 | g_loss: 0.0040\n",
            "Iteration [ 2810/20000] | d_real_loss: 0.0057 | d_Y_loss: 0.0033 | d_X_loss: 0.0015 | d_fake_loss: 0.0048 | g_loss: 0.0040\n",
            "Iteration [ 2820/20000] | d_real_loss: 0.0010 | d_Y_loss: 0.0008 | d_X_loss: 0.0010 | d_fake_loss: 0.0018 | g_loss: 0.0041\n",
            "Iteration [ 2830/20000] | d_real_loss: 0.0007 | d_Y_loss: 0.0018 | d_X_loss: 0.0013 | d_fake_loss: 0.0031 | g_loss: 0.0060\n",
            "Iteration [ 2840/20000] | d_real_loss: 0.0020 | d_Y_loss: 0.0060 | d_X_loss: 0.0006 | d_fake_loss: 0.0066 | g_loss: 0.0039\n",
            "Iteration [ 2850/20000] | d_real_loss: 0.0018 | d_Y_loss: 0.0009 | d_X_loss: 0.0007 | d_fake_loss: 0.0016 | g_loss: 0.0041\n",
            "Iteration [ 2860/20000] | d_real_loss: 0.0014 | d_Y_loss: 0.0002 | d_X_loss: 0.0002 | d_fake_loss: 0.0004 | g_loss: 0.0037\n",
            "Iteration [ 2870/20000] | d_real_loss: 0.0007 | d_Y_loss: 0.0001 | d_X_loss: 0.0003 | d_fake_loss: 0.0004 | g_loss: 0.0035\n",
            "Iteration [ 2880/20000] | d_real_loss: 0.0005 | d_Y_loss: 0.0032 | d_X_loss: 0.0007 | d_fake_loss: 0.0039 | g_loss: 0.0045\n",
            "Iteration [ 2890/20000] | d_real_loss: 0.0015 | d_Y_loss: 0.0019 | d_X_loss: 0.0005 | d_fake_loss: 0.0024 | g_loss: 0.0043\n",
            "Iteration [ 2900/20000] | d_real_loss: 0.0006 | d_Y_loss: 0.0026 | d_X_loss: 0.0007 | d_fake_loss: 0.0033 | g_loss: 0.0036\n",
            "Iteration [ 2910/20000] | d_real_loss: 0.0011 | d_Y_loss: 0.0011 | d_X_loss: 0.0004 | d_fake_loss: 0.0015 | g_loss: 0.0048\n",
            "Iteration [ 2920/20000] | d_real_loss: 0.0017 | d_Y_loss: 0.0004 | d_X_loss: 0.0006 | d_fake_loss: 0.0010 | g_loss: 0.0042\n",
            "Iteration [ 2930/20000] | d_real_loss: 0.0031 | d_Y_loss: 0.0006 | d_X_loss: 0.0003 | d_fake_loss: 0.0009 | g_loss: 0.0036\n",
            "Iteration [ 2940/20000] | d_real_loss: 0.0010 | d_Y_loss: 0.0005 | d_X_loss: 0.0002 | d_fake_loss: 0.0007 | g_loss: 0.0045\n",
            "Iteration [ 2950/20000] | d_real_loss: 0.0024 | d_Y_loss: 0.0032 | d_X_loss: 0.0006 | d_fake_loss: 0.0038 | g_loss: 0.0040\n",
            "Iteration [ 2960/20000] | d_real_loss: 0.0008 | d_Y_loss: 0.0020 | d_X_loss: 0.0005 | d_fake_loss: 0.0025 | g_loss: 0.0043\n",
            "Iteration [ 2970/20000] | d_real_loss: 0.0054 | d_Y_loss: 0.0033 | d_X_loss: 0.0045 | d_fake_loss: 0.0077 | g_loss: 0.0036\n",
            "Iteration [ 2980/20000] | d_real_loss: 0.0033 | d_Y_loss: 0.0001 | d_X_loss: 0.0007 | d_fake_loss: 0.0008 | g_loss: 0.0038\n",
            "Iteration [ 2990/20000] | d_real_loss: 0.0012 | d_Y_loss: 0.0006 | d_X_loss: 0.0009 | d_fake_loss: 0.0014 | g_loss: 0.0034\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float64 to uint8. Range [-1.0, 0.9935336709022522]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration [ 3000/20000] | d_real_loss: 0.0029 | d_Y_loss: 0.0001 | d_X_loss: 0.0005 | d_fake_loss: 0.0007 | g_loss: 0.0036\n",
            "Saved /content/sample-003000-X-Y.png\n",
            "Saved /content/sample-003000-Y-X.png\n",
            "Iteration [ 3010/20000] | d_real_loss: 0.0027 | d_Y_loss: 0.0002 | d_X_loss: 0.0006 | d_fake_loss: 0.0008 | g_loss: 0.0037\n",
            "Iteration [ 3020/20000] | d_real_loss: 0.0011 | d_Y_loss: 0.0001 | d_X_loss: 0.0004 | d_fake_loss: 0.0004 | g_loss: 0.0036\n",
            "Iteration [ 3030/20000] | d_real_loss: 0.0033 | d_Y_loss: 0.0012 | d_X_loss: 0.0004 | d_fake_loss: 0.0017 | g_loss: 0.0036\n",
            "Iteration [ 3040/20000] | d_real_loss: 0.0009 | d_Y_loss: 0.0031 | d_X_loss: 0.0009 | d_fake_loss: 0.0041 | g_loss: 0.0036\n",
            "Iteration [ 3050/20000] | d_real_loss: 0.0039 | d_Y_loss: 0.0002 | d_X_loss: 0.0007 | d_fake_loss: 0.0009 | g_loss: 0.0033\n",
            "Iteration [ 3060/20000] | d_real_loss: 0.0008 | d_Y_loss: 0.0013 | d_X_loss: 0.0004 | d_fake_loss: 0.0018 | g_loss: 0.0032\n",
            "Iteration [ 3070/20000] | d_real_loss: 0.0016 | d_Y_loss: 0.0001 | d_X_loss: 0.0004 | d_fake_loss: 0.0005 | g_loss: 0.0032\n",
            "Iteration [ 3080/20000] | d_real_loss: 0.0013 | d_Y_loss: 0.0001 | d_X_loss: 0.0010 | d_fake_loss: 0.0011 | g_loss: 0.0051\n",
            "Iteration [ 3090/20000] | d_real_loss: 0.0010 | d_Y_loss: 0.0006 | d_X_loss: 0.0005 | d_fake_loss: 0.0011 | g_loss: 0.0049\n",
            "Iteration [ 3100/20000] | d_real_loss: 0.0016 | d_Y_loss: 0.0002 | d_X_loss: 0.0002 | d_fake_loss: 0.0004 | g_loss: 0.0061\n",
            "Iteration [ 3110/20000] | d_real_loss: 0.0029 | d_Y_loss: 0.0022 | d_X_loss: 0.0001 | d_fake_loss: 0.0024 | g_loss: 0.0037\n",
            "Iteration [ 3120/20000] | d_real_loss: 0.0016 | d_Y_loss: 0.0005 | d_X_loss: 0.0004 | d_fake_loss: 0.0010 | g_loss: 0.0045\n",
            "Iteration [ 3130/20000] | d_real_loss: 0.0012 | d_Y_loss: 0.0005 | d_X_loss: 0.0007 | d_fake_loss: 0.0013 | g_loss: 0.0032\n",
            "Iteration [ 3140/20000] | d_real_loss: 0.0010 | d_Y_loss: 0.0002 | d_X_loss: 0.0012 | d_fake_loss: 0.0013 | g_loss: 0.0035\n",
            "Iteration [ 3150/20000] | d_real_loss: 0.0009 | d_Y_loss: 0.0003 | d_X_loss: 0.0001 | d_fake_loss: 0.0005 | g_loss: 0.0032\n",
            "Iteration [ 3160/20000] | d_real_loss: 0.0005 | d_Y_loss: 0.0002 | d_X_loss: 0.0004 | d_fake_loss: 0.0005 | g_loss: 0.0036\n",
            "Iteration [ 3170/20000] | d_real_loss: 0.0017 | d_Y_loss: 0.0022 | d_X_loss: 0.0005 | d_fake_loss: 0.0027 | g_loss: 0.0046\n",
            "Iteration [ 3180/20000] | d_real_loss: 0.0006 | d_Y_loss: 0.0002 | d_X_loss: 0.0003 | d_fake_loss: 0.0005 | g_loss: 0.0031\n",
            "Iteration [ 3190/20000] | d_real_loss: 0.0007 | d_Y_loss: 0.0002 | d_X_loss: 0.0001 | d_fake_loss: 0.0004 | g_loss: 0.0042\n",
            "Iteration [ 3200/20000] | d_real_loss: 0.0017 | d_Y_loss: 0.0006 | d_X_loss: 0.0008 | d_fake_loss: 0.0014 | g_loss: 0.0040\n",
            "Iteration [ 3210/20000] | d_real_loss: 0.0031 | d_Y_loss: 0.0021 | d_X_loss: 0.0010 | d_fake_loss: 0.0031 | g_loss: 0.0034\n",
            "Iteration [ 3220/20000] | d_real_loss: 0.0008 | d_Y_loss: 0.0006 | d_X_loss: 0.0016 | d_fake_loss: 0.0022 | g_loss: 0.0057\n",
            "Iteration [ 3230/20000] | d_real_loss: 0.0005 | d_Y_loss: 0.0001 | d_X_loss: 0.0006 | d_fake_loss: 0.0008 | g_loss: 0.0029\n",
            "Iteration [ 3240/20000] | d_real_loss: 0.0011 | d_Y_loss: 0.0001 | d_X_loss: 0.0019 | d_fake_loss: 0.0020 | g_loss: 0.0035\n",
            "Iteration [ 3250/20000] | d_real_loss: 0.0016 | d_Y_loss: 0.0024 | d_X_loss: 0.0004 | d_fake_loss: 0.0028 | g_loss: 0.0037\n",
            "Iteration [ 3260/20000] | d_real_loss: 0.0012 | d_Y_loss: 0.0003 | d_X_loss: 0.0002 | d_fake_loss: 0.0004 | g_loss: 0.0033\n",
            "Iteration [ 3270/20000] | d_real_loss: 0.0017 | d_Y_loss: 0.0008 | d_X_loss: 0.0017 | d_fake_loss: 0.0025 | g_loss: 0.0031\n",
            "Iteration [ 3280/20000] | d_real_loss: 0.0025 | d_Y_loss: 0.0016 | d_X_loss: 0.0010 | d_fake_loss: 0.0027 | g_loss: 0.0053\n",
            "Iteration [ 3290/20000] | d_real_loss: 0.0024 | d_Y_loss: 0.0007 | d_X_loss: 0.0011 | d_fake_loss: 0.0018 | g_loss: 0.0037\n",
            "Iteration [ 3300/20000] | d_real_loss: 0.0017 | d_Y_loss: 0.0019 | d_X_loss: 0.0005 | d_fake_loss: 0.0024 | g_loss: 0.0032\n",
            "Iteration [ 3310/20000] | d_real_loss: 0.0007 | d_Y_loss: 0.0008 | d_X_loss: 0.0003 | d_fake_loss: 0.0011 | g_loss: 0.0031\n",
            "Iteration [ 3320/20000] | d_real_loss: 0.0022 | d_Y_loss: 0.0010 | d_X_loss: 0.0003 | d_fake_loss: 0.0012 | g_loss: 0.0033\n",
            "Iteration [ 3330/20000] | d_real_loss: 0.0008 | d_Y_loss: 0.0001 | d_X_loss: 0.0002 | d_fake_loss: 0.0004 | g_loss: 0.0033\n",
            "Iteration [ 3340/20000] | d_real_loss: 0.0007 | d_Y_loss: 0.0005 | d_X_loss: 0.0003 | d_fake_loss: 0.0008 | g_loss: 0.0078\n",
            "Iteration [ 3350/20000] | d_real_loss: 0.0010 | d_Y_loss: 0.0014 | d_X_loss: 0.0004 | d_fake_loss: 0.0018 | g_loss: 0.0034\n",
            "Iteration [ 3360/20000] | d_real_loss: 0.0007 | d_Y_loss: 0.0032 | d_X_loss: 0.0002 | d_fake_loss: 0.0034 | g_loss: 0.0037\n",
            "Iteration [ 3370/20000] | d_real_loss: 0.0008 | d_Y_loss: 0.0029 | d_X_loss: 0.0004 | d_fake_loss: 0.0033 | g_loss: 0.0031\n",
            "Iteration [ 3380/20000] | d_real_loss: 0.0013 | d_Y_loss: 0.0002 | d_X_loss: 0.0003 | d_fake_loss: 0.0005 | g_loss: 0.0039\n",
            "Iteration [ 3390/20000] | d_real_loss: 0.0020 | d_Y_loss: 0.0019 | d_X_loss: 0.0008 | d_fake_loss: 0.0027 | g_loss: 0.0032\n",
            "Iteration [ 3400/20000] | d_real_loss: 0.0047 | d_Y_loss: 0.0019 | d_X_loss: 0.0005 | d_fake_loss: 0.0025 | g_loss: 0.0035\n",
            "Iteration [ 3410/20000] | d_real_loss: 0.0014 | d_Y_loss: 0.0001 | d_X_loss: 0.0006 | d_fake_loss: 0.0007 | g_loss: 0.0030\n",
            "Iteration [ 3420/20000] | d_real_loss: 0.0012 | d_Y_loss: 0.0010 | d_X_loss: 0.0010 | d_fake_loss: 0.0020 | g_loss: 0.0043\n",
            "Iteration [ 3430/20000] | d_real_loss: 0.0006 | d_Y_loss: 0.0008 | d_X_loss: 0.0003 | d_fake_loss: 0.0012 | g_loss: 0.0041\n",
            "Iteration [ 3440/20000] | d_real_loss: 0.0036 | d_Y_loss: 0.0027 | d_X_loss: 0.0005 | d_fake_loss: 0.0032 | g_loss: 0.0035\n",
            "Iteration [ 3450/20000] | d_real_loss: 0.0007 | d_Y_loss: 0.0027 | d_X_loss: 0.0005 | d_fake_loss: 0.0032 | g_loss: 0.0033\n",
            "Iteration [ 3460/20000] | d_real_loss: 0.0029 | d_Y_loss: 0.0003 | d_X_loss: 0.0007 | d_fake_loss: 0.0009 | g_loss: 0.0034\n",
            "Iteration [ 3470/20000] | d_real_loss: 0.0017 | d_Y_loss: 0.0001 | d_X_loss: 0.0018 | d_fake_loss: 0.0019 | g_loss: 0.0030\n",
            "Iteration [ 3480/20000] | d_real_loss: 0.0009 | d_Y_loss: 0.0001 | d_X_loss: 0.0004 | d_fake_loss: 0.0004 | g_loss: 0.0051\n",
            "Iteration [ 3490/20000] | d_real_loss: 0.0041 | d_Y_loss: 0.0004 | d_X_loss: 0.0020 | d_fake_loss: 0.0023 | g_loss: 0.0030\n",
            "Iteration [ 3500/20000] | d_real_loss: 0.0012 | d_Y_loss: 0.0001 | d_X_loss: 0.0004 | d_fake_loss: 0.0005 | g_loss: 0.0035\n",
            "Iteration [ 3510/20000] | d_real_loss: 0.0012 | d_Y_loss: 0.0001 | d_X_loss: 0.0003 | d_fake_loss: 0.0004 | g_loss: 0.0037\n",
            "Iteration [ 3520/20000] | d_real_loss: 0.0014 | d_Y_loss: 0.0004 | d_X_loss: 0.0007 | d_fake_loss: 0.0011 | g_loss: 0.0037\n",
            "Iteration [ 3530/20000] | d_real_loss: 0.0012 | d_Y_loss: 0.0011 | d_X_loss: 0.0005 | d_fake_loss: 0.0016 | g_loss: 0.0034\n",
            "Iteration [ 3540/20000] | d_real_loss: 0.0011 | d_Y_loss: 0.0004 | d_X_loss: 0.0011 | d_fake_loss: 0.0015 | g_loss: 0.0039\n",
            "Iteration [ 3550/20000] | d_real_loss: 0.0014 | d_Y_loss: 0.0029 | d_X_loss: 0.0004 | d_fake_loss: 0.0033 | g_loss: 0.0027\n",
            "Iteration [ 3560/20000] | d_real_loss: 0.0012 | d_Y_loss: 0.0034 | d_X_loss: 0.0005 | d_fake_loss: 0.0038 | g_loss: 0.0032\n",
            "Iteration [ 3570/20000] | d_real_loss: 0.0019 | d_Y_loss: 0.0008 | d_X_loss: 0.0001 | d_fake_loss: 0.0009 | g_loss: 0.0029\n",
            "Iteration [ 3580/20000] | d_real_loss: 0.0022 | d_Y_loss: 0.0024 | d_X_loss: 0.0004 | d_fake_loss: 0.0029 | g_loss: 0.0029\n",
            "Iteration [ 3590/20000] | d_real_loss: 0.0013 | d_Y_loss: 0.0009 | d_X_loss: 0.0001 | d_fake_loss: 0.0010 | g_loss: 0.0051\n",
            "Iteration [ 3600/20000] | d_real_loss: 0.0022 | d_Y_loss: 0.0002 | d_X_loss: 0.0003 | d_fake_loss: 0.0005 | g_loss: 0.0034\n",
            "Iteration [ 3610/20000] | d_real_loss: 0.0013 | d_Y_loss: 0.0080 | d_X_loss: 0.0001 | d_fake_loss: 0.0082 | g_loss: 0.0031\n",
            "Iteration [ 3620/20000] | d_real_loss: 0.0008 | d_Y_loss: 0.0022 | d_X_loss: 0.0004 | d_fake_loss: 0.0026 | g_loss: 0.0041\n",
            "Iteration [ 3630/20000] | d_real_loss: 0.0038 | d_Y_loss: 0.0005 | d_X_loss: 0.0001 | d_fake_loss: 0.0006 | g_loss: 0.0034\n",
            "Iteration [ 3640/20000] | d_real_loss: 0.0020 | d_Y_loss: 0.0002 | d_X_loss: 0.0002 | d_fake_loss: 0.0004 | g_loss: 0.0033\n",
            "Iteration [ 3650/20000] | d_real_loss: 0.0021 | d_Y_loss: 0.0002 | d_X_loss: 0.0008 | d_fake_loss: 0.0009 | g_loss: 0.0030\n",
            "Iteration [ 3660/20000] | d_real_loss: 0.0010 | d_Y_loss: 0.0002 | d_X_loss: 0.0007 | d_fake_loss: 0.0009 | g_loss: 0.0031\n",
            "Iteration [ 3670/20000] | d_real_loss: 0.0005 | d_Y_loss: 0.0000 | d_X_loss: 0.0002 | d_fake_loss: 0.0003 | g_loss: 0.0030\n",
            "Iteration [ 3680/20000] | d_real_loss: 0.0019 | d_Y_loss: 0.0004 | d_X_loss: 0.0003 | d_fake_loss: 0.0006 | g_loss: 0.0030\n",
            "Iteration [ 3690/20000] | d_real_loss: 0.0018 | d_Y_loss: 0.0015 | d_X_loss: 0.0010 | d_fake_loss: 0.0025 | g_loss: 0.0027\n",
            "Iteration [ 3700/20000] | d_real_loss: 0.0010 | d_Y_loss: 0.0004 | d_X_loss: 0.0001 | d_fake_loss: 0.0005 | g_loss: 0.0029\n",
            "Iteration [ 3710/20000] | d_real_loss: 0.0013 | d_Y_loss: 0.0002 | d_X_loss: 0.0008 | d_fake_loss: 0.0010 | g_loss: 0.0032\n",
            "Iteration [ 3720/20000] | d_real_loss: 0.0009 | d_Y_loss: 0.0028 | d_X_loss: 0.0003 | d_fake_loss: 0.0031 | g_loss: 0.0040\n",
            "Iteration [ 3730/20000] | d_real_loss: 0.0017 | d_Y_loss: 0.0010 | d_X_loss: 0.0002 | d_fake_loss: 0.0011 | g_loss: 0.0028\n",
            "Iteration [ 3740/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0002 | d_X_loss: 0.0001 | d_fake_loss: 0.0002 | g_loss: 0.0033\n",
            "Iteration [ 3750/20000] | d_real_loss: 0.0006 | d_Y_loss: 0.0002 | d_X_loss: 0.0000 | d_fake_loss: 0.0002 | g_loss: 0.0027\n",
            "Iteration [ 3760/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0002 | d_X_loss: 0.0001 | d_fake_loss: 0.0003 | g_loss: 0.0036\n",
            "Iteration [ 3770/20000] | d_real_loss: 0.0021 | d_Y_loss: 0.0014 | d_X_loss: 0.0008 | d_fake_loss: 0.0022 | g_loss: 0.0029\n",
            "Iteration [ 3780/20000] | d_real_loss: 0.0075 | d_Y_loss: 0.0007 | d_X_loss: 0.0005 | d_fake_loss: 0.0012 | g_loss: 0.0037\n",
            "Iteration [ 3790/20000] | d_real_loss: 0.0029 | d_Y_loss: 0.0030 | d_X_loss: 0.0020 | d_fake_loss: 0.0050 | g_loss: 0.0031\n",
            "Iteration [ 3800/20000] | d_real_loss: 0.0037 | d_Y_loss: 0.0003 | d_X_loss: 0.0017 | d_fake_loss: 0.0020 | g_loss: 0.0051\n",
            "Iteration [ 3810/20000] | d_real_loss: 0.0007 | d_Y_loss: 0.0013 | d_X_loss: 0.0005 | d_fake_loss: 0.0018 | g_loss: 0.0027\n",
            "Iteration [ 3820/20000] | d_real_loss: 0.0006 | d_Y_loss: 0.0005 | d_X_loss: 0.0003 | d_fake_loss: 0.0008 | g_loss: 0.0041\n",
            "Iteration [ 3830/20000] | d_real_loss: 0.0011 | d_Y_loss: 0.0004 | d_X_loss: 0.0006 | d_fake_loss: 0.0010 | g_loss: 0.0048\n",
            "Iteration [ 3840/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0034 | d_X_loss: 0.0005 | d_fake_loss: 0.0039 | g_loss: 0.0031\n",
            "Iteration [ 3850/20000] | d_real_loss: 0.0008 | d_Y_loss: 0.0032 | d_X_loss: 0.0004 | d_fake_loss: 0.0036 | g_loss: 0.0037\n",
            "Iteration [ 3860/20000] | d_real_loss: 0.0026 | d_Y_loss: 0.0042 | d_X_loss: 0.0005 | d_fake_loss: 0.0047 | g_loss: 0.0031\n",
            "Iteration [ 3870/20000] | d_real_loss: 0.0008 | d_Y_loss: 0.0015 | d_X_loss: 0.0012 | d_fake_loss: 0.0027 | g_loss: 0.0034\n",
            "Iteration [ 3880/20000] | d_real_loss: 0.0015 | d_Y_loss: 0.0003 | d_X_loss: 0.0001 | d_fake_loss: 0.0004 | g_loss: 0.0028\n",
            "Iteration [ 3890/20000] | d_real_loss: 0.0010 | d_Y_loss: 0.0004 | d_X_loss: 0.0001 | d_fake_loss: 0.0005 | g_loss: 0.0029\n",
            "Iteration [ 3900/20000] | d_real_loss: 0.0025 | d_Y_loss: 0.0013 | d_X_loss: 0.0005 | d_fake_loss: 0.0018 | g_loss: 0.0034\n",
            "Iteration [ 3910/20000] | d_real_loss: 0.0019 | d_Y_loss: 0.0006 | d_X_loss: 0.0003 | d_fake_loss: 0.0009 | g_loss: 0.0035\n",
            "Iteration [ 3920/20000] | d_real_loss: 0.0018 | d_Y_loss: 0.0012 | d_X_loss: 0.0005 | d_fake_loss: 0.0017 | g_loss: 0.0035\n",
            "Iteration [ 3930/20000] | d_real_loss: 0.0010 | d_Y_loss: 0.0001 | d_X_loss: 0.0001 | d_fake_loss: 0.0003 | g_loss: 0.0029\n",
            "Iteration [ 3940/20000] | d_real_loss: 0.0005 | d_Y_loss: 0.0004 | d_X_loss: 0.0001 | d_fake_loss: 0.0006 | g_loss: 0.0027\n",
            "Iteration [ 3950/20000] | d_real_loss: 0.0010 | d_Y_loss: 0.0003 | d_X_loss: 0.0003 | d_fake_loss: 0.0005 | g_loss: 0.0028\n",
            "Iteration [ 3960/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0006 | d_X_loss: 0.0002 | d_fake_loss: 0.0008 | g_loss: 0.0048\n",
            "Iteration [ 3970/20000] | d_real_loss: 0.0020 | d_Y_loss: 0.0008 | d_X_loss: 0.0002 | d_fake_loss: 0.0010 | g_loss: 0.0048\n",
            "Iteration [ 3980/20000] | d_real_loss: 0.0017 | d_Y_loss: 0.0001 | d_X_loss: 0.0005 | d_fake_loss: 0.0007 | g_loss: 0.0043\n",
            "Iteration [ 3990/20000] | d_real_loss: 0.0007 | d_Y_loss: 0.0003 | d_X_loss: 0.0004 | d_fake_loss: 0.0007 | g_loss: 0.0038\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration [ 4000/20000] | d_real_loss: 0.0009 | d_Y_loss: 0.0003 | d_X_loss: 0.0001 | d_fake_loss: 0.0004 | g_loss: 0.0037\n",
            "Saved /content/sample-004000-X-Y.png\n",
            "Saved /content/sample-004000-Y-X.png\n",
            "Iteration [ 4010/20000] | d_real_loss: 0.0009 | d_Y_loss: 0.0001 | d_X_loss: 0.0001 | d_fake_loss: 0.0002 | g_loss: 0.0028\n",
            "Iteration [ 4020/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0006 | d_X_loss: 0.0002 | d_fake_loss: 0.0008 | g_loss: 0.0030\n",
            "Iteration [ 4030/20000] | d_real_loss: 0.0005 | d_Y_loss: 0.0008 | d_X_loss: 0.0003 | d_fake_loss: 0.0011 | g_loss: 0.0027\n",
            "Iteration [ 4040/20000] | d_real_loss: 0.0014 | d_Y_loss: 0.0043 | d_X_loss: 0.0009 | d_fake_loss: 0.0052 | g_loss: 0.0030\n",
            "Iteration [ 4050/20000] | d_real_loss: 0.0008 | d_Y_loss: 0.0002 | d_X_loss: 0.0003 | d_fake_loss: 0.0004 | g_loss: 0.0025\n",
            "Iteration [ 4060/20000] | d_real_loss: 0.0005 | d_Y_loss: 0.0003 | d_X_loss: 0.0004 | d_fake_loss: 0.0007 | g_loss: 0.0024\n",
            "Iteration [ 4070/20000] | d_real_loss: 0.0008 | d_Y_loss: 0.0002 | d_X_loss: 0.0001 | d_fake_loss: 0.0004 | g_loss: 0.0038\n",
            "Iteration [ 4080/20000] | d_real_loss: 0.0009 | d_Y_loss: 0.0001 | d_X_loss: 0.0001 | d_fake_loss: 0.0002 | g_loss: 0.0031\n",
            "Iteration [ 4090/20000] | d_real_loss: 0.0011 | d_Y_loss: 0.0001 | d_X_loss: 0.0017 | d_fake_loss: 0.0018 | g_loss: 0.0029\n",
            "Iteration [ 4100/20000] | d_real_loss: 0.0085 | d_Y_loss: 0.0003 | d_X_loss: 0.0026 | d_fake_loss: 0.0029 | g_loss: 0.0026\n",
            "Iteration [ 4110/20000] | d_real_loss: 0.0066 | d_Y_loss: 0.0019 | d_X_loss: 0.0020 | d_fake_loss: 0.0039 | g_loss: 0.0030\n",
            "Iteration [ 4120/20000] | d_real_loss: 0.0007 | d_Y_loss: 0.0039 | d_X_loss: 0.0016 | d_fake_loss: 0.0055 | g_loss: 0.0029\n",
            "Iteration [ 4130/20000] | d_real_loss: 0.0014 | d_Y_loss: 0.0012 | d_X_loss: 0.0004 | d_fake_loss: 0.0016 | g_loss: 0.0050\n",
            "Iteration [ 4140/20000] | d_real_loss: 0.0017 | d_Y_loss: 0.0029 | d_X_loss: 0.0011 | d_fake_loss: 0.0039 | g_loss: 0.0038\n",
            "Iteration [ 4150/20000] | d_real_loss: 0.0033 | d_Y_loss: 0.0031 | d_X_loss: 0.0003 | d_fake_loss: 0.0034 | g_loss: 0.0037\n",
            "Iteration [ 4160/20000] | d_real_loss: 0.0030 | d_Y_loss: 0.0002 | d_X_loss: 0.0003 | d_fake_loss: 0.0005 | g_loss: 0.0038\n",
            "Iteration [ 4170/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0001 | d_X_loss: 0.0004 | d_fake_loss: 0.0005 | g_loss: 0.0032\n",
            "Iteration [ 4180/20000] | d_real_loss: 0.0005 | d_Y_loss: 0.0001 | d_X_loss: 0.0002 | d_fake_loss: 0.0002 | g_loss: 0.0025\n",
            "Iteration [ 4190/20000] | d_real_loss: 0.0014 | d_Y_loss: 0.0006 | d_X_loss: 0.0006 | d_fake_loss: 0.0012 | g_loss: 0.0027\n",
            "Iteration [ 4200/20000] | d_real_loss: 0.0015 | d_Y_loss: 0.0003 | d_X_loss: 0.0004 | d_fake_loss: 0.0007 | g_loss: 0.0035\n",
            "Iteration [ 4210/20000] | d_real_loss: 0.0006 | d_Y_loss: 0.0001 | d_X_loss: 0.0002 | d_fake_loss: 0.0003 | g_loss: 0.0034\n",
            "Iteration [ 4220/20000] | d_real_loss: 0.0019 | d_Y_loss: 0.0010 | d_X_loss: 0.0001 | d_fake_loss: 0.0012 | g_loss: 0.0023\n",
            "Iteration [ 4230/20000] | d_real_loss: 0.0010 | d_Y_loss: 0.0001 | d_X_loss: 0.0004 | d_fake_loss: 0.0006 | g_loss: 0.0025\n",
            "Iteration [ 4240/20000] | d_real_loss: 0.0012 | d_Y_loss: 0.0003 | d_X_loss: 0.0002 | d_fake_loss: 0.0005 | g_loss: 0.0024\n",
            "Iteration [ 4250/20000] | d_real_loss: 0.0007 | d_Y_loss: 0.0001 | d_X_loss: 0.0001 | d_fake_loss: 0.0002 | g_loss: 0.0028\n",
            "Iteration [ 4260/20000] | d_real_loss: 0.0005 | d_Y_loss: 0.0001 | d_X_loss: 0.0003 | d_fake_loss: 0.0003 | g_loss: 0.0024\n",
            "Iteration [ 4270/20000] | d_real_loss: 0.0010 | d_Y_loss: 0.0004 | d_X_loss: 0.0003 | d_fake_loss: 0.0007 | g_loss: 0.0027\n",
            "Iteration [ 4280/20000] | d_real_loss: 0.0010 | d_Y_loss: 0.0005 | d_X_loss: 0.0009 | d_fake_loss: 0.0014 | g_loss: 0.0027\n",
            "Iteration [ 4290/20000] | d_real_loss: 0.0012 | d_Y_loss: 0.0001 | d_X_loss: 0.0002 | d_fake_loss: 0.0003 | g_loss: 0.0025\n",
            "Iteration [ 4300/20000] | d_real_loss: 0.0009 | d_Y_loss: 0.0004 | d_X_loss: 0.0007 | d_fake_loss: 0.0011 | g_loss: 0.0028\n",
            "Iteration [ 4310/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0030\n",
            "Iteration [ 4320/20000] | d_real_loss: 0.0005 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0027\n",
            "Iteration [ 4330/20000] | d_real_loss: 0.0007 | d_Y_loss: 0.0003 | d_X_loss: 0.0001 | d_fake_loss: 0.0004 | g_loss: 0.0026\n",
            "Iteration [ 4340/20000] | d_real_loss: 0.0014 | d_Y_loss: 0.0000 | d_X_loss: 0.0003 | d_fake_loss: 0.0003 | g_loss: 0.0032\n",
            "Iteration [ 4350/20000] | d_real_loss: 0.0007 | d_Y_loss: 0.0003 | d_X_loss: 0.0001 | d_fake_loss: 0.0004 | g_loss: 0.0025\n",
            "Iteration [ 4360/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0004 | d_X_loss: 0.0002 | d_fake_loss: 0.0006 | g_loss: 0.0025\n",
            "Iteration [ 4370/20000] | d_real_loss: 0.0012 | d_Y_loss: 0.0006 | d_X_loss: 0.0007 | d_fake_loss: 0.0014 | g_loss: 0.0028\n",
            "Iteration [ 4380/20000] | d_real_loss: 0.0014 | d_Y_loss: 0.0001 | d_X_loss: 0.0003 | d_fake_loss: 0.0004 | g_loss: 0.0036\n",
            "Iteration [ 4390/20000] | d_real_loss: 0.0009 | d_Y_loss: 0.0003 | d_X_loss: 0.0001 | d_fake_loss: 0.0004 | g_loss: 0.0024\n",
            "Iteration [ 4400/20000] | d_real_loss: 0.0011 | d_Y_loss: 0.0002 | d_X_loss: 0.0001 | d_fake_loss: 0.0003 | g_loss: 0.0032\n",
            "Iteration [ 4410/20000] | d_real_loss: 0.0032 | d_Y_loss: 0.0009 | d_X_loss: 0.0006 | d_fake_loss: 0.0015 | g_loss: 0.0034\n",
            "Iteration [ 4420/20000] | d_real_loss: 0.0054 | d_Y_loss: 0.0010 | d_X_loss: 0.0002 | d_fake_loss: 0.0012 | g_loss: 0.0031\n",
            "Iteration [ 4430/20000] | d_real_loss: 0.0027 | d_Y_loss: 0.0014 | d_X_loss: 0.0003 | d_fake_loss: 0.0017 | g_loss: 0.0029\n",
            "Iteration [ 4440/20000] | d_real_loss: 0.0030 | d_Y_loss: 0.0027 | d_X_loss: 0.0007 | d_fake_loss: 0.0034 | g_loss: 0.0030\n",
            "Iteration [ 4450/20000] | d_real_loss: 0.0012 | d_Y_loss: 0.0031 | d_X_loss: 0.0005 | d_fake_loss: 0.0036 | g_loss: 0.0031\n",
            "Iteration [ 4460/20000] | d_real_loss: 0.0010 | d_Y_loss: 0.0001 | d_X_loss: 0.0006 | d_fake_loss: 0.0006 | g_loss: 0.0031\n",
            "Iteration [ 4470/20000] | d_real_loss: 0.0010 | d_Y_loss: 0.0001 | d_X_loss: 0.0003 | d_fake_loss: 0.0004 | g_loss: 0.0025\n",
            "Iteration [ 4480/20000] | d_real_loss: 0.0009 | d_Y_loss: 0.0003 | d_X_loss: 0.0006 | d_fake_loss: 0.0008 | g_loss: 0.0023\n",
            "Iteration [ 4490/20000] | d_real_loss: 0.0014 | d_Y_loss: 0.0006 | d_X_loss: 0.0002 | d_fake_loss: 0.0008 | g_loss: 0.0027\n",
            "Iteration [ 4500/20000] | d_real_loss: 0.0007 | d_Y_loss: 0.0002 | d_X_loss: 0.0004 | d_fake_loss: 0.0006 | g_loss: 0.0023\n",
            "Iteration [ 4510/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0001 | d_X_loss: 0.0003 | d_fake_loss: 0.0004 | g_loss: 0.0023\n",
            "Iteration [ 4520/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0003 | d_X_loss: 0.0002 | d_fake_loss: 0.0005 | g_loss: 0.0023\n",
            "Iteration [ 4530/20000] | d_real_loss: 0.0013 | d_Y_loss: 0.0001 | d_X_loss: 0.0002 | d_fake_loss: 0.0003 | g_loss: 0.0031\n",
            "Iteration [ 4540/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0018 | d_X_loss: 0.0001 | d_fake_loss: 0.0019 | g_loss: 0.0023\n",
            "Iteration [ 4550/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0004 | d_X_loss: 0.0001 | d_fake_loss: 0.0005 | g_loss: 0.0024\n",
            "Iteration [ 4560/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0001 | d_X_loss: 0.0005 | d_fake_loss: 0.0005 | g_loss: 0.0034\n",
            "Iteration [ 4570/20000] | d_real_loss: 0.0005 | d_Y_loss: 0.0010 | d_X_loss: 0.0003 | d_fake_loss: 0.0013 | g_loss: 0.0024\n",
            "Iteration [ 4580/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0002 | d_X_loss: 0.0001 | d_fake_loss: 0.0003 | g_loss: 0.0026\n",
            "Iteration [ 4590/20000] | d_real_loss: 0.0006 | d_Y_loss: 0.0009 | d_X_loss: 0.0006 | d_fake_loss: 0.0014 | g_loss: 0.0026\n",
            "Iteration [ 4600/20000] | d_real_loss: 0.0011 | d_Y_loss: 0.0007 | d_X_loss: 0.0004 | d_fake_loss: 0.0011 | g_loss: 0.0029\n",
            "Iteration [ 4610/20000] | d_real_loss: 0.0041 | d_Y_loss: 0.0021 | d_X_loss: 0.0048 | d_fake_loss: 0.0069 | g_loss: 0.0025\n",
            "Iteration [ 4620/20000] | d_real_loss: 0.0073 | d_Y_loss: 0.0035 | d_X_loss: 0.0012 | d_fake_loss: 0.0047 | g_loss: 0.0037\n",
            "Iteration [ 4630/20000] | d_real_loss: 0.0039 | d_Y_loss: 0.0024 | d_X_loss: 0.0007 | d_fake_loss: 0.0031 | g_loss: 0.0037\n",
            "Iteration [ 4640/20000] | d_real_loss: 0.0021 | d_Y_loss: 0.0037 | d_X_loss: 0.0030 | d_fake_loss: 0.0067 | g_loss: 0.0025\n",
            "Iteration [ 4650/20000] | d_real_loss: 0.0024 | d_Y_loss: 0.0001 | d_X_loss: 0.0013 | d_fake_loss: 0.0014 | g_loss: 0.0046\n",
            "Iteration [ 4660/20000] | d_real_loss: 0.0008 | d_Y_loss: 0.0001 | d_X_loss: 0.0002 | d_fake_loss: 0.0003 | g_loss: 0.0024\n",
            "Iteration [ 4670/20000] | d_real_loss: 0.0008 | d_Y_loss: 0.0005 | d_X_loss: 0.0006 | d_fake_loss: 0.0011 | g_loss: 0.0033\n",
            "Iteration [ 4680/20000] | d_real_loss: 0.0007 | d_Y_loss: 0.0001 | d_X_loss: 0.0004 | d_fake_loss: 0.0005 | g_loss: 0.0032\n",
            "Iteration [ 4690/20000] | d_real_loss: 0.0005 | d_Y_loss: 0.0004 | d_X_loss: 0.0002 | d_fake_loss: 0.0007 | g_loss: 0.0024\n",
            "Iteration [ 4700/20000] | d_real_loss: 0.0014 | d_Y_loss: 0.0006 | d_X_loss: 0.0002 | d_fake_loss: 0.0008 | g_loss: 0.0023\n",
            "Iteration [ 4710/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0002 | g_loss: 0.0037\n",
            "Iteration [ 4720/20000] | d_real_loss: 0.0007 | d_Y_loss: 0.0008 | d_X_loss: 0.0001 | d_fake_loss: 0.0009 | g_loss: 0.0041\n",
            "Iteration [ 4730/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0010 | d_X_loss: 0.0004 | d_fake_loss: 0.0014 | g_loss: 0.0027\n",
            "Iteration [ 4740/20000] | d_real_loss: 0.0006 | d_Y_loss: 0.0001 | d_X_loss: 0.0002 | d_fake_loss: 0.0003 | g_loss: 0.0026\n",
            "Iteration [ 4750/20000] | d_real_loss: 0.0008 | d_Y_loss: 0.0001 | d_X_loss: 0.0003 | d_fake_loss: 0.0004 | g_loss: 0.0023\n",
            "Iteration [ 4760/20000] | d_real_loss: 0.0010 | d_Y_loss: 0.0001 | d_X_loss: 0.0001 | d_fake_loss: 0.0003 | g_loss: 0.0036\n",
            "Iteration [ 4770/20000] | d_real_loss: 0.0008 | d_Y_loss: 0.0007 | d_X_loss: 0.0001 | d_fake_loss: 0.0008 | g_loss: 0.0027\n",
            "Iteration [ 4780/20000] | d_real_loss: 0.0006 | d_Y_loss: 0.0026 | d_X_loss: 0.0001 | d_fake_loss: 0.0027 | g_loss: 0.0025\n",
            "Iteration [ 4790/20000] | d_real_loss: 0.0018 | d_Y_loss: 0.0001 | d_X_loss: 0.0002 | d_fake_loss: 0.0003 | g_loss: 0.0027\n",
            "Iteration [ 4800/20000] | d_real_loss: 0.0014 | d_Y_loss: 0.0010 | d_X_loss: 0.0001 | d_fake_loss: 0.0011 | g_loss: 0.0031\n",
            "Iteration [ 4810/20000] | d_real_loss: 0.0008 | d_Y_loss: 0.0038 | d_X_loss: 0.0001 | d_fake_loss: 0.0039 | g_loss: 0.0025\n",
            "Iteration [ 4820/20000] | d_real_loss: 0.0013 | d_Y_loss: 0.0023 | d_X_loss: 0.0006 | d_fake_loss: 0.0028 | g_loss: 0.0029\n",
            "Iteration [ 4830/20000] | d_real_loss: 0.0009 | d_Y_loss: 0.0007 | d_X_loss: 0.0001 | d_fake_loss: 0.0008 | g_loss: 0.0030\n",
            "Iteration [ 4840/20000] | d_real_loss: 0.0007 | d_Y_loss: 0.0002 | d_X_loss: 0.0001 | d_fake_loss: 0.0003 | g_loss: 0.0024\n",
            "Iteration [ 4850/20000] | d_real_loss: 0.0006 | d_Y_loss: 0.0003 | d_X_loss: 0.0001 | d_fake_loss: 0.0004 | g_loss: 0.0022\n",
            "Iteration [ 4860/20000] | d_real_loss: 0.0005 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0036\n",
            "Iteration [ 4870/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0001 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0022\n",
            "Iteration [ 4880/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0001 | d_X_loss: 0.0001 | d_fake_loss: 0.0002 | g_loss: 0.0026\n",
            "Iteration [ 4890/20000] | d_real_loss: 0.0005 | d_Y_loss: 0.0008 | d_X_loss: 0.0001 | d_fake_loss: 0.0008 | g_loss: 0.0031\n",
            "Iteration [ 4900/20000] | d_real_loss: 0.0008 | d_Y_loss: 0.0011 | d_X_loss: 0.0001 | d_fake_loss: 0.0013 | g_loss: 0.0024\n",
            "Iteration [ 4910/20000] | d_real_loss: 0.0015 | d_Y_loss: 0.0008 | d_X_loss: 0.0001 | d_fake_loss: 0.0009 | g_loss: 0.0022\n",
            "Iteration [ 4920/20000] | d_real_loss: 0.0017 | d_Y_loss: 0.0005 | d_X_loss: 0.0009 | d_fake_loss: 0.0014 | g_loss: 0.0024\n",
            "Iteration [ 4930/20000] | d_real_loss: 0.0014 | d_Y_loss: 0.0001 | d_X_loss: 0.0013 | d_fake_loss: 0.0014 | g_loss: 0.0024\n",
            "Iteration [ 4940/20000] | d_real_loss: 0.0054 | d_Y_loss: 0.0000 | d_X_loss: 0.0010 | d_fake_loss: 0.0010 | g_loss: 0.0022\n",
            "Iteration [ 4950/20000] | d_real_loss: 0.0011 | d_Y_loss: 0.0001 | d_X_loss: 0.0013 | d_fake_loss: 0.0014 | g_loss: 0.0025\n",
            "Iteration [ 4960/20000] | d_real_loss: 0.0044 | d_Y_loss: 0.0004 | d_X_loss: 0.0012 | d_fake_loss: 0.0016 | g_loss: 0.0035\n",
            "Iteration [ 4970/20000] | d_real_loss: 0.0009 | d_Y_loss: 0.0012 | d_X_loss: 0.0003 | d_fake_loss: 0.0015 | g_loss: 0.0025\n",
            "Iteration [ 4980/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0002 | d_X_loss: 0.0001 | d_fake_loss: 0.0003 | g_loss: 0.0027\n",
            "Iteration [ 4990/20000] | d_real_loss: 0.0008 | d_Y_loss: 0.0005 | d_X_loss: 0.0002 | d_fake_loss: 0.0007 | g_loss: 0.0024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration [ 5000/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0001 | d_X_loss: 0.0001 | d_fake_loss: 0.0002 | g_loss: 0.0025\n",
            "Saved /content/sample-005000-X-Y.png\n",
            "Saved /content/sample-005000-Y-X.png\n",
            "Iteration [ 5010/20000] | d_real_loss: 0.0016 | d_Y_loss: 0.0011 | d_X_loss: 0.0001 | d_fake_loss: 0.0012 | g_loss: 0.0022\n",
            "Iteration [ 5020/20000] | d_real_loss: 0.0010 | d_Y_loss: 0.0006 | d_X_loss: 0.0002 | d_fake_loss: 0.0008 | g_loss: 0.0021\n",
            "Iteration [ 5030/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0006 | d_X_loss: 0.0002 | d_fake_loss: 0.0008 | g_loss: 0.0027\n",
            "Iteration [ 5040/20000] | d_real_loss: 0.0013 | d_Y_loss: 0.0001 | d_X_loss: 0.0001 | d_fake_loss: 0.0002 | g_loss: 0.0029\n",
            "Iteration [ 5050/20000] | d_real_loss: 0.0012 | d_Y_loss: 0.0002 | d_X_loss: 0.0001 | d_fake_loss: 0.0004 | g_loss: 0.0022\n",
            "Iteration [ 5060/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0002 | d_X_loss: 0.0002 | d_fake_loss: 0.0005 | g_loss: 0.0025\n",
            "Iteration [ 5070/20000] | d_real_loss: 0.0009 | d_Y_loss: 0.0002 | d_X_loss: 0.0001 | d_fake_loss: 0.0002 | g_loss: 0.0035\n",
            "Iteration [ 5080/20000] | d_real_loss: 0.0013 | d_Y_loss: 0.0001 | d_X_loss: 0.0003 | d_fake_loss: 0.0003 | g_loss: 0.0026\n",
            "Iteration [ 5090/20000] | d_real_loss: 0.0015 | d_Y_loss: 0.0047 | d_X_loss: 0.0002 | d_fake_loss: 0.0049 | g_loss: 0.0045\n",
            "Iteration [ 5100/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0026 | d_X_loss: 0.0000 | d_fake_loss: 0.0027 | g_loss: 0.0025\n",
            "Iteration [ 5110/20000] | d_real_loss: 0.0007 | d_Y_loss: 0.0021 | d_X_loss: 0.0001 | d_fake_loss: 0.0022 | g_loss: 0.0021\n",
            "Iteration [ 5120/20000] | d_real_loss: 0.0017 | d_Y_loss: 0.0001 | d_X_loss: 0.0007 | d_fake_loss: 0.0007 | g_loss: 0.0025\n",
            "Iteration [ 5130/20000] | d_real_loss: 0.0016 | d_Y_loss: 0.0009 | d_X_loss: 0.0001 | d_fake_loss: 0.0010 | g_loss: 0.0025\n",
            "Iteration [ 5140/20000] | d_real_loss: 0.0014 | d_Y_loss: 0.0023 | d_X_loss: 0.0003 | d_fake_loss: 0.0025 | g_loss: 0.0026\n",
            "Iteration [ 5150/20000] | d_real_loss: 0.0017 | d_Y_loss: 0.0008 | d_X_loss: 0.0003 | d_fake_loss: 0.0011 | g_loss: 0.0022\n",
            "Iteration [ 5160/20000] | d_real_loss: 0.0006 | d_Y_loss: 0.0000 | d_X_loss: 0.0002 | d_fake_loss: 0.0002 | g_loss: 0.0019\n",
            "Iteration [ 5170/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0018\n",
            "Iteration [ 5180/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0005 | d_X_loss: 0.0003 | d_fake_loss: 0.0008 | g_loss: 0.0023\n",
            "Iteration [ 5190/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0025\n",
            "Iteration [ 5200/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0021\n",
            "Iteration [ 5210/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0003 | d_X_loss: 0.0001 | d_fake_loss: 0.0004 | g_loss: 0.0018\n",
            "Iteration [ 5220/20000] | d_real_loss: 0.0006 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0002 | g_loss: 0.0025\n",
            "Iteration [ 5230/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0001 | d_X_loss: 0.0001 | d_fake_loss: 0.0002 | g_loss: 0.0021\n",
            "Iteration [ 5240/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0002 | d_X_loss: 0.0001 | d_fake_loss: 0.0003 | g_loss: 0.0020\n",
            "Iteration [ 5250/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0002 | d_X_loss: 0.0004 | d_fake_loss: 0.0006 | g_loss: 0.0020\n",
            "Iteration [ 5260/20000] | d_real_loss: 0.0010 | d_Y_loss: 0.0003 | d_X_loss: 0.0001 | d_fake_loss: 0.0004 | g_loss: 0.0022\n",
            "Iteration [ 5270/20000] | d_real_loss: 0.0015 | d_Y_loss: 0.0004 | d_X_loss: 0.0001 | d_fake_loss: 0.0005 | g_loss: 0.0024\n",
            "Iteration [ 5280/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0005 | d_X_loss: 0.0003 | d_fake_loss: 0.0008 | g_loss: 0.0024\n",
            "Iteration [ 5290/20000] | d_real_loss: 0.0015 | d_Y_loss: 0.0013 | d_X_loss: 0.0003 | d_fake_loss: 0.0016 | g_loss: 0.0030\n",
            "Iteration [ 5300/20000] | d_real_loss: 0.0012 | d_Y_loss: 0.0002 | d_X_loss: 0.0005 | d_fake_loss: 0.0007 | g_loss: 0.0025\n",
            "Iteration [ 5310/20000] | d_real_loss: 0.0010 | d_Y_loss: 0.0001 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0026\n",
            "Iteration [ 5320/20000] | d_real_loss: 0.0010 | d_Y_loss: 0.0001 | d_X_loss: 0.0002 | d_fake_loss: 0.0002 | g_loss: 0.0035\n",
            "Iteration [ 5330/20000] | d_real_loss: 0.0007 | d_Y_loss: 0.0003 | d_X_loss: 0.0001 | d_fake_loss: 0.0004 | g_loss: 0.0021\n",
            "Iteration [ 5340/20000] | d_real_loss: 0.0006 | d_Y_loss: 0.0008 | d_X_loss: 0.0005 | d_fake_loss: 0.0012 | g_loss: 0.0020\n",
            "Iteration [ 5350/20000] | d_real_loss: 0.0010 | d_Y_loss: 0.0001 | d_X_loss: 0.0003 | d_fake_loss: 0.0003 | g_loss: 0.0025\n",
            "Iteration [ 5360/20000] | d_real_loss: 0.0007 | d_Y_loss: 0.0012 | d_X_loss: 0.0003 | d_fake_loss: 0.0015 | g_loss: 0.0025\n",
            "Iteration [ 5370/20000] | d_real_loss: 0.0007 | d_Y_loss: 0.0043 | d_X_loss: 0.0005 | d_fake_loss: 0.0048 | g_loss: 0.0025\n",
            "Iteration [ 5380/20000] | d_real_loss: 0.0007 | d_Y_loss: 0.0002 | d_X_loss: 0.0006 | d_fake_loss: 0.0008 | g_loss: 0.0022\n",
            "Iteration [ 5390/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0001 | d_X_loss: 0.0005 | d_fake_loss: 0.0007 | g_loss: 0.0028\n",
            "Iteration [ 5400/20000] | d_real_loss: 0.0012 | d_Y_loss: 0.0001 | d_X_loss: 0.0016 | d_fake_loss: 0.0017 | g_loss: 0.0023\n",
            "Iteration [ 5410/20000] | d_real_loss: 0.0005 | d_Y_loss: 0.0003 | d_X_loss: 0.0005 | d_fake_loss: 0.0007 | g_loss: 0.0024\n",
            "Iteration [ 5420/20000] | d_real_loss: 0.0009 | d_Y_loss: 0.0003 | d_X_loss: 0.0003 | d_fake_loss: 0.0006 | g_loss: 0.0022\n",
            "Iteration [ 5430/20000] | d_real_loss: 0.0011 | d_Y_loss: 0.0011 | d_X_loss: 0.0037 | d_fake_loss: 0.0048 | g_loss: 0.0022\n",
            "Iteration [ 5440/20000] | d_real_loss: 0.0007 | d_Y_loss: 0.0026 | d_X_loss: 0.0008 | d_fake_loss: 0.0034 | g_loss: 0.0027\n",
            "Iteration [ 5450/20000] | d_real_loss: 0.0010 | d_Y_loss: 0.0015 | d_X_loss: 0.0010 | d_fake_loss: 0.0025 | g_loss: 0.0020\n",
            "Iteration [ 5460/20000] | d_real_loss: 0.0021 | d_Y_loss: 0.0016 | d_X_loss: 0.0018 | d_fake_loss: 0.0034 | g_loss: 0.0028\n",
            "Iteration [ 5470/20000] | d_real_loss: 0.0143 | d_Y_loss: 0.0005 | d_X_loss: 0.0042 | d_fake_loss: 0.0048 | g_loss: 0.0021\n",
            "Iteration [ 5480/20000] | d_real_loss: 0.0011 | d_Y_loss: 0.0001 | d_X_loss: 0.0012 | d_fake_loss: 0.0013 | g_loss: 0.0019\n",
            "Iteration [ 5490/20000] | d_real_loss: 0.0005 | d_Y_loss: 0.0002 | d_X_loss: 0.0005 | d_fake_loss: 0.0007 | g_loss: 0.0021\n",
            "Iteration [ 5500/20000] | d_real_loss: 0.0005 | d_Y_loss: 0.0001 | d_X_loss: 0.0004 | d_fake_loss: 0.0005 | g_loss: 0.0020\n",
            "Iteration [ 5510/20000] | d_real_loss: 0.0007 | d_Y_loss: 0.0008 | d_X_loss: 0.0003 | d_fake_loss: 0.0011 | g_loss: 0.0031\n",
            "Iteration [ 5520/20000] | d_real_loss: 0.0005 | d_Y_loss: 0.0001 | d_X_loss: 0.0001 | d_fake_loss: 0.0002 | g_loss: 0.0021\n",
            "Iteration [ 5530/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0016 | d_X_loss: 0.0003 | d_fake_loss: 0.0019 | g_loss: 0.0044\n",
            "Iteration [ 5540/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0004 | d_X_loss: 0.0001 | d_fake_loss: 0.0005 | g_loss: 0.0027\n",
            "Iteration [ 5550/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0007 | d_X_loss: 0.0000 | d_fake_loss: 0.0008 | g_loss: 0.0020\n",
            "Iteration [ 5560/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0003 | d_X_loss: 0.0000 | d_fake_loss: 0.0003 | g_loss: 0.0022\n",
            "Iteration [ 5570/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0004 | d_X_loss: 0.0001 | d_fake_loss: 0.0004 | g_loss: 0.0021\n",
            "Iteration [ 5580/20000] | d_real_loss: 0.0027 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0026\n",
            "Iteration [ 5590/20000] | d_real_loss: 0.0031 | d_Y_loss: 0.0013 | d_X_loss: 0.0001 | d_fake_loss: 0.0014 | g_loss: 0.0026\n",
            "Iteration [ 5600/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0012 | d_X_loss: 0.0001 | d_fake_loss: 0.0014 | g_loss: 0.0017\n",
            "Iteration [ 5610/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0019\n",
            "Iteration [ 5620/20000] | d_real_loss: 0.0009 | d_Y_loss: 0.0002 | d_X_loss: 0.0001 | d_fake_loss: 0.0003 | g_loss: 0.0019\n",
            "Iteration [ 5630/20000] | d_real_loss: 0.0017 | d_Y_loss: 0.0011 | d_X_loss: 0.0003 | d_fake_loss: 0.0014 | g_loss: 0.0022\n",
            "Iteration [ 5640/20000] | d_real_loss: 0.0005 | d_Y_loss: 0.0009 | d_X_loss: 0.0001 | d_fake_loss: 0.0011 | g_loss: 0.0021\n",
            "Iteration [ 5650/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0001 | d_X_loss: 0.0001 | d_fake_loss: 0.0002 | g_loss: 0.0045\n",
            "Iteration [ 5660/20000] | d_real_loss: 0.0009 | d_Y_loss: 0.0001 | d_X_loss: 0.0002 | d_fake_loss: 0.0003 | g_loss: 0.0021\n",
            "Iteration [ 5670/20000] | d_real_loss: 0.0005 | d_Y_loss: 0.0001 | d_X_loss: 0.0001 | d_fake_loss: 0.0002 | g_loss: 0.0020\n",
            "Iteration [ 5680/20000] | d_real_loss: 0.0006 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0020\n",
            "Iteration [ 5690/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0008 | d_X_loss: 0.0001 | d_fake_loss: 0.0009 | g_loss: 0.0018\n",
            "Iteration [ 5700/20000] | d_real_loss: 0.0006 | d_Y_loss: 0.0033 | d_X_loss: 0.0001 | d_fake_loss: 0.0034 | g_loss: 0.0020\n",
            "Iteration [ 5710/20000] | d_real_loss: 0.0026 | d_Y_loss: 0.0023 | d_X_loss: 0.0013 | d_fake_loss: 0.0037 | g_loss: 0.0020\n",
            "Iteration [ 5720/20000] | d_real_loss: 0.0025 | d_Y_loss: 0.0006 | d_X_loss: 0.0002 | d_fake_loss: 0.0008 | g_loss: 0.0018\n",
            "Iteration [ 5730/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0002 | d_X_loss: 0.0002 | d_fake_loss: 0.0004 | g_loss: 0.0020\n",
            "Iteration [ 5740/20000] | d_real_loss: 0.0005 | d_Y_loss: 0.0003 | d_X_loss: 0.0007 | d_fake_loss: 0.0010 | g_loss: 0.0027\n",
            "Iteration [ 5750/20000] | d_real_loss: 0.0008 | d_Y_loss: 0.0001 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0024\n",
            "Iteration [ 5760/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0003 | d_X_loss: 0.0003 | d_fake_loss: 0.0006 | g_loss: 0.0019\n",
            "Iteration [ 5770/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0017\n",
            "Iteration [ 5780/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0003 | d_X_loss: 0.0000 | d_fake_loss: 0.0003 | g_loss: 0.0020\n",
            "Iteration [ 5790/20000] | d_real_loss: 0.0007 | d_Y_loss: 0.0036 | d_X_loss: 0.0001 | d_fake_loss: 0.0038 | g_loss: 0.0025\n",
            "Iteration [ 5800/20000] | d_real_loss: 0.0008 | d_Y_loss: 0.0023 | d_X_loss: 0.0003 | d_fake_loss: 0.0026 | g_loss: 0.0030\n",
            "Iteration [ 5810/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0019 | d_X_loss: 0.0001 | d_fake_loss: 0.0021 | g_loss: 0.0022\n",
            "Iteration [ 5820/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0022\n",
            "Iteration [ 5830/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0006 | d_X_loss: 0.0001 | d_fake_loss: 0.0007 | g_loss: 0.0031\n",
            "Iteration [ 5840/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0004 | d_X_loss: 0.0000 | d_fake_loss: 0.0004 | g_loss: 0.0024\n",
            "Iteration [ 5850/20000] | d_real_loss: 0.0005 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0019\n",
            "Iteration [ 5860/20000] | d_real_loss: 0.0006 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0017\n",
            "Iteration [ 5870/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0002 | d_X_loss: 0.0000 | d_fake_loss: 0.0002 | g_loss: 0.0022\n",
            "Iteration [ 5880/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0011 | d_X_loss: 0.0001 | d_fake_loss: 0.0012 | g_loss: 0.0019\n",
            "Iteration [ 5890/20000] | d_real_loss: 0.0010 | d_Y_loss: 0.0008 | d_X_loss: 0.0000 | d_fake_loss: 0.0008 | g_loss: 0.0025\n",
            "Iteration [ 5900/20000] | d_real_loss: 0.0009 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0019\n",
            "Iteration [ 5910/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0012 | d_X_loss: 0.0000 | d_fake_loss: 0.0013 | g_loss: 0.0023\n",
            "Iteration [ 5920/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0007 | d_X_loss: 0.0002 | d_fake_loss: 0.0008 | g_loss: 0.0033\n",
            "Iteration [ 5930/20000] | d_real_loss: 0.0006 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0002 | g_loss: 0.0023\n",
            "Iteration [ 5940/20000] | d_real_loss: 0.0012 | d_Y_loss: 0.0003 | d_X_loss: 0.0001 | d_fake_loss: 0.0004 | g_loss: 0.0020\n",
            "Iteration [ 5950/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0011 | d_X_loss: 0.0000 | d_fake_loss: 0.0012 | g_loss: 0.0021\n",
            "Iteration [ 5960/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0005 | d_X_loss: 0.0001 | d_fake_loss: 0.0006 | g_loss: 0.0023\n",
            "Iteration [ 5970/20000] | d_real_loss: 0.0008 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0002 | g_loss: 0.0020\n",
            "Iteration [ 5980/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0000 | d_X_loss: 0.0007 | d_fake_loss: 0.0007 | g_loss: 0.0019\n",
            "Iteration [ 5990/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0005 | d_fake_loss: 0.0005 | g_loss: 0.0016\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration [ 6000/20000] | d_real_loss: 0.0009 | d_Y_loss: 0.0001 | d_X_loss: 0.0005 | d_fake_loss: 0.0006 | g_loss: 0.0017\n",
            "Saved /content/sample-006000-X-Y.png\n",
            "Saved /content/sample-006000-Y-X.png\n",
            "Iteration [ 6010/20000] | d_real_loss: 0.0006 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0022\n",
            "Iteration [ 6020/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0002 | d_X_loss: 0.0001 | d_fake_loss: 0.0003 | g_loss: 0.0034\n",
            "Iteration [ 6030/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0003 | d_X_loss: 0.0001 | d_fake_loss: 0.0004 | g_loss: 0.0019\n",
            "Iteration [ 6040/20000] | d_real_loss: 0.0005 | d_Y_loss: 0.0002 | d_X_loss: 0.0001 | d_fake_loss: 0.0003 | g_loss: 0.0021\n",
            "Iteration [ 6050/20000] | d_real_loss: 0.0007 | d_Y_loss: 0.0003 | d_X_loss: 0.0003 | d_fake_loss: 0.0007 | g_loss: 0.0025\n",
            "Iteration [ 6060/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0012 | d_X_loss: 0.0001 | d_fake_loss: 0.0013 | g_loss: 0.0036\n",
            "Iteration [ 6070/20000] | d_real_loss: 0.0009 | d_Y_loss: 0.0045 | d_X_loss: 0.0002 | d_fake_loss: 0.0047 | g_loss: 0.0027\n",
            "Iteration [ 6080/20000] | d_real_loss: 0.0012 | d_Y_loss: 0.0010 | d_X_loss: 0.0017 | d_fake_loss: 0.0027 | g_loss: 0.0020\n",
            "Iteration [ 6090/20000] | d_real_loss: 0.0005 | d_Y_loss: 0.0009 | d_X_loss: 0.0001 | d_fake_loss: 0.0010 | g_loss: 0.0022\n",
            "Iteration [ 6100/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0004 | d_X_loss: 0.0001 | d_fake_loss: 0.0005 | g_loss: 0.0019\n",
            "Iteration [ 6110/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0001 | d_X_loss: 0.0002 | d_fake_loss: 0.0003 | g_loss: 0.0029\n",
            "Iteration [ 6120/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0006 | d_X_loss: 0.0006 | d_fake_loss: 0.0012 | g_loss: 0.0018\n",
            "Iteration [ 6130/20000] | d_real_loss: 0.0007 | d_Y_loss: 0.0000 | d_X_loss: 0.0002 | d_fake_loss: 0.0002 | g_loss: 0.0019\n",
            "Iteration [ 6140/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0001 | d_X_loss: 0.0001 | d_fake_loss: 0.0002 | g_loss: 0.0019\n",
            "Iteration [ 6150/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0004 | d_X_loss: 0.0001 | d_fake_loss: 0.0005 | g_loss: 0.0020\n",
            "Iteration [ 6160/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0001 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0025\n",
            "Iteration [ 6170/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0002 | d_X_loss: 0.0001 | d_fake_loss: 0.0002 | g_loss: 0.0017\n",
            "Iteration [ 6180/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0020\n",
            "Iteration [ 6190/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0028\n",
            "Iteration [ 6200/20000] | d_real_loss: 0.0007 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0021\n",
            "Iteration [ 6210/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0002 | d_X_loss: 0.0009 | d_fake_loss: 0.0011 | g_loss: 0.0023\n",
            "Iteration [ 6220/20000] | d_real_loss: 0.0005 | d_Y_loss: 0.0001 | d_X_loss: 0.0001 | d_fake_loss: 0.0002 | g_loss: 0.0018\n",
            "Iteration [ 6230/20000] | d_real_loss: 0.0022 | d_Y_loss: 0.0003 | d_X_loss: 0.0003 | d_fake_loss: 0.0006 | g_loss: 0.0027\n",
            "Iteration [ 6240/20000] | d_real_loss: 0.0028 | d_Y_loss: 0.0029 | d_X_loss: 0.0001 | d_fake_loss: 0.0030 | g_loss: 0.0034\n",
            "Iteration [ 6250/20000] | d_real_loss: 0.0013 | d_Y_loss: 0.0075 | d_X_loss: 0.0003 | d_fake_loss: 0.0078 | g_loss: 0.0022\n",
            "Iteration [ 6260/20000] | d_real_loss: 0.0021 | d_Y_loss: 0.0006 | d_X_loss: 0.0001 | d_fake_loss: 0.0008 | g_loss: 0.0030\n",
            "Iteration [ 6270/20000] | d_real_loss: 0.0013 | d_Y_loss: 0.0001 | d_X_loss: 0.0005 | d_fake_loss: 0.0006 | g_loss: 0.0025\n",
            "Iteration [ 6280/20000] | d_real_loss: 0.0010 | d_Y_loss: 0.0001 | d_X_loss: 0.0001 | d_fake_loss: 0.0002 | g_loss: 0.0024\n",
            "Iteration [ 6290/20000] | d_real_loss: 0.0005 | d_Y_loss: 0.0013 | d_X_loss: 0.0002 | d_fake_loss: 0.0015 | g_loss: 0.0020\n",
            "Iteration [ 6300/20000] | d_real_loss: 0.0006 | d_Y_loss: 0.0014 | d_X_loss: 0.0005 | d_fake_loss: 0.0019 | g_loss: 0.0017\n",
            "Iteration [ 6310/20000] | d_real_loss: 0.0010 | d_Y_loss: 0.0001 | d_X_loss: 0.0002 | d_fake_loss: 0.0003 | g_loss: 0.0017\n",
            "Iteration [ 6320/20000] | d_real_loss: 0.0005 | d_Y_loss: 0.0000 | d_X_loss: 0.0010 | d_fake_loss: 0.0010 | g_loss: 0.0020\n",
            "Iteration [ 6330/20000] | d_real_loss: 0.0051 | d_Y_loss: 0.0004 | d_X_loss: 0.0027 | d_fake_loss: 0.0031 | g_loss: 0.0019\n",
            "Iteration [ 6340/20000] | d_real_loss: 0.0483 | d_Y_loss: 0.0000 | d_X_loss: 0.0059 | d_fake_loss: 0.0059 | g_loss: 0.0024\n",
            "Iteration [ 6350/20000] | d_real_loss: 0.0013 | d_Y_loss: 0.0001 | d_X_loss: 0.0023 | d_fake_loss: 0.0024 | g_loss: 0.0023\n",
            "Iteration [ 6360/20000] | d_real_loss: 0.0005 | d_Y_loss: 0.0002 | d_X_loss: 0.0003 | d_fake_loss: 0.0005 | g_loss: 0.0022\n",
            "Iteration [ 6370/20000] | d_real_loss: 0.0005 | d_Y_loss: 0.0003 | d_X_loss: 0.0003 | d_fake_loss: 0.0006 | g_loss: 0.0021\n",
            "Iteration [ 6380/20000] | d_real_loss: 0.0005 | d_Y_loss: 0.0002 | d_X_loss: 0.0000 | d_fake_loss: 0.0002 | g_loss: 0.0019\n",
            "Iteration [ 6390/20000] | d_real_loss: 0.0009 | d_Y_loss: 0.0001 | d_X_loss: 0.0002 | d_fake_loss: 0.0003 | g_loss: 0.0017\n",
            "Iteration [ 6400/20000] | d_real_loss: 0.0006 | d_Y_loss: 0.0004 | d_X_loss: 0.0004 | d_fake_loss: 0.0008 | g_loss: 0.0017\n",
            "Iteration [ 6410/20000] | d_real_loss: 0.0005 | d_Y_loss: 0.0007 | d_X_loss: 0.0000 | d_fake_loss: 0.0008 | g_loss: 0.0018\n",
            "Iteration [ 6420/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0017\n",
            "Iteration [ 6430/20000] | d_real_loss: 0.0006 | d_Y_loss: 0.0005 | d_X_loss: 0.0002 | d_fake_loss: 0.0006 | g_loss: 0.0018\n",
            "Iteration [ 6440/20000] | d_real_loss: 0.0005 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0016\n",
            "Iteration [ 6450/20000] | d_real_loss: 0.0006 | d_Y_loss: 0.0002 | d_X_loss: 0.0000 | d_fake_loss: 0.0002 | g_loss: 0.0020\n",
            "Iteration [ 6460/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0017\n",
            "Iteration [ 6470/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0015\n",
            "Iteration [ 6480/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0004 | d_X_loss: 0.0001 | d_fake_loss: 0.0005 | g_loss: 0.0018\n",
            "Iteration [ 6490/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0019\n",
            "Iteration [ 6500/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0002 | d_X_loss: 0.0000 | d_fake_loss: 0.0003 | g_loss: 0.0017\n",
            "Iteration [ 6510/20000] | d_real_loss: 0.0011 | d_Y_loss: 0.0003 | d_X_loss: 0.0001 | d_fake_loss: 0.0004 | g_loss: 0.0021\n",
            "Iteration [ 6520/20000] | d_real_loss: 0.0007 | d_Y_loss: 0.0008 | d_X_loss: 0.0001 | d_fake_loss: 0.0008 | g_loss: 0.0023\n",
            "Iteration [ 6530/20000] | d_real_loss: 0.0018 | d_Y_loss: 0.0036 | d_X_loss: 0.0000 | d_fake_loss: 0.0037 | g_loss: 0.0029\n",
            "Iteration [ 6540/20000] | d_real_loss: 0.0017 | d_Y_loss: 0.0020 | d_X_loss: 0.0002 | d_fake_loss: 0.0022 | g_loss: 0.0019\n",
            "Iteration [ 6550/20000] | d_real_loss: 0.0005 | d_Y_loss: 0.0004 | d_X_loss: 0.0000 | d_fake_loss: 0.0005 | g_loss: 0.0016\n",
            "Iteration [ 6560/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0002 | g_loss: 0.0028\n",
            "Iteration [ 6570/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0002 | g_loss: 0.0017\n",
            "Iteration [ 6580/20000] | d_real_loss: 0.0006 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0002 | g_loss: 0.0017\n",
            "Iteration [ 6590/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0000 | d_X_loss: 0.0002 | d_fake_loss: 0.0002 | g_loss: 0.0018\n",
            "Iteration [ 6600/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0020\n",
            "Iteration [ 6610/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0004 | d_X_loss: 0.0002 | d_fake_loss: 0.0006 | g_loss: 0.0016\n",
            "Iteration [ 6620/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0002 | g_loss: 0.0014\n",
            "Iteration [ 6630/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0002 | d_X_loss: 0.0000 | d_fake_loss: 0.0002 | g_loss: 0.0021\n",
            "Iteration [ 6640/20000] | d_real_loss: 0.0009 | d_Y_loss: 0.0001 | d_X_loss: 0.0003 | d_fake_loss: 0.0004 | g_loss: 0.0019\n",
            "Iteration [ 6650/20000] | d_real_loss: 0.0006 | d_Y_loss: 0.0001 | d_X_loss: 0.0002 | d_fake_loss: 0.0003 | g_loss: 0.0018\n",
            "Iteration [ 6660/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0000 | d_X_loss: 0.0002 | d_fake_loss: 0.0003 | g_loss: 0.0016\n",
            "Iteration [ 6670/20000] | d_real_loss: 0.0008 | d_Y_loss: 0.0000 | d_X_loss: 0.0003 | d_fake_loss: 0.0004 | g_loss: 0.0015\n",
            "Iteration [ 6680/20000] | d_real_loss: 0.0017 | d_Y_loss: 0.0001 | d_X_loss: 0.0004 | d_fake_loss: 0.0004 | g_loss: 0.0026\n",
            "Iteration [ 6690/20000] | d_real_loss: 0.0008 | d_Y_loss: 0.0005 | d_X_loss: 0.0010 | d_fake_loss: 0.0015 | g_loss: 0.0027\n",
            "Iteration [ 6700/20000] | d_real_loss: 0.0008 | d_Y_loss: 0.0001 | d_X_loss: 0.0006 | d_fake_loss: 0.0006 | g_loss: 0.0019\n",
            "Iteration [ 6710/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0002 | d_X_loss: 0.0001 | d_fake_loss: 0.0002 | g_loss: 0.0016\n",
            "Iteration [ 6720/20000] | d_real_loss: 0.0030 | d_Y_loss: 0.0001 | d_X_loss: 0.0003 | d_fake_loss: 0.0004 | g_loss: 0.0021\n",
            "Iteration [ 6730/20000] | d_real_loss: 0.0010 | d_Y_loss: 0.0003 | d_X_loss: 0.0003 | d_fake_loss: 0.0006 | g_loss: 0.0024\n",
            "Iteration [ 6740/20000] | d_real_loss: 0.0036 | d_Y_loss: 0.0148 | d_X_loss: 0.0001 | d_fake_loss: 0.0148 | g_loss: 0.0043\n",
            "Iteration [ 6750/20000] | d_real_loss: 0.0007 | d_Y_loss: 0.0011 | d_X_loss: 0.0001 | d_fake_loss: 0.0013 | g_loss: 0.0019\n",
            "Iteration [ 6760/20000] | d_real_loss: 0.0010 | d_Y_loss: 0.0001 | d_X_loss: 0.0002 | d_fake_loss: 0.0003 | g_loss: 0.0018\n",
            "Iteration [ 6770/20000] | d_real_loss: 0.0006 | d_Y_loss: 0.0001 | d_X_loss: 0.0001 | d_fake_loss: 0.0002 | g_loss: 0.0017\n",
            "Iteration [ 6780/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0015\n",
            "Iteration [ 6790/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0019\n",
            "Iteration [ 6800/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0001 | d_X_loss: 0.0001 | d_fake_loss: 0.0002 | g_loss: 0.0017\n",
            "Iteration [ 6810/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0016\n",
            "Iteration [ 6820/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0017\n",
            "Iteration [ 6830/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0019\n",
            "Iteration [ 6840/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0016\n",
            "Iteration [ 6850/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0001 | d_X_loss: 0.0003 | d_fake_loss: 0.0004 | g_loss: 0.0016\n",
            "Iteration [ 6860/20000] | d_real_loss: 0.0007 | d_Y_loss: 0.0000 | d_X_loss: 0.0003 | d_fake_loss: 0.0003 | g_loss: 0.0030\n",
            "Iteration [ 6870/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0001 | d_X_loss: 0.0001 | d_fake_loss: 0.0002 | g_loss: 0.0023\n",
            "Iteration [ 6880/20000] | d_real_loss: 0.0006 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0002 | g_loss: 0.0019\n",
            "Iteration [ 6890/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0000 | d_X_loss: 0.0003 | d_fake_loss: 0.0003 | g_loss: 0.0015\n",
            "Iteration [ 6900/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0002 | g_loss: 0.0021\n",
            "Iteration [ 6910/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0003 | d_X_loss: 0.0001 | d_fake_loss: 0.0003 | g_loss: 0.0020\n",
            "Iteration [ 6920/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0016\n",
            "Iteration [ 6930/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0009 | d_X_loss: 0.0000 | d_fake_loss: 0.0009 | g_loss: 0.0015\n",
            "Iteration [ 6940/20000] | d_real_loss: 0.0005 | d_Y_loss: 0.0019 | d_X_loss: 0.0002 | d_fake_loss: 0.0020 | g_loss: 0.0025\n",
            "Iteration [ 6950/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0005 | d_X_loss: 0.0000 | d_fake_loss: 0.0005 | g_loss: 0.0021\n",
            "Iteration [ 6960/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0028\n",
            "Iteration [ 6970/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0017\n",
            "Iteration [ 6980/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0002 | d_X_loss: 0.0000 | d_fake_loss: 0.0002 | g_loss: 0.0015\n",
            "Iteration [ 6990/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0043 | d_X_loss: 0.0001 | d_fake_loss: 0.0044 | g_loss: 0.0023\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration [ 7000/20000] | d_real_loss: 0.0005 | d_Y_loss: 0.0024 | d_X_loss: 0.0003 | d_fake_loss: 0.0026 | g_loss: 0.0015\n",
            "Saved /content/sample-007000-X-Y.png\n",
            "Saved /content/sample-007000-Y-X.png\n",
            "Iteration [ 7010/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0010 | d_X_loss: 0.0004 | d_fake_loss: 0.0014 | g_loss: 0.0015\n",
            "Iteration [ 7020/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0015\n",
            "Iteration [ 7030/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0004 | d_X_loss: 0.0001 | d_fake_loss: 0.0005 | g_loss: 0.0016\n",
            "Iteration [ 7040/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0003 | d_X_loss: 0.0000 | d_fake_loss: 0.0003 | g_loss: 0.0015\n",
            "Iteration [ 7050/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0001 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0018\n",
            "Iteration [ 7060/20000] | d_real_loss: 0.0007 | d_Y_loss: 0.0000 | d_X_loss: 0.0002 | d_fake_loss: 0.0002 | g_loss: 0.0017\n",
            "Iteration [ 7070/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0014\n",
            "Iteration [ 7080/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0016\n",
            "Iteration [ 7090/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0001 | d_X_loss: 0.0005 | d_fake_loss: 0.0005 | g_loss: 0.0016\n",
            "Iteration [ 7100/20000] | d_real_loss: 0.0007 | d_Y_loss: 0.0009 | d_X_loss: 0.0009 | d_fake_loss: 0.0018 | g_loss: 0.0030\n",
            "Iteration [ 7110/20000] | d_real_loss: 0.0021 | d_Y_loss: 0.0029 | d_X_loss: 0.0004 | d_fake_loss: 0.0033 | g_loss: 0.0020\n",
            "Iteration [ 7120/20000] | d_real_loss: 0.0006 | d_Y_loss: 0.0007 | d_X_loss: 0.0001 | d_fake_loss: 0.0008 | g_loss: 0.0022\n",
            "Iteration [ 7130/20000] | d_real_loss: 0.0006 | d_Y_loss: 0.0004 | d_X_loss: 0.0008 | d_fake_loss: 0.0012 | g_loss: 0.0018\n",
            "Iteration [ 7140/20000] | d_real_loss: 0.0008 | d_Y_loss: 0.0016 | d_X_loss: 0.0005 | d_fake_loss: 0.0021 | g_loss: 0.0016\n",
            "Iteration [ 7150/20000] | d_real_loss: 0.0041 | d_Y_loss: 0.0005 | d_X_loss: 0.0075 | d_fake_loss: 0.0080 | g_loss: 0.0016\n",
            "Iteration [ 7160/20000] | d_real_loss: 0.0016 | d_Y_loss: 0.0005 | d_X_loss: 0.0009 | d_fake_loss: 0.0014 | g_loss: 0.0026\n",
            "Iteration [ 7170/20000] | d_real_loss: 0.0017 | d_Y_loss: 0.0000 | d_X_loss: 0.0015 | d_fake_loss: 0.0015 | g_loss: 0.0015\n",
            "Iteration [ 7180/20000] | d_real_loss: 0.0023 | d_Y_loss: 0.0004 | d_X_loss: 0.0006 | d_fake_loss: 0.0011 | g_loss: 0.0018\n",
            "Iteration [ 7190/20000] | d_real_loss: 0.0011 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0018\n",
            "Iteration [ 7200/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0002 | d_X_loss: 0.0013 | d_fake_loss: 0.0015 | g_loss: 0.0016\n",
            "Iteration [ 7210/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0002 | d_X_loss: 0.0001 | d_fake_loss: 0.0003 | g_loss: 0.0016\n",
            "Iteration [ 7220/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0008 | d_X_loss: 0.0001 | d_fake_loss: 0.0009 | g_loss: 0.0016\n",
            "Iteration [ 7230/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0017 | d_X_loss: 0.0000 | d_fake_loss: 0.0017 | g_loss: 0.0017\n",
            "Iteration [ 7240/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0005 | d_X_loss: 0.0000 | d_fake_loss: 0.0005 | g_loss: 0.0014\n",
            "Iteration [ 7250/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0003 | d_X_loss: 0.0000 | d_fake_loss: 0.0003 | g_loss: 0.0019\n",
            "Iteration [ 7260/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0015\n",
            "Iteration [ 7270/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0007 | d_X_loss: 0.0000 | d_fake_loss: 0.0007 | g_loss: 0.0020\n",
            "Iteration [ 7280/20000] | d_real_loss: 0.0014 | d_Y_loss: 0.0013 | d_X_loss: 0.0000 | d_fake_loss: 0.0013 | g_loss: 0.0021\n",
            "Iteration [ 7290/20000] | d_real_loss: 0.0011 | d_Y_loss: 0.0010 | d_X_loss: 0.0000 | d_fake_loss: 0.0010 | g_loss: 0.0018\n",
            "Iteration [ 7300/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0018 | d_X_loss: 0.0000 | d_fake_loss: 0.0018 | g_loss: 0.0016\n",
            "Iteration [ 7310/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0003 | d_X_loss: 0.0001 | d_fake_loss: 0.0004 | g_loss: 0.0018\n",
            "Iteration [ 7320/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0015\n",
            "Iteration [ 7330/20000] | d_real_loss: 0.0005 | d_Y_loss: 0.0002 | d_X_loss: 0.0004 | d_fake_loss: 0.0006 | g_loss: 0.0015\n",
            "Iteration [ 7340/20000] | d_real_loss: 0.0005 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0018\n",
            "Iteration [ 7350/20000] | d_real_loss: 0.0008 | d_Y_loss: 0.0008 | d_X_loss: 0.0001 | d_fake_loss: 0.0009 | g_loss: 0.0014\n",
            "Iteration [ 7360/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0026\n",
            "Iteration [ 7370/20000] | d_real_loss: 0.0005 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0016\n",
            "Iteration [ 7380/20000] | d_real_loss: 0.0006 | d_Y_loss: 0.0011 | d_X_loss: 0.0002 | d_fake_loss: 0.0013 | g_loss: 0.0023\n",
            "Iteration [ 7390/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0014 | d_X_loss: 0.0001 | d_fake_loss: 0.0015 | g_loss: 0.0018\n",
            "Iteration [ 7400/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0008 | d_X_loss: 0.0001 | d_fake_loss: 0.0009 | g_loss: 0.0017\n",
            "Iteration [ 7410/20000] | d_real_loss: 0.0006 | d_Y_loss: 0.0003 | d_X_loss: 0.0002 | d_fake_loss: 0.0004 | g_loss: 0.0019\n",
            "Iteration [ 7420/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0019\n",
            "Iteration [ 7430/20000] | d_real_loss: 0.0008 | d_Y_loss: 0.0005 | d_X_loss: 0.0001 | d_fake_loss: 0.0007 | g_loss: 0.0019\n",
            "Iteration [ 7440/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0017\n",
            "Iteration [ 7450/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0007 | d_X_loss: 0.0001 | d_fake_loss: 0.0008 | g_loss: 0.0023\n",
            "Iteration [ 7460/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0007 | d_X_loss: 0.0003 | d_fake_loss: 0.0010 | g_loss: 0.0020\n",
            "Iteration [ 7470/20000] | d_real_loss: 0.0006 | d_Y_loss: 0.0006 | d_X_loss: 0.0001 | d_fake_loss: 0.0007 | g_loss: 0.0015\n",
            "Iteration [ 7480/20000] | d_real_loss: 0.0015 | d_Y_loss: 0.0003 | d_X_loss: 0.0003 | d_fake_loss: 0.0007 | g_loss: 0.0022\n",
            "Iteration [ 7490/20000] | d_real_loss: 0.0005 | d_Y_loss: 0.0004 | d_X_loss: 0.0004 | d_fake_loss: 0.0008 | g_loss: 0.0016\n",
            "Iteration [ 7500/20000] | d_real_loss: 0.0005 | d_Y_loss: 0.0004 | d_X_loss: 0.0001 | d_fake_loss: 0.0005 | g_loss: 0.0015\n",
            "Iteration [ 7510/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0015 | d_X_loss: 0.0002 | d_fake_loss: 0.0017 | g_loss: 0.0018\n",
            "Iteration [ 7520/20000] | d_real_loss: 0.0012 | d_Y_loss: 0.0006 | d_X_loss: 0.0001 | d_fake_loss: 0.0007 | g_loss: 0.0027\n",
            "Iteration [ 7530/20000] | d_real_loss: 0.0008 | d_Y_loss: 0.0001 | d_X_loss: 0.0001 | d_fake_loss: 0.0002 | g_loss: 0.0018\n",
            "Iteration [ 7540/20000] | d_real_loss: 0.0006 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0014\n",
            "Iteration [ 7550/20000] | d_real_loss: 0.0016 | d_Y_loss: 0.0001 | d_X_loss: 0.0004 | d_fake_loss: 0.0005 | g_loss: 0.0015\n",
            "Iteration [ 7560/20000] | d_real_loss: 0.0006 | d_Y_loss: 0.0001 | d_X_loss: 0.0004 | d_fake_loss: 0.0004 | g_loss: 0.0016\n",
            "Iteration [ 7570/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0000 | d_X_loss: 0.0003 | d_fake_loss: 0.0004 | g_loss: 0.0015\n",
            "Iteration [ 7580/20000] | d_real_loss: 0.0007 | d_Y_loss: 0.0003 | d_X_loss: 0.0002 | d_fake_loss: 0.0005 | g_loss: 0.0026\n",
            "Iteration [ 7590/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0002 | d_X_loss: 0.0003 | d_fake_loss: 0.0005 | g_loss: 0.0032\n",
            "Iteration [ 7600/20000] | d_real_loss: 0.0018 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0002 | g_loss: 0.0028\n",
            "Iteration [ 7610/20000] | d_real_loss: 0.0010 | d_Y_loss: 0.0004 | d_X_loss: 0.0001 | d_fake_loss: 0.0005 | g_loss: 0.0020\n",
            "Iteration [ 7620/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0002 | d_X_loss: 0.0001 | d_fake_loss: 0.0003 | g_loss: 0.0023\n",
            "Iteration [ 7630/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0001 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0017\n",
            "Iteration [ 7640/20000] | d_real_loss: 0.0012 | d_Y_loss: 0.0001 | d_X_loss: 0.0005 | d_fake_loss: 0.0006 | g_loss: 0.0019\n",
            "Iteration [ 7650/20000] | d_real_loss: 0.0012 | d_Y_loss: 0.0007 | d_X_loss: 0.0003 | d_fake_loss: 0.0010 | g_loss: 0.0029\n",
            "Iteration [ 7660/20000] | d_real_loss: 0.0020 | d_Y_loss: 0.0017 | d_X_loss: 0.0001 | d_fake_loss: 0.0018 | g_loss: 0.0035\n",
            "Iteration [ 7670/20000] | d_real_loss: 0.0025 | d_Y_loss: 0.0041 | d_X_loss: 0.0002 | d_fake_loss: 0.0042 | g_loss: 0.0020\n",
            "Iteration [ 7680/20000] | d_real_loss: 0.0011 | d_Y_loss: 0.0022 | d_X_loss: 0.0001 | d_fake_loss: 0.0023 | g_loss: 0.0016\n",
            "Iteration [ 7690/20000] | d_real_loss: 0.0009 | d_Y_loss: 0.0006 | d_X_loss: 0.0001 | d_fake_loss: 0.0007 | g_loss: 0.0015\n",
            "Iteration [ 7700/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0001 | d_X_loss: 0.0001 | d_fake_loss: 0.0002 | g_loss: 0.0019\n",
            "Iteration [ 7710/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0016\n",
            "Iteration [ 7720/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0014\n",
            "Iteration [ 7730/20000] | d_real_loss: 0.0006 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0022\n",
            "Iteration [ 7740/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0003 | d_fake_loss: 0.0003 | g_loss: 0.0013\n",
            "Iteration [ 7750/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0006 | d_X_loss: 0.0001 | d_fake_loss: 0.0007 | g_loss: 0.0017\n",
            "Iteration [ 7760/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0002 | d_X_loss: 0.0002 | d_fake_loss: 0.0004 | g_loss: 0.0014\n",
            "Iteration [ 7770/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0015\n",
            "Iteration [ 7780/20000] | d_real_loss: 0.0042 | d_Y_loss: 0.0000 | d_X_loss: 0.0008 | d_fake_loss: 0.0008 | g_loss: 0.0020\n",
            "Iteration [ 7790/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0002 | d_X_loss: 0.0010 | d_fake_loss: 0.0012 | g_loss: 0.0030\n",
            "Iteration [ 7800/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0003 | d_X_loss: 0.0002 | d_fake_loss: 0.0005 | g_loss: 0.0015\n",
            "Iteration [ 7810/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0004 | d_X_loss: 0.0001 | d_fake_loss: 0.0005 | g_loss: 0.0013\n",
            "Iteration [ 7820/20000] | d_real_loss: 0.0011 | d_Y_loss: 0.0003 | d_X_loss: 0.0001 | d_fake_loss: 0.0003 | g_loss: 0.0017\n",
            "Iteration [ 7830/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0002 | g_loss: 0.0026\n",
            "Iteration [ 7840/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0001 | d_X_loss: 0.0002 | d_fake_loss: 0.0004 | g_loss: 0.0014\n",
            "Iteration [ 7850/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0002 | d_X_loss: 0.0004 | d_fake_loss: 0.0006 | g_loss: 0.0015\n",
            "Iteration [ 7860/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0002 | d_X_loss: 0.0000 | d_fake_loss: 0.0003 | g_loss: 0.0018\n",
            "Iteration [ 7870/20000] | d_real_loss: 0.0007 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0019\n",
            "Iteration [ 7880/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0007 | d_X_loss: 0.0001 | d_fake_loss: 0.0008 | g_loss: 0.0019\n",
            "Iteration [ 7890/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0007 | d_X_loss: 0.0000 | d_fake_loss: 0.0007 | g_loss: 0.0017\n",
            "Iteration [ 7900/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0003 | d_X_loss: 0.0004 | d_fake_loss: 0.0007 | g_loss: 0.0023\n",
            "Iteration [ 7910/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0010 | d_X_loss: 0.0002 | d_fake_loss: 0.0012 | g_loss: 0.0017\n",
            "Iteration [ 7920/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0004 | d_X_loss: 0.0003 | d_fake_loss: 0.0007 | g_loss: 0.0014\n",
            "Iteration [ 7930/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0003 | d_X_loss: 0.0000 | d_fake_loss: 0.0003 | g_loss: 0.0012\n",
            "Iteration [ 7940/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0002 | g_loss: 0.0014\n",
            "Iteration [ 7950/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0014\n",
            "Iteration [ 7960/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0015\n",
            "Iteration [ 7970/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0019\n",
            "Iteration [ 7980/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0014\n",
            "Iteration [ 7990/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0006 | d_X_loss: 0.0001 | d_fake_loss: 0.0007 | g_loss: 0.0016\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration [ 8000/20000] | d_real_loss: 0.0009 | d_Y_loss: 0.0005 | d_X_loss: 0.0002 | d_fake_loss: 0.0007 | g_loss: 0.0021\n",
            "Saved /content/sample-008000-X-Y.png\n",
            "Saved /content/sample-008000-Y-X.png\n",
            "Iteration [ 8010/20000] | d_real_loss: 0.0006 | d_Y_loss: 0.0009 | d_X_loss: 0.0001 | d_fake_loss: 0.0010 | g_loss: 0.0018\n",
            "Iteration [ 8020/20000] | d_real_loss: 0.0014 | d_Y_loss: 0.0011 | d_X_loss: 0.0001 | d_fake_loss: 0.0012 | g_loss: 0.0021\n",
            "Iteration [ 8030/20000] | d_real_loss: 0.0019 | d_Y_loss: 0.0021 | d_X_loss: 0.0001 | d_fake_loss: 0.0022 | g_loss: 0.0035\n",
            "Iteration [ 8040/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0034 | d_X_loss: 0.0001 | d_fake_loss: 0.0035 | g_loss: 0.0018\n",
            "Iteration [ 8050/20000] | d_real_loss: 0.0006 | d_Y_loss: 0.0008 | d_X_loss: 0.0000 | d_fake_loss: 0.0008 | g_loss: 0.0018\n",
            "Iteration [ 8060/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0001 | d_X_loss: 0.0002 | d_fake_loss: 0.0002 | g_loss: 0.0015\n",
            "Iteration [ 8070/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0008 | d_X_loss: 0.0002 | d_fake_loss: 0.0009 | g_loss: 0.0016\n",
            "Iteration [ 8080/20000] | d_real_loss: 0.0007 | d_Y_loss: 0.0001 | d_X_loss: 0.0005 | d_fake_loss: 0.0006 | g_loss: 0.0013\n",
            "Iteration [ 8090/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0002 | d_X_loss: 0.0000 | d_fake_loss: 0.0003 | g_loss: 0.0018\n",
            "Iteration [ 8100/20000] | d_real_loss: 0.0005 | d_Y_loss: 0.0003 | d_X_loss: 0.0001 | d_fake_loss: 0.0004 | g_loss: 0.0014\n",
            "Iteration [ 8110/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0017\n",
            "Iteration [ 8120/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0010 | d_X_loss: 0.0000 | d_fake_loss: 0.0011 | g_loss: 0.0016\n",
            "Iteration [ 8130/20000] | d_real_loss: 0.0008 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0002 | g_loss: 0.0026\n",
            "Iteration [ 8140/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0002 | g_loss: 0.0017\n",
            "Iteration [ 8150/20000] | d_real_loss: 0.0006 | d_Y_loss: 0.0004 | d_X_loss: 0.0000 | d_fake_loss: 0.0004 | g_loss: 0.0017\n",
            "Iteration [ 8160/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0004 | d_X_loss: 0.0000 | d_fake_loss: 0.0004 | g_loss: 0.0014\n",
            "Iteration [ 8170/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0001 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0012\n",
            "Iteration [ 8180/20000] | d_real_loss: 0.0008 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0015\n",
            "Iteration [ 8190/20000] | d_real_loss: 0.0011 | d_Y_loss: 0.0000 | d_X_loss: 0.0006 | d_fake_loss: 0.0006 | g_loss: 0.0018\n",
            "Iteration [ 8200/20000] | d_real_loss: 0.0005 | d_Y_loss: 0.0001 | d_X_loss: 0.0004 | d_fake_loss: 0.0005 | g_loss: 0.0015\n",
            "Iteration [ 8210/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0001 | d_X_loss: 0.0003 | d_fake_loss: 0.0003 | g_loss: 0.0016\n",
            "Iteration [ 8220/20000] | d_real_loss: 0.0005 | d_Y_loss: 0.0000 | d_X_loss: 0.0004 | d_fake_loss: 0.0004 | g_loss: 0.0016\n",
            "Iteration [ 8230/20000] | d_real_loss: 0.0008 | d_Y_loss: 0.0001 | d_X_loss: 0.0008 | d_fake_loss: 0.0008 | g_loss: 0.0015\n",
            "Iteration [ 8240/20000] | d_real_loss: 0.0006 | d_Y_loss: 0.0000 | d_X_loss: 0.0007 | d_fake_loss: 0.0008 | g_loss: 0.0022\n",
            "Iteration [ 8250/20000] | d_real_loss: 0.0042 | d_Y_loss: 0.0000 | d_X_loss: 0.0042 | d_fake_loss: 0.0042 | g_loss: 0.0017\n",
            "Iteration [ 8260/20000] | d_real_loss: 0.0033 | d_Y_loss: 0.0000 | d_X_loss: 0.0012 | d_fake_loss: 0.0012 | g_loss: 0.0022\n",
            "Iteration [ 8270/20000] | d_real_loss: 0.0011 | d_Y_loss: 0.0000 | d_X_loss: 0.0028 | d_fake_loss: 0.0028 | g_loss: 0.0021\n",
            "Iteration [ 8280/20000] | d_real_loss: 0.0132 | d_Y_loss: 0.0000 | d_X_loss: 0.0062 | d_fake_loss: 0.0062 | g_loss: 0.0025\n",
            "Iteration [ 8290/20000] | d_real_loss: 0.0012 | d_Y_loss: 0.0000 | d_X_loss: 0.0009 | d_fake_loss: 0.0009 | g_loss: 0.0016\n",
            "Iteration [ 8300/20000] | d_real_loss: 0.0006 | d_Y_loss: 0.0001 | d_X_loss: 0.0003 | d_fake_loss: 0.0004 | g_loss: 0.0016\n",
            "Iteration [ 8310/20000] | d_real_loss: 0.0019 | d_Y_loss: 0.0001 | d_X_loss: 0.0002 | d_fake_loss: 0.0003 | g_loss: 0.0025\n",
            "Iteration [ 8320/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0016\n",
            "Iteration [ 8330/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0004 | d_X_loss: 0.0000 | d_fake_loss: 0.0005 | g_loss: 0.0018\n",
            "Iteration [ 8340/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0014\n",
            "Iteration [ 8350/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0015\n",
            "Iteration [ 8360/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0013\n",
            "Iteration [ 8370/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0012\n",
            "Iteration [ 8380/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0006 | d_X_loss: 0.0001 | d_fake_loss: 0.0007 | g_loss: 0.0014\n",
            "Iteration [ 8390/20000] | d_real_loss: 0.0005 | d_Y_loss: 0.0013 | d_X_loss: 0.0000 | d_fake_loss: 0.0013 | g_loss: 0.0015\n",
            "Iteration [ 8400/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0023\n",
            "Iteration [ 8410/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0003 | d_X_loss: 0.0000 | d_fake_loss: 0.0004 | g_loss: 0.0019\n",
            "Iteration [ 8420/20000] | d_real_loss: 0.0006 | d_Y_loss: 0.0003 | d_X_loss: 0.0000 | d_fake_loss: 0.0003 | g_loss: 0.0016\n",
            "Iteration [ 8430/20000] | d_real_loss: 0.0010 | d_Y_loss: 0.0003 | d_X_loss: 0.0000 | d_fake_loss: 0.0003 | g_loss: 0.0021\n",
            "Iteration [ 8440/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0003 | d_X_loss: 0.0000 | d_fake_loss: 0.0004 | g_loss: 0.0015\n",
            "Iteration [ 8450/20000] | d_real_loss: 0.0018 | d_Y_loss: 0.0005 | d_X_loss: 0.0000 | d_fake_loss: 0.0005 | g_loss: 0.0024\n",
            "Iteration [ 8460/20000] | d_real_loss: 0.0005 | d_Y_loss: 0.0003 | d_X_loss: 0.0000 | d_fake_loss: 0.0003 | g_loss: 0.0020\n",
            "Iteration [ 8470/20000] | d_real_loss: 0.0009 | d_Y_loss: 0.0003 | d_X_loss: 0.0001 | d_fake_loss: 0.0004 | g_loss: 0.0024\n",
            "Iteration [ 8480/20000] | d_real_loss: 0.0007 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0002 | g_loss: 0.0022\n",
            "Iteration [ 8490/20000] | d_real_loss: 0.0006 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0019\n",
            "Iteration [ 8500/20000] | d_real_loss: 0.0010 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0016\n",
            "Iteration [ 8510/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0016\n",
            "Iteration [ 8520/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0014\n",
            "Iteration [ 8530/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0001 | d_X_loss: 0.0001 | d_fake_loss: 0.0002 | g_loss: 0.0014\n",
            "Iteration [ 8540/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0018\n",
            "Iteration [ 8550/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0014\n",
            "Iteration [ 8560/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0003 | d_X_loss: 0.0000 | d_fake_loss: 0.0003 | g_loss: 0.0017\n",
            "Iteration [ 8570/20000] | d_real_loss: 0.0020 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0023\n",
            "Iteration [ 8580/20000] | d_real_loss: 0.0029 | d_Y_loss: 0.0003 | d_X_loss: 0.0000 | d_fake_loss: 0.0003 | g_loss: 0.0034\n",
            "Iteration [ 8590/20000] | d_real_loss: 0.0058 | d_Y_loss: 0.0116 | d_X_loss: 0.0000 | d_fake_loss: 0.0116 | g_loss: 0.0068\n",
            "Iteration [ 8600/20000] | d_real_loss: 0.0023 | d_Y_loss: 0.0005 | d_X_loss: 0.0000 | d_fake_loss: 0.0005 | g_loss: 0.0032\n",
            "Iteration [ 8610/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0009 | d_X_loss: 0.0000 | d_fake_loss: 0.0009 | g_loss: 0.0014\n",
            "Iteration [ 8620/20000] | d_real_loss: 0.0005 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0016\n",
            "Iteration [ 8630/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0015\n",
            "Iteration [ 8640/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0001 | d_X_loss: 0.0001 | d_fake_loss: 0.0002 | g_loss: 0.0013\n",
            "Iteration [ 8650/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0015\n",
            "Iteration [ 8660/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0013\n",
            "Iteration [ 8670/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0001 | d_X_loss: 0.0001 | d_fake_loss: 0.0002 | g_loss: 0.0013\n",
            "Iteration [ 8680/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0013\n",
            "Iteration [ 8690/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0003 | d_fake_loss: 0.0003 | g_loss: 0.0018\n",
            "Iteration [ 8700/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0015\n",
            "Iteration [ 8710/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0007 | d_X_loss: 0.0000 | d_fake_loss: 0.0008 | g_loss: 0.0015\n",
            "Iteration [ 8720/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0001 | d_X_loss: 0.0001 | d_fake_loss: 0.0002 | g_loss: 0.0021\n",
            "Iteration [ 8730/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0015\n",
            "Iteration [ 8740/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0013\n",
            "Iteration [ 8750/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0013\n",
            "Iteration [ 8760/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0005 | d_X_loss: 0.0001 | d_fake_loss: 0.0005 | g_loss: 0.0011\n",
            "Iteration [ 8770/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0004 | d_X_loss: 0.0000 | d_fake_loss: 0.0004 | g_loss: 0.0017\n",
            "Iteration [ 8780/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0001 | d_X_loss: 0.0001 | d_fake_loss: 0.0002 | g_loss: 0.0012\n",
            "Iteration [ 8790/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0013\n",
            "Iteration [ 8800/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0016\n",
            "Iteration [ 8810/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0012\n",
            "Iteration [ 8820/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0016\n",
            "Iteration [ 8830/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0015\n",
            "Iteration [ 8840/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0004 | d_X_loss: 0.0001 | d_fake_loss: 0.0005 | g_loss: 0.0013\n",
            "Iteration [ 8850/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0007 | d_X_loss: 0.0000 | d_fake_loss: 0.0008 | g_loss: 0.0014\n",
            "Iteration [ 8860/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0010 | d_X_loss: 0.0000 | d_fake_loss: 0.0010 | g_loss: 0.0015\n",
            "Iteration [ 8870/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0024 | d_X_loss: 0.0000 | d_fake_loss: 0.0024 | g_loss: 0.0014\n",
            "Iteration [ 8880/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0017\n",
            "Iteration [ 8890/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0013\n",
            "Iteration [ 8900/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0012\n",
            "Iteration [ 8910/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0016\n",
            "Iteration [ 8920/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0019\n",
            "Iteration [ 8930/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0013\n",
            "Iteration [ 8940/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0002 | d_X_loss: 0.0001 | d_fake_loss: 0.0003 | g_loss: 0.0014\n",
            "Iteration [ 8950/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0013\n",
            "Iteration [ 8960/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0014\n",
            "Iteration [ 8970/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0005 | d_X_loss: 0.0000 | d_fake_loss: 0.0006 | g_loss: 0.0013\n",
            "Iteration [ 8980/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0003 | d_X_loss: 0.0000 | d_fake_loss: 0.0004 | g_loss: 0.0011\n",
            "Iteration [ 8990/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0002 | d_X_loss: 0.0001 | d_fake_loss: 0.0003 | g_loss: 0.0014\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float64 to uint8. Range [-1.0, 0.9954954385757446]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration [ 9000/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0015\n",
            "Saved /content/sample-009000-X-Y.png\n",
            "Saved /content/sample-009000-Y-X.png\n",
            "Iteration [ 9010/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0016\n",
            "Iteration [ 9020/20000] | d_real_loss: 0.0008 | d_Y_loss: 0.0001 | d_X_loss: 0.0001 | d_fake_loss: 0.0002 | g_loss: 0.0012\n",
            "Iteration [ 9030/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0011\n",
            "Iteration [ 9040/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0014\n",
            "Iteration [ 9050/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0005 | d_X_loss: 0.0000 | d_fake_loss: 0.0005 | g_loss: 0.0014\n",
            "Iteration [ 9060/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0003 | d_X_loss: 0.0001 | d_fake_loss: 0.0004 | g_loss: 0.0017\n",
            "Iteration [ 9070/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0012\n",
            "Iteration [ 9080/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0012\n",
            "Iteration [ 9090/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0015\n",
            "Iteration [ 9100/20000] | d_real_loss: 0.0016 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0020\n",
            "Iteration [ 9110/20000] | d_real_loss: 0.0006 | d_Y_loss: 0.0002 | d_X_loss: 0.0001 | d_fake_loss: 0.0003 | g_loss: 0.0013\n",
            "Iteration [ 9120/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0003 | d_X_loss: 0.0001 | d_fake_loss: 0.0004 | g_loss: 0.0018\n",
            "Iteration [ 9130/20000] | d_real_loss: 0.0011 | d_Y_loss: 0.0004 | d_X_loss: 0.0000 | d_fake_loss: 0.0005 | g_loss: 0.0014\n",
            "Iteration [ 9140/20000] | d_real_loss: 0.0008 | d_Y_loss: 0.0013 | d_X_loss: 0.0003 | d_fake_loss: 0.0016 | g_loss: 0.0019\n",
            "Iteration [ 9150/20000] | d_real_loss: 0.0011 | d_Y_loss: 0.0027 | d_X_loss: 0.0002 | d_fake_loss: 0.0029 | g_loss: 0.0034\n",
            "Iteration [ 9160/20000] | d_real_loss: 0.0024 | d_Y_loss: 0.0011 | d_X_loss: 0.0001 | d_fake_loss: 0.0012 | g_loss: 0.0024\n",
            "Iteration [ 9170/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0006 | d_X_loss: 0.0001 | d_fake_loss: 0.0007 | g_loss: 0.0014\n",
            "Iteration [ 9180/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0012\n",
            "Iteration [ 9190/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0012\n",
            "Iteration [ 9200/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0014\n",
            "Iteration [ 9210/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0015\n",
            "Iteration [ 9220/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0013\n",
            "Iteration [ 9230/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0002 | d_X_loss: 0.0001 | d_fake_loss: 0.0003 | g_loss: 0.0012\n",
            "Iteration [ 9240/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0002 | g_loss: 0.0011\n",
            "Iteration [ 9250/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0004 | d_X_loss: 0.0002 | d_fake_loss: 0.0006 | g_loss: 0.0012\n",
            "Iteration [ 9260/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0004 | d_X_loss: 0.0001 | d_fake_loss: 0.0005 | g_loss: 0.0014\n",
            "Iteration [ 9270/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0009 | d_X_loss: 0.0000 | d_fake_loss: 0.0009 | g_loss: 0.0015\n",
            "Iteration [ 9280/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0011 | d_X_loss: 0.0001 | d_fake_loss: 0.0011 | g_loss: 0.0012\n",
            "Iteration [ 9290/20000] | d_real_loss: 0.0005 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0014\n",
            "Iteration [ 9300/20000] | d_real_loss: 0.0005 | d_Y_loss: 0.0000 | d_X_loss: 0.0002 | d_fake_loss: 0.0002 | g_loss: 0.0012\n",
            "Iteration [ 9310/20000] | d_real_loss: 0.0008 | d_Y_loss: 0.0000 | d_X_loss: 0.0011 | d_fake_loss: 0.0011 | g_loss: 0.0017\n",
            "Iteration [ 9320/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0002 | d_X_loss: 0.0003 | d_fake_loss: 0.0005 | g_loss: 0.0014\n",
            "Iteration [ 9330/20000] | d_real_loss: 0.0011 | d_Y_loss: 0.0016 | d_X_loss: 0.0007 | d_fake_loss: 0.0023 | g_loss: 0.0033\n",
            "Iteration [ 9340/20000] | d_real_loss: 0.0007 | d_Y_loss: 0.0010 | d_X_loss: 0.0008 | d_fake_loss: 0.0019 | g_loss: 0.0013\n",
            "Iteration [ 9350/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0004 | d_X_loss: 0.0007 | d_fake_loss: 0.0011 | g_loss: 0.0010\n",
            "Iteration [ 9360/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0000 | d_X_loss: 0.0002 | d_fake_loss: 0.0002 | g_loss: 0.0015\n",
            "Iteration [ 9370/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0010\n",
            "Iteration [ 9380/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0015\n",
            "Iteration [ 9390/20000] | d_real_loss: 0.0007 | d_Y_loss: 0.0001 | d_X_loss: 0.0001 | d_fake_loss: 0.0002 | g_loss: 0.0021\n",
            "Iteration [ 9400/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0001 | d_X_loss: 0.0001 | d_fake_loss: 0.0002 | g_loss: 0.0012\n",
            "Iteration [ 9410/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0000 | d_X_loss: 0.0028 | d_fake_loss: 0.0028 | g_loss: 0.0013\n",
            "Iteration [ 9420/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0001 | d_X_loss: 0.0002 | d_fake_loss: 0.0003 | g_loss: 0.0013\n",
            "Iteration [ 9430/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0014\n",
            "Iteration [ 9440/20000] | d_real_loss: 0.0006 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0002 | g_loss: 0.0014\n",
            "Iteration [ 9450/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0011\n",
            "Iteration [ 9460/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0011\n",
            "Iteration [ 9470/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0013\n",
            "Iteration [ 9480/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0011\n",
            "Iteration [ 9490/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0000 | d_X_loss: 0.0002 | d_fake_loss: 0.0002 | g_loss: 0.0016\n",
            "Iteration [ 9500/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0001 | d_X_loss: 0.0002 | d_fake_loss: 0.0003 | g_loss: 0.0017\n",
            "Iteration [ 9510/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0001 | d_X_loss: 0.0001 | d_fake_loss: 0.0002 | g_loss: 0.0015\n",
            "Iteration [ 9520/20000] | d_real_loss: 0.0008 | d_Y_loss: 0.0002 | d_X_loss: 0.0002 | d_fake_loss: 0.0005 | g_loss: 0.0012\n",
            "Iteration [ 9530/20000] | d_real_loss: 0.0008 | d_Y_loss: 0.0001 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0022\n",
            "Iteration [ 9540/20000] | d_real_loss: 0.0010 | d_Y_loss: 0.0003 | d_X_loss: 0.0002 | d_fake_loss: 0.0005 | g_loss: 0.0020\n",
            "Iteration [ 9550/20000] | d_real_loss: 0.0006 | d_Y_loss: 0.0002 | d_X_loss: 0.0001 | d_fake_loss: 0.0004 | g_loss: 0.0012\n",
            "Iteration [ 9560/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0002 | g_loss: 0.0013\n",
            "Iteration [ 9570/20000] | d_real_loss: 0.0006 | d_Y_loss: 0.0000 | d_X_loss: 0.0005 | d_fake_loss: 0.0005 | g_loss: 0.0014\n",
            "Iteration [ 9580/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0010\n",
            "Iteration [ 9590/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0002 | d_X_loss: 0.0002 | d_fake_loss: 0.0005 | g_loss: 0.0014\n",
            "Iteration [ 9600/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0011\n",
            "Iteration [ 9610/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0001 | d_X_loss: 0.0002 | d_fake_loss: 0.0003 | g_loss: 0.0011\n",
            "Iteration [ 9620/20000] | d_real_loss: 0.0012 | d_Y_loss: 0.0000 | d_X_loss: 0.0006 | d_fake_loss: 0.0006 | g_loss: 0.0020\n",
            "Iteration [ 9630/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0000 | d_X_loss: 0.0003 | d_fake_loss: 0.0003 | g_loss: 0.0017\n",
            "Iteration [ 9640/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0003 | d_fake_loss: 0.0003 | g_loss: 0.0013\n",
            "Iteration [ 9650/20000] | d_real_loss: 0.0009 | d_Y_loss: 0.0000 | d_X_loss: 0.0015 | d_fake_loss: 0.0016 | g_loss: 0.0013\n",
            "Iteration [ 9660/20000] | d_real_loss: 0.0023 | d_Y_loss: 0.0000 | d_X_loss: 0.0108 | d_fake_loss: 0.0109 | g_loss: 0.0019\n",
            "Iteration [ 9670/20000] | d_real_loss: 0.0056 | d_Y_loss: 0.0000 | d_X_loss: 0.0042 | d_fake_loss: 0.0042 | g_loss: 0.0018\n",
            "Iteration [ 9680/20000] | d_real_loss: 0.0037 | d_Y_loss: 0.0001 | d_X_loss: 0.0004 | d_fake_loss: 0.0005 | g_loss: 0.0014\n",
            "Iteration [ 9690/20000] | d_real_loss: 0.0013 | d_Y_loss: 0.0000 | d_X_loss: 0.0003 | d_fake_loss: 0.0004 | g_loss: 0.0012\n",
            "Iteration [ 9700/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0001 | d_X_loss: 0.0006 | d_fake_loss: 0.0007 | g_loss: 0.0015\n",
            "Iteration [ 9710/20000] | d_real_loss: 0.0009 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0012\n",
            "Iteration [ 9720/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0012\n",
            "Iteration [ 9730/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0002 | g_loss: 0.0012\n",
            "Iteration [ 9740/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0003 | d_X_loss: 0.0002 | d_fake_loss: 0.0005 | g_loss: 0.0015\n",
            "Iteration [ 9750/20000] | d_real_loss: 0.0005 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0015\n",
            "Iteration [ 9760/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0013\n",
            "Iteration [ 9770/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0012\n",
            "Iteration [ 9780/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0002 | d_X_loss: 0.0001 | d_fake_loss: 0.0003 | g_loss: 0.0012\n",
            "Iteration [ 9790/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0011\n",
            "Iteration [ 9800/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0002 | g_loss: 0.0012\n",
            "Iteration [ 9810/20000] | d_real_loss: 0.0011 | d_Y_loss: 0.0007 | d_X_loss: 0.0000 | d_fake_loss: 0.0007 | g_loss: 0.0013\n",
            "Iteration [ 9820/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0015\n",
            "Iteration [ 9830/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0011\n",
            "Iteration [ 9840/20000] | d_real_loss: 0.0009 | d_Y_loss: 0.0006 | d_X_loss: 0.0000 | d_fake_loss: 0.0006 | g_loss: 0.0012\n",
            "Iteration [ 9850/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0013\n",
            "Iteration [ 9860/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0011\n",
            "Iteration [ 9870/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0015\n",
            "Iteration [ 9880/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0002 | d_X_loss: 0.0001 | d_fake_loss: 0.0003 | g_loss: 0.0016\n",
            "Iteration [ 9890/20000] | d_real_loss: 0.0006 | d_Y_loss: 0.0002 | d_X_loss: 0.0000 | d_fake_loss: 0.0002 | g_loss: 0.0014\n",
            "Iteration [ 9900/20000] | d_real_loss: 0.0014 | d_Y_loss: 0.0005 | d_X_loss: 0.0000 | d_fake_loss: 0.0005 | g_loss: 0.0011\n",
            "Iteration [ 9910/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0011\n",
            "Iteration [ 9920/20000] | d_real_loss: 0.0005 | d_Y_loss: 0.0002 | d_X_loss: 0.0000 | d_fake_loss: 0.0002 | g_loss: 0.0014\n",
            "Iteration [ 9930/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0013\n",
            "Iteration [ 9940/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0012\n",
            "Iteration [ 9950/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0010\n",
            "Iteration [ 9960/20000] | d_real_loss: 0.0008 | d_Y_loss: 0.0002 | d_X_loss: 0.0000 | d_fake_loss: 0.0002 | g_loss: 0.0019\n",
            "Iteration [ 9970/20000] | d_real_loss: 0.0007 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0012\n",
            "Iteration [ 9980/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0004 | d_X_loss: 0.0000 | d_fake_loss: 0.0004 | g_loss: 0.0013\n",
            "Iteration [ 9990/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0014\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float64 to uint8. Range [-1.0, 0.9925885200500488]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration [10000/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0007 | d_X_loss: 0.0000 | d_fake_loss: 0.0007 | g_loss: 0.0016\n",
            "Saved /content/sample-010000-X-Y.png\n",
            "Saved /content/sample-010000-Y-X.png\n",
            "Iteration [10010/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0003 | d_X_loss: 0.0000 | d_fake_loss: 0.0004 | g_loss: 0.0013\n",
            "Iteration [10020/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0002 | d_X_loss: 0.0000 | d_fake_loss: 0.0002 | g_loss: 0.0010\n",
            "Iteration [10030/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0011\n",
            "Iteration [10040/20000] | d_real_loss: 0.0007 | d_Y_loss: 0.0007 | d_X_loss: 0.0000 | d_fake_loss: 0.0007 | g_loss: 0.0016\n",
            "Iteration [10050/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0006 | d_X_loss: 0.0001 | d_fake_loss: 0.0007 | g_loss: 0.0013\n",
            "Iteration [10060/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0011\n",
            "Iteration [10070/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0003 | d_X_loss: 0.0000 | d_fake_loss: 0.0003 | g_loss: 0.0012\n",
            "Iteration [10080/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0017\n",
            "Iteration [10090/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0023\n",
            "Iteration [10100/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0004 | d_X_loss: 0.0000 | d_fake_loss: 0.0004 | g_loss: 0.0016\n",
            "Iteration [10110/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0002 | d_fake_loss: 0.0003 | g_loss: 0.0011\n",
            "Iteration [10120/20000] | d_real_loss: 0.0008 | d_Y_loss: 0.0001 | d_X_loss: 0.0005 | d_fake_loss: 0.0006 | g_loss: 0.0012\n",
            "Iteration [10130/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0001 | d_X_loss: 0.0004 | d_fake_loss: 0.0005 | g_loss: 0.0010\n",
            "Iteration [10140/20000] | d_real_loss: 0.0009 | d_Y_loss: 0.0003 | d_X_loss: 0.0006 | d_fake_loss: 0.0009 | g_loss: 0.0012\n",
            "Iteration [10150/20000] | d_real_loss: 0.0034 | d_Y_loss: 0.0001 | d_X_loss: 0.0002 | d_fake_loss: 0.0003 | g_loss: 0.0011\n",
            "Iteration [10160/20000] | d_real_loss: 0.0019 | d_Y_loss: 0.0006 | d_X_loss: 0.0003 | d_fake_loss: 0.0009 | g_loss: 0.0014\n",
            "Iteration [10170/20000] | d_real_loss: 0.0016 | d_Y_loss: 0.0007 | d_X_loss: 0.0003 | d_fake_loss: 0.0010 | g_loss: 0.0024\n",
            "Iteration [10180/20000] | d_real_loss: 0.0011 | d_Y_loss: 0.0004 | d_X_loss: 0.0003 | d_fake_loss: 0.0007 | g_loss: 0.0013\n",
            "Iteration [10190/20000] | d_real_loss: 0.0008 | d_Y_loss: 0.0007 | d_X_loss: 0.0000 | d_fake_loss: 0.0007 | g_loss: 0.0011\n",
            "Iteration [10200/20000] | d_real_loss: 0.0010 | d_Y_loss: 0.0006 | d_X_loss: 0.0001 | d_fake_loss: 0.0007 | g_loss: 0.0010\n",
            "Iteration [10210/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0003 | d_X_loss: 0.0001 | d_fake_loss: 0.0004 | g_loss: 0.0012\n",
            "Iteration [10220/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0002 | d_X_loss: 0.0000 | d_fake_loss: 0.0002 | g_loss: 0.0013\n",
            "Iteration [10230/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0002 | d_X_loss: 0.0000 | d_fake_loss: 0.0002 | g_loss: 0.0013\n",
            "Iteration [10240/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0010\n",
            "Iteration [10250/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0002 | g_loss: 0.0014\n",
            "Iteration [10260/20000] | d_real_loss: 0.0010 | d_Y_loss: 0.0006 | d_X_loss: 0.0000 | d_fake_loss: 0.0006 | g_loss: 0.0013\n",
            "Iteration [10270/20000] | d_real_loss: 0.0008 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0010\n",
            "Iteration [10280/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0015\n",
            "Iteration [10290/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0015\n",
            "Iteration [10300/20000] | d_real_loss: 0.0005 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0018\n",
            "Iteration [10310/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0008 | d_X_loss: 0.0000 | d_fake_loss: 0.0009 | g_loss: 0.0017\n",
            "Iteration [10320/20000] | d_real_loss: 0.0015 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0002 | g_loss: 0.0015\n",
            "Iteration [10330/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0003 | d_X_loss: 0.0000 | d_fake_loss: 0.0003 | g_loss: 0.0010\n",
            "Iteration [10340/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0002 | d_X_loss: 0.0000 | d_fake_loss: 0.0002 | g_loss: 0.0015\n",
            "Iteration [10350/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0009 | d_X_loss: 0.0001 | d_fake_loss: 0.0010 | g_loss: 0.0016\n",
            "Iteration [10360/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0005 | d_X_loss: 0.0000 | d_fake_loss: 0.0005 | g_loss: 0.0018\n",
            "Iteration [10370/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0011\n",
            "Iteration [10380/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0010\n",
            "Iteration [10390/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0003 | d_X_loss: 0.0000 | d_fake_loss: 0.0003 | g_loss: 0.0011\n",
            "Iteration [10400/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0002 | g_loss: 0.0010\n",
            "Iteration [10410/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0010\n",
            "Iteration [10420/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0011\n",
            "Iteration [10430/20000] | d_real_loss: 0.0006 | d_Y_loss: 0.0001 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0013\n",
            "Iteration [10440/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0002 | d_fake_loss: 0.0003 | g_loss: 0.0013\n",
            "Iteration [10450/20000] | d_real_loss: 0.0009 | d_Y_loss: 0.0000 | d_X_loss: 0.0002 | d_fake_loss: 0.0002 | g_loss: 0.0013\n",
            "Iteration [10460/20000] | d_real_loss: 0.0005 | d_Y_loss: 0.0000 | d_X_loss: 0.0005 | d_fake_loss: 0.0005 | g_loss: 0.0013\n",
            "Iteration [10470/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0002 | d_fake_loss: 0.0002 | g_loss: 0.0013\n",
            "Iteration [10480/20000] | d_real_loss: 0.0007 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0014\n",
            "Iteration [10490/20000] | d_real_loss: 0.0014 | d_Y_loss: 0.0002 | d_X_loss: 0.0004 | d_fake_loss: 0.0006 | g_loss: 0.0010\n",
            "Iteration [10500/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0003 | d_fake_loss: 0.0003 | g_loss: 0.0010\n",
            "Iteration [10510/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0001 | d_X_loss: 0.0001 | d_fake_loss: 0.0002 | g_loss: 0.0011\n",
            "Iteration [10520/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0011\n",
            "Iteration [10530/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0001 | d_X_loss: 0.0001 | d_fake_loss: 0.0002 | g_loss: 0.0010\n",
            "Iteration [10540/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0012\n",
            "Iteration [10550/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0011\n",
            "Iteration [10560/20000] | d_real_loss: 0.0005 | d_Y_loss: 0.0003 | d_X_loss: 0.0000 | d_fake_loss: 0.0003 | g_loss: 0.0013\n",
            "Iteration [10570/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0011\n",
            "Iteration [10580/20000] | d_real_loss: 0.0006 | d_Y_loss: 0.0004 | d_X_loss: 0.0001 | d_fake_loss: 0.0005 | g_loss: 0.0013\n",
            "Iteration [10590/20000] | d_real_loss: 0.0006 | d_Y_loss: 0.0003 | d_X_loss: 0.0002 | d_fake_loss: 0.0005 | g_loss: 0.0015\n",
            "Iteration [10600/20000] | d_real_loss: 0.0010 | d_Y_loss: 0.0004 | d_X_loss: 0.0000 | d_fake_loss: 0.0004 | g_loss: 0.0012\n",
            "Iteration [10610/20000] | d_real_loss: 0.0011 | d_Y_loss: 0.0000 | d_X_loss: 0.0002 | d_fake_loss: 0.0002 | g_loss: 0.0014\n",
            "Iteration [10620/20000] | d_real_loss: 0.0007 | d_Y_loss: 0.0001 | d_X_loss: 0.0002 | d_fake_loss: 0.0002 | g_loss: 0.0011\n",
            "Iteration [10630/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0000 | d_X_loss: 0.0002 | d_fake_loss: 0.0002 | g_loss: 0.0010\n",
            "Iteration [10640/20000] | d_real_loss: 0.0006 | d_Y_loss: 0.0011 | d_X_loss: 0.0001 | d_fake_loss: 0.0012 | g_loss: 0.0019\n",
            "Iteration [10650/20000] | d_real_loss: 0.0006 | d_Y_loss: 0.0009 | d_X_loss: 0.0000 | d_fake_loss: 0.0009 | g_loss: 0.0027\n",
            "Iteration [10660/20000] | d_real_loss: 0.0026 | d_Y_loss: 0.0002 | d_X_loss: 0.0002 | d_fake_loss: 0.0004 | g_loss: 0.0037\n",
            "Iteration [10670/20000] | d_real_loss: 0.0036 | d_Y_loss: 0.0003 | d_X_loss: 0.0000 | d_fake_loss: 0.0003 | g_loss: 0.0017\n",
            "Iteration [10680/20000] | d_real_loss: 0.0018 | d_Y_loss: 0.0003 | d_X_loss: 0.0002 | d_fake_loss: 0.0004 | g_loss: 0.0013\n",
            "Iteration [10690/20000] | d_real_loss: 0.0023 | d_Y_loss: 0.0002 | d_X_loss: 0.0003 | d_fake_loss: 0.0006 | g_loss: 0.0015\n",
            "Iteration [10700/20000] | d_real_loss: 0.0008 | d_Y_loss: 0.0002 | d_X_loss: 0.0001 | d_fake_loss: 0.0003 | g_loss: 0.0013\n",
            "Iteration [10710/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0002 | d_X_loss: 0.0000 | d_fake_loss: 0.0002 | g_loss: 0.0013\n",
            "Iteration [10720/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0002 | d_X_loss: 0.0002 | d_fake_loss: 0.0004 | g_loss: 0.0018\n",
            "Iteration [10730/20000] | d_real_loss: 0.0006 | d_Y_loss: 0.0002 | d_X_loss: 0.0001 | d_fake_loss: 0.0003 | g_loss: 0.0011\n",
            "Iteration [10740/20000] | d_real_loss: 0.0006 | d_Y_loss: 0.0004 | d_X_loss: 0.0002 | d_fake_loss: 0.0006 | g_loss: 0.0019\n",
            "Iteration [10750/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0012\n",
            "Iteration [10760/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0002 | d_X_loss: 0.0000 | d_fake_loss: 0.0002 | g_loss: 0.0021\n",
            "Iteration [10770/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0001 | d_X_loss: 0.0001 | d_fake_loss: 0.0002 | g_loss: 0.0011\n",
            "Iteration [10780/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0008 | d_X_loss: 0.0000 | d_fake_loss: 0.0008 | g_loss: 0.0010\n",
            "Iteration [10790/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0011\n",
            "Iteration [10800/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0010\n",
            "Iteration [10810/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0015\n",
            "Iteration [10820/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0002 | d_X_loss: 0.0000 | d_fake_loss: 0.0002 | g_loss: 0.0012\n",
            "Iteration [10830/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0006 | d_X_loss: 0.0001 | d_fake_loss: 0.0007 | g_loss: 0.0014\n",
            "Iteration [10840/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0015\n",
            "Iteration [10850/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0005 | d_fake_loss: 0.0006 | g_loss: 0.0013\n",
            "Iteration [10860/20000] | d_real_loss: 0.0008 | d_Y_loss: 0.0004 | d_X_loss: 0.0001 | d_fake_loss: 0.0005 | g_loss: 0.0011\n",
            "Iteration [10870/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0005 | d_fake_loss: 0.0005 | g_loss: 0.0012\n",
            "Iteration [10880/20000] | d_real_loss: 0.0007 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0015\n",
            "Iteration [10890/20000] | d_real_loss: 0.0025 | d_Y_loss: 0.0002 | d_X_loss: 0.0001 | d_fake_loss: 0.0003 | g_loss: 0.0024\n",
            "Iteration [10900/20000] | d_real_loss: 0.0011 | d_Y_loss: 0.0011 | d_X_loss: 0.0000 | d_fake_loss: 0.0011 | g_loss: 0.0010\n",
            "Iteration [10910/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0002 | d_X_loss: 0.0012 | d_fake_loss: 0.0014 | g_loss: 0.0012\n",
            "Iteration [10920/20000] | d_real_loss: 0.0016 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0011\n",
            "Iteration [10930/20000] | d_real_loss: 0.0005 | d_Y_loss: 0.0001 | d_X_loss: 0.0002 | d_fake_loss: 0.0004 | g_loss: 0.0012\n",
            "Iteration [10940/20000] | d_real_loss: 0.0016 | d_Y_loss: 0.0009 | d_X_loss: 0.0006 | d_fake_loss: 0.0016 | g_loss: 0.0012\n",
            "Iteration [10950/20000] | d_real_loss: 0.0040 | d_Y_loss: 0.0005 | d_X_loss: 0.0002 | d_fake_loss: 0.0007 | g_loss: 0.0011\n",
            "Iteration [10960/20000] | d_real_loss: 0.0008 | d_Y_loss: 0.0004 | d_X_loss: 0.0005 | d_fake_loss: 0.0009 | g_loss: 0.0012\n",
            "Iteration [10970/20000] | d_real_loss: 0.0007 | d_Y_loss: 0.0001 | d_X_loss: 0.0002 | d_fake_loss: 0.0003 | g_loss: 0.0012\n",
            "Iteration [10980/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0000 | d_X_loss: 0.0003 | d_fake_loss: 0.0003 | g_loss: 0.0011\n",
            "Iteration [10990/20000] | d_real_loss: 0.0006 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0011\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration [11000/20000] | d_real_loss: 0.0008 | d_Y_loss: 0.0000 | d_X_loss: 0.0004 | d_fake_loss: 0.0005 | g_loss: 0.0011\n",
            "Saved /content/sample-011000-X-Y.png\n",
            "Saved /content/sample-011000-Y-X.png\n",
            "Iteration [11010/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0011\n",
            "Iteration [11020/20000] | d_real_loss: 0.0005 | d_Y_loss: 0.0003 | d_X_loss: 0.0000 | d_fake_loss: 0.0003 | g_loss: 0.0009\n",
            "Iteration [11030/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0000 | d_X_loss: 0.0003 | d_fake_loss: 0.0003 | g_loss: 0.0011\n",
            "Iteration [11040/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0001 | d_X_loss: 0.0001 | d_fake_loss: 0.0002 | g_loss: 0.0011\n",
            "Iteration [11050/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0000 | d_X_loss: 0.0003 | d_fake_loss: 0.0003 | g_loss: 0.0010\n",
            "Iteration [11060/20000] | d_real_loss: 0.0010 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0013\n",
            "Iteration [11070/20000] | d_real_loss: 0.0010 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0021\n",
            "Iteration [11080/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0013\n",
            "Iteration [11090/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0012\n",
            "Iteration [11100/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0014\n",
            "Iteration [11110/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0013\n",
            "Iteration [11120/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0010\n",
            "Iteration [11130/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0012\n",
            "Iteration [11140/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0002 | d_X_loss: 0.0000 | d_fake_loss: 0.0002 | g_loss: 0.0014\n",
            "Iteration [11150/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0012\n",
            "Iteration [11160/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0003 | d_X_loss: 0.0001 | d_fake_loss: 0.0004 | g_loss: 0.0010\n",
            "Iteration [11170/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0010\n",
            "Iteration [11180/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0011\n",
            "Iteration [11190/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0009\n",
            "Iteration [11200/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0009\n",
            "Iteration [11210/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0011\n",
            "Iteration [11220/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0011\n",
            "Iteration [11230/20000] | d_real_loss: 0.0006 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0015\n",
            "Iteration [11240/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0009\n",
            "Iteration [11250/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0013\n",
            "Iteration [11260/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0010\n",
            "Iteration [11270/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0010\n",
            "Iteration [11280/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0001 | d_X_loss: 0.0001 | d_fake_loss: 0.0002 | g_loss: 0.0015\n",
            "Iteration [11290/20000] | d_real_loss: 0.0005 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0013\n",
            "Iteration [11300/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0002 | d_X_loss: 0.0000 | d_fake_loss: 0.0002 | g_loss: 0.0012\n",
            "Iteration [11310/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0008 | d_X_loss: 0.0001 | d_fake_loss: 0.0009 | g_loss: 0.0011\n",
            "Iteration [11320/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0002 | d_X_loss: 0.0000 | d_fake_loss: 0.0002 | g_loss: 0.0011\n",
            "Iteration [11330/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0010\n",
            "Iteration [11340/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0013\n",
            "Iteration [11350/20000] | d_real_loss: 0.0005 | d_Y_loss: 0.0002 | d_X_loss: 0.0003 | d_fake_loss: 0.0004 | g_loss: 0.0011\n",
            "Iteration [11360/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0001 | d_X_loss: 0.0004 | d_fake_loss: 0.0005 | g_loss: 0.0011\n",
            "Iteration [11370/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0002 | d_fake_loss: 0.0002 | g_loss: 0.0010\n",
            "Iteration [11380/20000] | d_real_loss: 0.0011 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0014\n",
            "Iteration [11390/20000] | d_real_loss: 0.0009 | d_Y_loss: 0.0001 | d_X_loss: 0.0001 | d_fake_loss: 0.0003 | g_loss: 0.0011\n",
            "Iteration [11400/20000] | d_real_loss: 0.0032 | d_Y_loss: 0.0003 | d_X_loss: 0.0005 | d_fake_loss: 0.0008 | g_loss: 0.0019\n",
            "Iteration [11410/20000] | d_real_loss: 0.0037 | d_Y_loss: 0.0002 | d_X_loss: 0.0002 | d_fake_loss: 0.0003 | g_loss: 0.0013\n",
            "Iteration [11420/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0005 | d_fake_loss: 0.0005 | g_loss: 0.0014\n",
            "Iteration [11430/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0010\n",
            "Iteration [11440/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0002 | d_fake_loss: 0.0002 | g_loss: 0.0012\n",
            "Iteration [11450/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0011\n",
            "Iteration [11460/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0012\n",
            "Iteration [11470/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0006 | d_X_loss: 0.0000 | d_fake_loss: 0.0006 | g_loss: 0.0017\n",
            "Iteration [11480/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0004 | d_X_loss: 0.0000 | d_fake_loss: 0.0004 | g_loss: 0.0015\n",
            "Iteration [11490/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0006 | d_X_loss: 0.0000 | d_fake_loss: 0.0006 | g_loss: 0.0012\n",
            "Iteration [11500/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0010\n",
            "Iteration [11510/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0003 | d_X_loss: 0.0000 | d_fake_loss: 0.0003 | g_loss: 0.0009\n",
            "Iteration [11520/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0014\n",
            "Iteration [11530/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0003 | d_X_loss: 0.0000 | d_fake_loss: 0.0003 | g_loss: 0.0009\n",
            "Iteration [11540/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0014\n",
            "Iteration [11550/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0010\n",
            "Iteration [11560/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0010\n",
            "Iteration [11570/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0010\n",
            "Iteration [11580/20000] | d_real_loss: 0.0005 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0013\n",
            "Iteration [11590/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0002 | d_X_loss: 0.0000 | d_fake_loss: 0.0002 | g_loss: 0.0010\n",
            "Iteration [11600/20000] | d_real_loss: 0.0009 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0012\n",
            "Iteration [11610/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0009\n",
            "Iteration [11620/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0003 | d_X_loss: 0.0000 | d_fake_loss: 0.0003 | g_loss: 0.0011\n",
            "Iteration [11630/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0004 | d_X_loss: 0.0000 | d_fake_loss: 0.0004 | g_loss: 0.0009\n",
            "Iteration [11640/20000] | d_real_loss: 0.0006 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0002 | g_loss: 0.0010\n",
            "Iteration [11650/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0012\n",
            "Iteration [11660/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0015\n",
            "Iteration [11670/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0010\n",
            "Iteration [11680/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0011\n",
            "Iteration [11690/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0000 | d_X_loss: 0.0002 | d_fake_loss: 0.0002 | g_loss: 0.0010\n",
            "Iteration [11700/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0012\n",
            "Iteration [11710/20000] | d_real_loss: 0.0010 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0012\n",
            "Iteration [11720/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0002 | g_loss: 0.0012\n",
            "Iteration [11730/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0010\n",
            "Iteration [11740/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0012\n",
            "Iteration [11750/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0010\n",
            "Iteration [11760/20000] | d_real_loss: 0.0007 | d_Y_loss: 0.0001 | d_X_loss: 0.0002 | d_fake_loss: 0.0003 | g_loss: 0.0008\n",
            "Iteration [11770/20000] | d_real_loss: 0.0005 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0002 | g_loss: 0.0011\n",
            "Iteration [11780/20000] | d_real_loss: 0.0006 | d_Y_loss: 0.0005 | d_X_loss: 0.0002 | d_fake_loss: 0.0007 | g_loss: 0.0010\n",
            "Iteration [11790/20000] | d_real_loss: 0.0005 | d_Y_loss: 0.0013 | d_X_loss: 0.0000 | d_fake_loss: 0.0013 | g_loss: 0.0015\n",
            "Iteration [11800/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0011 | d_X_loss: 0.0001 | d_fake_loss: 0.0012 | g_loss: 0.0013\n",
            "Iteration [11810/20000] | d_real_loss: 0.0005 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0013\n",
            "Iteration [11820/20000] | d_real_loss: 0.0008 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0015\n",
            "Iteration [11830/20000] | d_real_loss: 0.0007 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0010\n",
            "Iteration [11840/20000] | d_real_loss: 0.0005 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0011\n",
            "Iteration [11850/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0001 | d_X_loss: 0.0002 | d_fake_loss: 0.0002 | g_loss: 0.0012\n",
            "Iteration [11860/20000] | d_real_loss: 0.0008 | d_Y_loss: 0.0005 | d_X_loss: 0.0000 | d_fake_loss: 0.0006 | g_loss: 0.0009\n",
            "Iteration [11870/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0002 | d_X_loss: 0.0000 | d_fake_loss: 0.0002 | g_loss: 0.0010\n",
            "Iteration [11880/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0011\n",
            "Iteration [11890/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0002 | g_loss: 0.0009\n",
            "Iteration [11900/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0010\n",
            "Iteration [11910/20000] | d_real_loss: 0.0005 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0009\n",
            "Iteration [11920/20000] | d_real_loss: 0.0036 | d_Y_loss: 0.0003 | d_X_loss: 0.0012 | d_fake_loss: 0.0015 | g_loss: 0.0010\n",
            "Iteration [11930/20000] | d_real_loss: 0.0008 | d_Y_loss: 0.0000 | d_X_loss: 0.0008 | d_fake_loss: 0.0009 | g_loss: 0.0011\n",
            "Iteration [11940/20000] | d_real_loss: 0.0008 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0002 | g_loss: 0.0012\n",
            "Iteration [11950/20000] | d_real_loss: 0.0007 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0002 | g_loss: 0.0009\n",
            "Iteration [11960/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0010\n",
            "Iteration [11970/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0001 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0010\n",
            "Iteration [11980/20000] | d_real_loss: 0.0006 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0012\n",
            "Iteration [11990/20000] | d_real_loss: 0.0005 | d_Y_loss: 0.0001 | d_X_loss: 0.0003 | d_fake_loss: 0.0004 | g_loss: 0.0011\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration [12000/20000] | d_real_loss: 0.0006 | d_Y_loss: 0.0001 | d_X_loss: 0.0002 | d_fake_loss: 0.0002 | g_loss: 0.0010\n",
            "Saved /content/sample-012000-X-Y.png\n",
            "Saved /content/sample-012000-Y-X.png\n",
            "Iteration [12010/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0003 | d_X_loss: 0.0003 | d_fake_loss: 0.0006 | g_loss: 0.0010\n",
            "Iteration [12020/20000] | d_real_loss: 0.0005 | d_Y_loss: 0.0001 | d_X_loss: 0.0001 | d_fake_loss: 0.0002 | g_loss: 0.0011\n",
            "Iteration [12030/20000] | d_real_loss: 0.0020 | d_Y_loss: 0.0003 | d_X_loss: 0.0001 | d_fake_loss: 0.0004 | g_loss: 0.0016\n",
            "Iteration [12040/20000] | d_real_loss: 0.0010 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0014\n",
            "Iteration [12050/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0002 | d_X_loss: 0.0000 | d_fake_loss: 0.0002 | g_loss: 0.0011\n",
            "Iteration [12060/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0009\n",
            "Iteration [12070/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0003 | d_X_loss: 0.0000 | d_fake_loss: 0.0003 | g_loss: 0.0010\n",
            "Iteration [12080/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0003 | d_X_loss: 0.0000 | d_fake_loss: 0.0003 | g_loss: 0.0014\n",
            "Iteration [12090/20000] | d_real_loss: 0.0005 | d_Y_loss: 0.0005 | d_X_loss: 0.0000 | d_fake_loss: 0.0005 | g_loss: 0.0010\n",
            "Iteration [12100/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0010\n",
            "Iteration [12110/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0001 | d_X_loss: 0.0001 | d_fake_loss: 0.0002 | g_loss: 0.0009\n",
            "Iteration [12120/20000] | d_real_loss: 0.0007 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0002 | g_loss: 0.0020\n",
            "Iteration [12130/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0001 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0009\n",
            "Iteration [12140/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0002 | d_X_loss: 0.0000 | d_fake_loss: 0.0002 | g_loss: 0.0014\n",
            "Iteration [12150/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0002 | d_X_loss: 0.0000 | d_fake_loss: 0.0002 | g_loss: 0.0011\n",
            "Iteration [12160/20000] | d_real_loss: 0.0011 | d_Y_loss: 0.0000 | d_X_loss: 0.0004 | d_fake_loss: 0.0005 | g_loss: 0.0010\n",
            "Iteration [12170/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0010\n",
            "Iteration [12180/20000] | d_real_loss: 0.0006 | d_Y_loss: 0.0005 | d_X_loss: 0.0002 | d_fake_loss: 0.0006 | g_loss: 0.0009\n",
            "Iteration [12190/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0012\n",
            "Iteration [12200/20000] | d_real_loss: 0.0013 | d_Y_loss: 0.0002 | d_X_loss: 0.0001 | d_fake_loss: 0.0003 | g_loss: 0.0010\n",
            "Iteration [12210/20000] | d_real_loss: 0.0011 | d_Y_loss: 0.0002 | d_X_loss: 0.0000 | d_fake_loss: 0.0002 | g_loss: 0.0009\n",
            "Iteration [12220/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0005 | d_fake_loss: 0.0005 | g_loss: 0.0011\n",
            "Iteration [12230/20000] | d_real_loss: 0.0005 | d_Y_loss: 0.0001 | d_X_loss: 0.0001 | d_fake_loss: 0.0002 | g_loss: 0.0012\n",
            "Iteration [12240/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0002 | d_fake_loss: 0.0002 | g_loss: 0.0009\n",
            "Iteration [12250/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0011\n",
            "Iteration [12260/20000] | d_real_loss: 0.0005 | d_Y_loss: 0.0002 | d_X_loss: 0.0000 | d_fake_loss: 0.0002 | g_loss: 0.0012\n",
            "Iteration [12270/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0010\n",
            "Iteration [12280/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0011\n",
            "Iteration [12290/20000] | d_real_loss: 0.0008 | d_Y_loss: 0.0002 | d_X_loss: 0.0000 | d_fake_loss: 0.0003 | g_loss: 0.0010\n",
            "Iteration [12300/20000] | d_real_loss: 0.0013 | d_Y_loss: 0.0003 | d_X_loss: 0.0001 | d_fake_loss: 0.0004 | g_loss: 0.0011\n",
            "Iteration [12310/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0003 | d_X_loss: 0.0000 | d_fake_loss: 0.0003 | g_loss: 0.0010\n",
            "Iteration [12320/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0010\n",
            "Iteration [12330/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0003 | d_X_loss: 0.0001 | d_fake_loss: 0.0003 | g_loss: 0.0013\n",
            "Iteration [12340/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0001 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0010\n",
            "Iteration [12350/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0011\n",
            "Iteration [12360/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0011\n",
            "Iteration [12370/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0001 | d_X_loss: 0.0002 | d_fake_loss: 0.0002 | g_loss: 0.0010\n",
            "Iteration [12380/20000] | d_real_loss: 0.0006 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0010\n",
            "Iteration [12390/20000] | d_real_loss: 0.0025 | d_Y_loss: 0.0001 | d_X_loss: 0.0002 | d_fake_loss: 0.0003 | g_loss: 0.0009\n",
            "Iteration [12400/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0001 | d_X_loss: 0.0002 | d_fake_loss: 0.0003 | g_loss: 0.0009\n",
            "Iteration [12410/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0002 | d_X_loss: 0.0001 | d_fake_loss: 0.0003 | g_loss: 0.0010\n",
            "Iteration [12420/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0009\n",
            "Iteration [12430/20000] | d_real_loss: 0.0005 | d_Y_loss: 0.0007 | d_X_loss: 0.0001 | d_fake_loss: 0.0007 | g_loss: 0.0013\n",
            "Iteration [12440/20000] | d_real_loss: 0.0006 | d_Y_loss: 0.0012 | d_X_loss: 0.0000 | d_fake_loss: 0.0012 | g_loss: 0.0014\n",
            "Iteration [12450/20000] | d_real_loss: 0.0012 | d_Y_loss: 0.0004 | d_X_loss: 0.0000 | d_fake_loss: 0.0004 | g_loss: 0.0016\n",
            "Iteration [12460/20000] | d_real_loss: 0.0033 | d_Y_loss: 0.0030 | d_X_loss: 0.0001 | d_fake_loss: 0.0031 | g_loss: 0.0024\n",
            "Iteration [12470/20000] | d_real_loss: 0.0039 | d_Y_loss: 0.0013 | d_X_loss: 0.0001 | d_fake_loss: 0.0014 | g_loss: 0.0094\n",
            "Iteration [12480/20000] | d_real_loss: 0.0015 | d_Y_loss: 0.0004 | d_X_loss: 0.0001 | d_fake_loss: 0.0005 | g_loss: 0.0042\n",
            "Iteration [12490/20000] | d_real_loss: 0.0005 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0022\n",
            "Iteration [12500/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0001 | d_X_loss: 0.0001 | d_fake_loss: 0.0002 | g_loss: 0.0016\n",
            "Iteration [12510/20000] | d_real_loss: 0.0018 | d_Y_loss: 0.0005 | d_X_loss: 0.0001 | d_fake_loss: 0.0006 | g_loss: 0.0022\n",
            "Iteration [12520/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0007 | d_X_loss: 0.0001 | d_fake_loss: 0.0008 | g_loss: 0.0018\n",
            "Iteration [12530/20000] | d_real_loss: 0.0009 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0016\n",
            "Iteration [12540/20000] | d_real_loss: 0.0028 | d_Y_loss: 0.0000 | d_X_loss: 0.0002 | d_fake_loss: 0.0002 | g_loss: 0.0010\n",
            "Iteration [12550/20000] | d_real_loss: 0.0005 | d_Y_loss: 0.0002 | d_X_loss: 0.0002 | d_fake_loss: 0.0004 | g_loss: 0.0011\n",
            "Iteration [12560/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0002 | d_X_loss: 0.0001 | d_fake_loss: 0.0003 | g_loss: 0.0010\n",
            "Iteration [12570/20000] | d_real_loss: 0.0005 | d_Y_loss: 0.0002 | d_X_loss: 0.0000 | d_fake_loss: 0.0003 | g_loss: 0.0012\n",
            "Iteration [12580/20000] | d_real_loss: 0.0012 | d_Y_loss: 0.0002 | d_X_loss: 0.0001 | d_fake_loss: 0.0002 | g_loss: 0.0019\n",
            "Iteration [12590/20000] | d_real_loss: 0.0006 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0002 | g_loss: 0.0017\n",
            "Iteration [12600/20000] | d_real_loss: 0.0017 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0020\n",
            "Iteration [12610/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0002 | d_X_loss: 0.0000 | d_fake_loss: 0.0003 | g_loss: 0.0013\n",
            "Iteration [12620/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0011\n",
            "Iteration [12630/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0008 | d_X_loss: 0.0000 | d_fake_loss: 0.0008 | g_loss: 0.0014\n",
            "Iteration [12640/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0002 | d_X_loss: 0.0000 | d_fake_loss: 0.0003 | g_loss: 0.0010\n",
            "Iteration [12650/20000] | d_real_loss: 0.0006 | d_Y_loss: 0.0004 | d_X_loss: 0.0000 | d_fake_loss: 0.0005 | g_loss: 0.0018\n",
            "Iteration [12660/20000] | d_real_loss: 0.0005 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0012\n",
            "Iteration [12670/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0002 | g_loss: 0.0009\n",
            "Iteration [12680/20000] | d_real_loss: 0.0006 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0012\n",
            "Iteration [12690/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0010\n",
            "Iteration [12700/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0015\n",
            "Iteration [12710/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0009\n",
            "Iteration [12720/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0011\n",
            "Iteration [12730/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0013\n",
            "Iteration [12740/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0009\n",
            "Iteration [12750/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0009\n",
            "Iteration [12760/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0002 | d_X_loss: 0.0002 | d_fake_loss: 0.0003 | g_loss: 0.0010\n",
            "Iteration [12770/20000] | d_real_loss: 0.0005 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0016\n",
            "Iteration [12780/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0012\n",
            "Iteration [12790/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0010\n",
            "Iteration [12800/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0003 | d_X_loss: 0.0000 | d_fake_loss: 0.0003 | g_loss: 0.0008\n",
            "Iteration [12810/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0002 | g_loss: 0.0011\n",
            "Iteration [12820/20000] | d_real_loss: 0.0010 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0014\n",
            "Iteration [12830/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0011\n",
            "Iteration [12840/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0010\n",
            "Iteration [12850/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0009\n",
            "Iteration [12860/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0010\n",
            "Iteration [12870/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0009\n",
            "Iteration [12880/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0003 | d_fake_loss: 0.0003 | g_loss: 0.0012\n",
            "Iteration [12890/20000] | d_real_loss: 0.0011 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0010\n",
            "Iteration [12900/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0009\n",
            "Iteration [12910/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0000 | d_X_loss: 0.0002 | d_fake_loss: 0.0002 | g_loss: 0.0012\n",
            "Iteration [12920/20000] | d_real_loss: 0.0006 | d_Y_loss: 0.0005 | d_X_loss: 0.0002 | d_fake_loss: 0.0007 | g_loss: 0.0012\n",
            "Iteration [12930/20000] | d_real_loss: 0.0010 | d_Y_loss: 0.0000 | d_X_loss: 0.0002 | d_fake_loss: 0.0002 | g_loss: 0.0014\n",
            "Iteration [12940/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0001 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0012\n",
            "Iteration [12950/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0001 | d_X_loss: 0.0001 | d_fake_loss: 0.0002 | g_loss: 0.0014\n",
            "Iteration [12960/20000] | d_real_loss: 0.0007 | d_Y_loss: 0.0002 | d_X_loss: 0.0000 | d_fake_loss: 0.0002 | g_loss: 0.0009\n",
            "Iteration [12970/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0011\n",
            "Iteration [12980/20000] | d_real_loss: 0.0010 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0012\n",
            "Iteration [12990/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0005 | d_X_loss: 0.0001 | d_fake_loss: 0.0005 | g_loss: 0.0010\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration [13000/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0002 | d_X_loss: 0.0002 | d_fake_loss: 0.0004 | g_loss: 0.0015\n",
            "Saved /content/sample-013000-X-Y.png\n",
            "Saved /content/sample-013000-Y-X.png\n",
            "Iteration [13010/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0004 | d_X_loss: 0.0000 | d_fake_loss: 0.0004 | g_loss: 0.0012\n",
            "Iteration [13020/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0010\n",
            "Iteration [13030/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0009\n",
            "Iteration [13040/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0013\n",
            "Iteration [13050/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0010\n",
            "Iteration [13060/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0010\n",
            "Iteration [13070/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0001 | d_X_loss: 0.0002 | d_fake_loss: 0.0003 | g_loss: 0.0010\n",
            "Iteration [13080/20000] | d_real_loss: 0.0009 | d_Y_loss: 0.0000 | d_X_loss: 0.0002 | d_fake_loss: 0.0002 | g_loss: 0.0011\n",
            "Iteration [13090/20000] | d_real_loss: 0.0010 | d_Y_loss: 0.0000 | d_X_loss: 0.0004 | d_fake_loss: 0.0005 | g_loss: 0.0008\n",
            "Iteration [13100/20000] | d_real_loss: 0.0006 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0014\n",
            "Iteration [13110/20000] | d_real_loss: 0.0028 | d_Y_loss: 0.0000 | d_X_loss: 0.0006 | d_fake_loss: 0.0006 | g_loss: 0.0011\n",
            "Iteration [13120/20000] | d_real_loss: 0.0007 | d_Y_loss: 0.0002 | d_X_loss: 0.0001 | d_fake_loss: 0.0003 | g_loss: 0.0011\n",
            "Iteration [13130/20000] | d_real_loss: 0.0020 | d_Y_loss: 0.0001 | d_X_loss: 0.0006 | d_fake_loss: 0.0007 | g_loss: 0.0018\n",
            "Iteration [13140/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0010\n",
            "Iteration [13150/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0002 | d_X_loss: 0.0001 | d_fake_loss: 0.0003 | g_loss: 0.0013\n",
            "Iteration [13160/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0011\n",
            "Iteration [13170/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0002 | g_loss: 0.0013\n",
            "Iteration [13180/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0003 | d_X_loss: 0.0000 | d_fake_loss: 0.0003 | g_loss: 0.0012\n",
            "Iteration [13190/20000] | d_real_loss: 0.0009 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0014\n",
            "Iteration [13200/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0009\n",
            "Iteration [13210/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0009\n",
            "Iteration [13220/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0005 | d_X_loss: 0.0001 | d_fake_loss: 0.0006 | g_loss: 0.0012\n",
            "Iteration [13230/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0012\n",
            "Iteration [13240/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0010\n",
            "Iteration [13250/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0003 | d_X_loss: 0.0000 | d_fake_loss: 0.0003 | g_loss: 0.0010\n",
            "Iteration [13260/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0016\n",
            "Iteration [13270/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0013\n",
            "Iteration [13280/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0009\n",
            "Iteration [13290/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0002 | d_X_loss: 0.0000 | d_fake_loss: 0.0002 | g_loss: 0.0009\n",
            "Iteration [13300/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0002 | d_X_loss: 0.0000 | d_fake_loss: 0.0002 | g_loss: 0.0015\n",
            "Iteration [13310/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0009\n",
            "Iteration [13320/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0003 | d_X_loss: 0.0000 | d_fake_loss: 0.0003 | g_loss: 0.0014\n",
            "Iteration [13330/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0010\n",
            "Iteration [13340/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0008\n",
            "Iteration [13350/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0010\n",
            "Iteration [13360/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0009\n",
            "Iteration [13370/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0008\n",
            "Iteration [13380/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0004 | d_X_loss: 0.0000 | d_fake_loss: 0.0004 | g_loss: 0.0015\n",
            "Iteration [13390/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0004 | d_X_loss: 0.0000 | d_fake_loss: 0.0004 | g_loss: 0.0010\n",
            "Iteration [13400/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0013\n",
            "Iteration [13410/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0005 | d_X_loss: 0.0000 | d_fake_loss: 0.0005 | g_loss: 0.0009\n",
            "Iteration [13420/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0002 | d_X_loss: 0.0000 | d_fake_loss: 0.0002 | g_loss: 0.0011\n",
            "Iteration [13430/20000] | d_real_loss: 0.0011 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0025\n",
            "Iteration [13440/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0008\n",
            "Iteration [13450/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0001 | d_X_loss: 0.0002 | d_fake_loss: 0.0002 | g_loss: 0.0008\n",
            "Iteration [13460/20000] | d_real_loss: 0.0011 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0002 | g_loss: 0.0011\n",
            "Iteration [13470/20000] | d_real_loss: 0.0011 | d_Y_loss: 0.0004 | d_X_loss: 0.0013 | d_fake_loss: 0.0017 | g_loss: 0.0013\n",
            "Iteration [13480/20000] | d_real_loss: 0.0026 | d_Y_loss: 0.0001 | d_X_loss: 0.0001 | d_fake_loss: 0.0002 | g_loss: 0.0010\n",
            "Iteration [13490/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0005 | d_fake_loss: 0.0006 | g_loss: 0.0010\n",
            "Iteration [13500/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0001 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0008\n",
            "Iteration [13510/20000] | d_real_loss: 0.0010 | d_Y_loss: 0.0007 | d_X_loss: 0.0001 | d_fake_loss: 0.0007 | g_loss: 0.0010\n",
            "Iteration [13520/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0008\n",
            "Iteration [13530/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0003 | d_X_loss: 0.0000 | d_fake_loss: 0.0003 | g_loss: 0.0009\n",
            "Iteration [13540/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0008\n",
            "Iteration [13550/20000] | d_real_loss: 0.0009 | d_Y_loss: 0.0002 | d_X_loss: 0.0000 | d_fake_loss: 0.0002 | g_loss: 0.0012\n",
            "Iteration [13560/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0002 | d_X_loss: 0.0000 | d_fake_loss: 0.0002 | g_loss: 0.0011\n",
            "Iteration [13570/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0008\n",
            "Iteration [13580/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0003 | d_X_loss: 0.0000 | d_fake_loss: 0.0003 | g_loss: 0.0009\n",
            "Iteration [13590/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0010\n",
            "Iteration [13600/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0010\n",
            "Iteration [13610/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0001 | d_X_loss: 0.0001 | d_fake_loss: 0.0002 | g_loss: 0.0010\n",
            "Iteration [13620/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0012\n",
            "Iteration [13630/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0004 | d_X_loss: 0.0000 | d_fake_loss: 0.0005 | g_loss: 0.0008\n",
            "Iteration [13640/20000] | d_real_loss: 0.0007 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0012\n",
            "Iteration [13650/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0016\n",
            "Iteration [13660/20000] | d_real_loss: 0.0005 | d_Y_loss: 0.0001 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0011\n",
            "Iteration [13670/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0007\n",
            "Iteration [13680/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0008\n",
            "Iteration [13690/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0010\n",
            "Iteration [13700/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0012\n",
            "Iteration [13710/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0009\n",
            "Iteration [13720/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0003 | d_X_loss: 0.0000 | d_fake_loss: 0.0003 | g_loss: 0.0012\n",
            "Iteration [13730/20000] | d_real_loss: 0.0008 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0010\n",
            "Iteration [13740/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0008\n",
            "Iteration [13750/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0003 | d_X_loss: 0.0000 | d_fake_loss: 0.0004 | g_loss: 0.0008\n",
            "Iteration [13760/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0009\n",
            "Iteration [13770/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0008\n",
            "Iteration [13780/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0002 | d_X_loss: 0.0000 | d_fake_loss: 0.0002 | g_loss: 0.0009\n",
            "Iteration [13790/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0005 | d_X_loss: 0.0000 | d_fake_loss: 0.0005 | g_loss: 0.0020\n",
            "Iteration [13800/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0003 | d_X_loss: 0.0000 | d_fake_loss: 0.0003 | g_loss: 0.0008\n",
            "Iteration [13810/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0013\n",
            "Iteration [13820/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0004 | d_X_loss: 0.0000 | d_fake_loss: 0.0004 | g_loss: 0.0011\n",
            "Iteration [13830/20000] | d_real_loss: 0.0007 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0012\n",
            "Iteration [13840/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0011\n",
            "Iteration [13850/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0005 | d_X_loss: 0.0001 | d_fake_loss: 0.0006 | g_loss: 0.0009\n",
            "Iteration [13860/20000] | d_real_loss: 0.0007 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0012\n",
            "Iteration [13870/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0009\n",
            "Iteration [13880/20000] | d_real_loss: 0.0006 | d_Y_loss: 0.0002 | d_X_loss: 0.0000 | d_fake_loss: 0.0003 | g_loss: 0.0015\n",
            "Iteration [13890/20000] | d_real_loss: 0.0011 | d_Y_loss: 0.0003 | d_X_loss: 0.0000 | d_fake_loss: 0.0004 | g_loss: 0.0008\n",
            "Iteration [13900/20000] | d_real_loss: 0.0008 | d_Y_loss: 0.0001 | d_X_loss: 0.0009 | d_fake_loss: 0.0010 | g_loss: 0.0008\n",
            "Iteration [13910/20000] | d_real_loss: 0.0007 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0008\n",
            "Iteration [13920/20000] | d_real_loss: 0.0005 | d_Y_loss: 0.0001 | d_X_loss: 0.0011 | d_fake_loss: 0.0011 | g_loss: 0.0012\n",
            "Iteration [13930/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0004 | d_X_loss: 0.0001 | d_fake_loss: 0.0005 | g_loss: 0.0011\n",
            "Iteration [13940/20000] | d_real_loss: 0.0024 | d_Y_loss: 0.0000 | d_X_loss: 0.0005 | d_fake_loss: 0.0005 | g_loss: 0.0011\n",
            "Iteration [13950/20000] | d_real_loss: 0.0032 | d_Y_loss: 0.0000 | d_X_loss: 0.0002 | d_fake_loss: 0.0003 | g_loss: 0.0012\n",
            "Iteration [13960/20000] | d_real_loss: 0.0011 | d_Y_loss: 0.0001 | d_X_loss: 0.0005 | d_fake_loss: 0.0005 | g_loss: 0.0008\n",
            "Iteration [13970/20000] | d_real_loss: 0.0197 | d_Y_loss: 0.0002 | d_X_loss: 0.0065 | d_fake_loss: 0.0068 | g_loss: 0.0025\n",
            "Iteration [13980/20000] | d_real_loss: 0.0018 | d_Y_loss: 0.0000 | d_X_loss: 0.0008 | d_fake_loss: 0.0008 | g_loss: 0.0024\n",
            "Iteration [13990/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0012\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration [14000/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0013\n",
            "Saved /content/sample-014000-X-Y.png\n",
            "Saved /content/sample-014000-Y-X.png\n",
            "Iteration [14010/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0015\n",
            "Iteration [14020/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0009\n",
            "Iteration [14030/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0010\n",
            "Iteration [14040/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0010\n",
            "Iteration [14050/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0016\n",
            "Iteration [14060/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0010\n",
            "Iteration [14070/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0000 | d_X_loss: 0.0002 | d_fake_loss: 0.0002 | g_loss: 0.0009\n",
            "Iteration [14080/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0009\n",
            "Iteration [14090/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0010\n",
            "Iteration [14100/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0011\n",
            "Iteration [14110/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0001 | d_X_loss: 0.0002 | d_fake_loss: 0.0002 | g_loss: 0.0010\n",
            "Iteration [14120/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0008\n",
            "Iteration [14130/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0007\n",
            "Iteration [14140/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0002 | d_X_loss: 0.0000 | d_fake_loss: 0.0002 | g_loss: 0.0008\n",
            "Iteration [14150/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0002 | g_loss: 0.0008\n",
            "Iteration [14160/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0003 | d_X_loss: 0.0000 | d_fake_loss: 0.0003 | g_loss: 0.0010\n",
            "Iteration [14170/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0011\n",
            "Iteration [14180/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0002 | d_X_loss: 0.0000 | d_fake_loss: 0.0002 | g_loss: 0.0010\n",
            "Iteration [14190/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0008\n",
            "Iteration [14200/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0009\n",
            "Iteration [14210/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0008\n",
            "Iteration [14220/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0009\n",
            "Iteration [14230/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0010\n",
            "Iteration [14240/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0003 | d_X_loss: 0.0000 | d_fake_loss: 0.0003 | g_loss: 0.0010\n",
            "Iteration [14250/20000] | d_real_loss: 0.0022 | d_Y_loss: 0.0026 | d_X_loss: 0.0000 | d_fake_loss: 0.0026 | g_loss: 0.0014\n",
            "Iteration [14260/20000] | d_real_loss: 0.0008 | d_Y_loss: 0.0005 | d_X_loss: 0.0000 | d_fake_loss: 0.0005 | g_loss: 0.0009\n",
            "Iteration [14270/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0004 | d_X_loss: 0.0000 | d_fake_loss: 0.0004 | g_loss: 0.0010\n",
            "Iteration [14280/20000] | d_real_loss: 0.0007 | d_Y_loss: 0.0006 | d_X_loss: 0.0000 | d_fake_loss: 0.0007 | g_loss: 0.0010\n",
            "Iteration [14290/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0011\n",
            "Iteration [14300/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0008 | d_X_loss: 0.0000 | d_fake_loss: 0.0008 | g_loss: 0.0025\n",
            "Iteration [14310/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0005 | d_X_loss: 0.0001 | d_fake_loss: 0.0006 | g_loss: 0.0008\n",
            "Iteration [14320/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0010\n",
            "Iteration [14330/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0014\n",
            "Iteration [14340/20000] | d_real_loss: 0.0014 | d_Y_loss: 0.0004 | d_X_loss: 0.0000 | d_fake_loss: 0.0005 | g_loss: 0.0012\n",
            "Iteration [14350/20000] | d_real_loss: 0.0005 | d_Y_loss: 0.0005 | d_X_loss: 0.0000 | d_fake_loss: 0.0005 | g_loss: 0.0015\n",
            "Iteration [14360/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0015 | d_X_loss: 0.0000 | d_fake_loss: 0.0015 | g_loss: 0.0010\n",
            "Iteration [14370/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0011\n",
            "Iteration [14380/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0012\n",
            "Iteration [14390/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0002 | d_X_loss: 0.0000 | d_fake_loss: 0.0002 | g_loss: 0.0009\n",
            "Iteration [14400/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0008\n",
            "Iteration [14410/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0002 | d_X_loss: 0.0000 | d_fake_loss: 0.0002 | g_loss: 0.0008\n",
            "Iteration [14420/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0009\n",
            "Iteration [14430/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0008\n",
            "Iteration [14440/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0010\n",
            "Iteration [14450/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0008\n",
            "Iteration [14460/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0008\n",
            "Iteration [14470/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0009\n",
            "Iteration [14480/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0007\n",
            "Iteration [14490/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0001 | d_X_loss: 0.0001 | d_fake_loss: 0.0002 | g_loss: 0.0010\n",
            "Iteration [14500/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0008\n",
            "Iteration [14510/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0008\n",
            "Iteration [14520/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0010\n",
            "Iteration [14530/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0008\n",
            "Iteration [14540/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0009\n",
            "Iteration [14550/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0007\n",
            "Iteration [14560/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0007\n",
            "Iteration [14570/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0008\n",
            "Iteration [14580/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0002 | d_X_loss: 0.0000 | d_fake_loss: 0.0002 | g_loss: 0.0010\n",
            "Iteration [14590/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0002 | d_X_loss: 0.0000 | d_fake_loss: 0.0002 | g_loss: 0.0011\n",
            "Iteration [14600/20000] | d_real_loss: 0.0007 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0012\n",
            "Iteration [14610/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0002 | d_X_loss: 0.0001 | d_fake_loss: 0.0003 | g_loss: 0.0010\n",
            "Iteration [14620/20000] | d_real_loss: 0.0005 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0011\n",
            "Iteration [14630/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0007 | d_X_loss: 0.0000 | d_fake_loss: 0.0007 | g_loss: 0.0009\n",
            "Iteration [14640/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0009\n",
            "Iteration [14650/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0007\n",
            "Iteration [14660/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0007 | d_X_loss: 0.0000 | d_fake_loss: 0.0008 | g_loss: 0.0011\n",
            "Iteration [14670/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0010\n",
            "Iteration [14680/20000] | d_real_loss: 0.0006 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0009\n",
            "Iteration [14690/20000] | d_real_loss: 0.0007 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0009\n",
            "Iteration [14700/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0001 | d_X_loss: 0.0004 | d_fake_loss: 0.0005 | g_loss: 0.0009\n",
            "Iteration [14710/20000] | d_real_loss: 0.0007 | d_Y_loss: 0.0006 | d_X_loss: 0.0000 | d_fake_loss: 0.0007 | g_loss: 0.0009\n",
            "Iteration [14720/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0001 | d_X_loss: 0.0002 | d_fake_loss: 0.0003 | g_loss: 0.0009\n",
            "Iteration [14730/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0001 | d_X_loss: 0.0001 | d_fake_loss: 0.0002 | g_loss: 0.0016\n",
            "Iteration [14740/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0008\n",
            "Iteration [14750/20000] | d_real_loss: 0.0006 | d_Y_loss: 0.0000 | d_X_loss: 0.0002 | d_fake_loss: 0.0002 | g_loss: 0.0018\n",
            "Iteration [14760/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0011\n",
            "Iteration [14770/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0002 | d_X_loss: 0.0001 | d_fake_loss: 0.0002 | g_loss: 0.0010\n",
            "Iteration [14780/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0009\n",
            "Iteration [14790/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0008\n",
            "Iteration [14800/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0007\n",
            "Iteration [14810/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0003 | d_X_loss: 0.0000 | d_fake_loss: 0.0003 | g_loss: 0.0007\n",
            "Iteration [14820/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0002 | d_X_loss: 0.0000 | d_fake_loss: 0.0002 | g_loss: 0.0009\n",
            "Iteration [14830/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0006 | d_X_loss: 0.0000 | d_fake_loss: 0.0006 | g_loss: 0.0008\n",
            "Iteration [14840/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0011\n",
            "Iteration [14850/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0010\n",
            "Iteration [14860/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0007\n",
            "Iteration [14870/20000] | d_real_loss: 0.0006 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0014\n",
            "Iteration [14880/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0010\n",
            "Iteration [14890/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0012\n",
            "Iteration [14900/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0009\n",
            "Iteration [14910/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0010\n",
            "Iteration [14920/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0009\n",
            "Iteration [14930/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0008\n",
            "Iteration [14940/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0009\n",
            "Iteration [14950/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0008\n",
            "Iteration [14960/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0007\n",
            "Iteration [14970/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0008\n",
            "Iteration [14980/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0009\n",
            "Iteration [14990/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0007\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration [15000/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0008\n",
            "Saved /content/sample-015000-X-Y.png\n",
            "Saved /content/sample-015000-Y-X.png\n",
            "Iteration [15010/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0008\n",
            "Iteration [15020/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0008\n",
            "Iteration [15030/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0008\n",
            "Iteration [15040/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0008\n",
            "Iteration [15050/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0002 | g_loss: 0.0009\n",
            "Iteration [15060/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0009\n",
            "Iteration [15070/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0007 | d_X_loss: 0.0001 | d_fake_loss: 0.0008 | g_loss: 0.0010\n",
            "Iteration [15080/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0003 | d_X_loss: 0.0001 | d_fake_loss: 0.0004 | g_loss: 0.0016\n",
            "Iteration [15090/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0010\n",
            "Iteration [15100/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0004 | d_X_loss: 0.0000 | d_fake_loss: 0.0004 | g_loss: 0.0008\n",
            "Iteration [15110/20000] | d_real_loss: 0.0011 | d_Y_loss: 0.0005 | d_X_loss: 0.0001 | d_fake_loss: 0.0007 | g_loss: 0.0010\n",
            "Iteration [15120/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0008\n",
            "Iteration [15130/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0009\n",
            "Iteration [15140/20000] | d_real_loss: 0.0011 | d_Y_loss: 0.0028 | d_X_loss: 0.0000 | d_fake_loss: 0.0028 | g_loss: 0.0020\n",
            "Iteration [15150/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0002 | d_X_loss: 0.0001 | d_fake_loss: 0.0003 | g_loss: 0.0010\n",
            "Iteration [15160/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0001 | d_X_loss: 0.0001 | d_fake_loss: 0.0002 | g_loss: 0.0015\n",
            "Iteration [15170/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0010\n",
            "Iteration [15180/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0002 | d_X_loss: 0.0000 | d_fake_loss: 0.0002 | g_loss: 0.0016\n",
            "Iteration [15190/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0003 | d_X_loss: 0.0001 | d_fake_loss: 0.0004 | g_loss: 0.0014\n",
            "Iteration [15200/20000] | d_real_loss: 0.0008 | d_Y_loss: 0.0006 | d_X_loss: 0.0000 | d_fake_loss: 0.0006 | g_loss: 0.0009\n",
            "Iteration [15210/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0002 | d_X_loss: 0.0000 | d_fake_loss: 0.0002 | g_loss: 0.0008\n",
            "Iteration [15220/20000] | d_real_loss: 0.0005 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0015\n",
            "Iteration [15230/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0012 | d_X_loss: 0.0002 | d_fake_loss: 0.0014 | g_loss: 0.0014\n",
            "Iteration [15240/20000] | d_real_loss: 0.0006 | d_Y_loss: 0.0002 | d_X_loss: 0.0001 | d_fake_loss: 0.0003 | g_loss: 0.0007\n",
            "Iteration [15250/20000] | d_real_loss: 0.0011 | d_Y_loss: 0.0004 | d_X_loss: 0.0002 | d_fake_loss: 0.0006 | g_loss: 0.0030\n",
            "Iteration [15260/20000] | d_real_loss: 0.0005 | d_Y_loss: 0.0001 | d_X_loss: 0.0003 | d_fake_loss: 0.0004 | g_loss: 0.0007\n",
            "Iteration [15270/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0002 | d_X_loss: 0.0006 | d_fake_loss: 0.0008 | g_loss: 0.0009\n",
            "Iteration [15280/20000] | d_real_loss: 0.0005 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0009\n",
            "Iteration [15290/20000] | d_real_loss: 0.0006 | d_Y_loss: 0.0002 | d_X_loss: 0.0001 | d_fake_loss: 0.0003 | g_loss: 0.0007\n",
            "Iteration [15300/20000] | d_real_loss: 0.0006 | d_Y_loss: 0.0004 | d_X_loss: 0.0001 | d_fake_loss: 0.0005 | g_loss: 0.0008\n",
            "Iteration [15310/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0007\n",
            "Iteration [15320/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0009\n",
            "Iteration [15330/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0008\n",
            "Iteration [15340/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0008\n",
            "Iteration [15350/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0004 | d_X_loss: 0.0000 | d_fake_loss: 0.0004 | g_loss: 0.0010\n",
            "Iteration [15360/20000] | d_real_loss: 0.0010 | d_Y_loss: 0.0001 | d_X_loss: 0.0002 | d_fake_loss: 0.0003 | g_loss: 0.0012\n",
            "Iteration [15370/20000] | d_real_loss: 0.0014 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0011\n",
            "Iteration [15380/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0008\n",
            "Iteration [15390/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0010\n",
            "Iteration [15400/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0009\n",
            "Iteration [15410/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0008\n",
            "Iteration [15420/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0022 | d_X_loss: 0.0000 | d_fake_loss: 0.0023 | g_loss: 0.0017\n",
            "Iteration [15430/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0008\n",
            "Iteration [15440/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0002 | d_X_loss: 0.0000 | d_fake_loss: 0.0002 | g_loss: 0.0009\n",
            "Iteration [15450/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0002 | d_X_loss: 0.0000 | d_fake_loss: 0.0003 | g_loss: 0.0011\n",
            "Iteration [15460/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0010\n",
            "Iteration [15470/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0003 | d_X_loss: 0.0000 | d_fake_loss: 0.0003 | g_loss: 0.0009\n",
            "Iteration [15480/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0008\n",
            "Iteration [15490/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0009\n",
            "Iteration [15500/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0009\n",
            "Iteration [15510/20000] | d_real_loss: 0.0007 | d_Y_loss: 0.0002 | d_X_loss: 0.0000 | d_fake_loss: 0.0003 | g_loss: 0.0008\n",
            "Iteration [15520/20000] | d_real_loss: 0.0011 | d_Y_loss: 0.0005 | d_X_loss: 0.0001 | d_fake_loss: 0.0006 | g_loss: 0.0009\n",
            "Iteration [15530/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0006 | d_X_loss: 0.0000 | d_fake_loss: 0.0006 | g_loss: 0.0017\n",
            "Iteration [15540/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0002 | d_X_loss: 0.0000 | d_fake_loss: 0.0002 | g_loss: 0.0013\n",
            "Iteration [15550/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0010\n",
            "Iteration [15560/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0003 | d_X_loss: 0.0000 | d_fake_loss: 0.0003 | g_loss: 0.0009\n",
            "Iteration [15570/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0008\n",
            "Iteration [15580/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0007\n",
            "Iteration [15590/20000] | d_real_loss: 0.0013 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0017\n",
            "Iteration [15600/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0009\n",
            "Iteration [15610/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0008\n",
            "Iteration [15620/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0008\n",
            "Iteration [15630/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0009\n",
            "Iteration [15640/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0007\n",
            "Iteration [15650/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0007\n",
            "Iteration [15660/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0002 | d_fake_loss: 0.0002 | g_loss: 0.0008\n",
            "Iteration [15670/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0009\n",
            "Iteration [15680/20000] | d_real_loss: 0.0006 | d_Y_loss: 0.0000 | d_X_loss: 0.0002 | d_fake_loss: 0.0002 | g_loss: 0.0007\n",
            "Iteration [15690/20000] | d_real_loss: 0.0007 | d_Y_loss: 0.0001 | d_X_loss: 0.0001 | d_fake_loss: 0.0002 | g_loss: 0.0007\n",
            "Iteration [15700/20000] | d_real_loss: 0.0010 | d_Y_loss: 0.0000 | d_X_loss: 0.0002 | d_fake_loss: 0.0002 | g_loss: 0.0009\n",
            "Iteration [15710/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0002 | g_loss: 0.0007\n",
            "Iteration [15720/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0007\n",
            "Iteration [15730/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0010\n",
            "Iteration [15740/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0002 | d_X_loss: 0.0000 | d_fake_loss: 0.0002 | g_loss: 0.0008\n",
            "Iteration [15750/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0009\n",
            "Iteration [15760/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0007\n",
            "Iteration [15770/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0006\n",
            "Iteration [15780/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0009\n",
            "Iteration [15790/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0008\n",
            "Iteration [15800/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0007\n",
            "Iteration [15810/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0007\n",
            "Iteration [15820/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0012\n",
            "Iteration [15830/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0012\n",
            "Iteration [15840/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0007 | d_X_loss: 0.0000 | d_fake_loss: 0.0008 | g_loss: 0.0007\n",
            "Iteration [15850/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0010\n",
            "Iteration [15860/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0002 | g_loss: 0.0007\n",
            "Iteration [15870/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0010\n",
            "Iteration [15880/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0002 | d_X_loss: 0.0000 | d_fake_loss: 0.0003 | g_loss: 0.0007\n",
            "Iteration [15890/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0008\n",
            "Iteration [15900/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0007\n",
            "Iteration [15910/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0009\n",
            "Iteration [15920/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0002 | d_X_loss: 0.0000 | d_fake_loss: 0.0002 | g_loss: 0.0008\n",
            "Iteration [15930/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0006\n",
            "Iteration [15940/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0003 | d_X_loss: 0.0000 | d_fake_loss: 0.0003 | g_loss: 0.0010\n",
            "Iteration [15950/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0008 | d_X_loss: 0.0000 | d_fake_loss: 0.0008 | g_loss: 0.0011\n",
            "Iteration [15960/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0013 | d_X_loss: 0.0004 | d_fake_loss: 0.0017 | g_loss: 0.0020\n",
            "Iteration [15970/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0002 | d_X_loss: 0.0000 | d_fake_loss: 0.0003 | g_loss: 0.0008\n",
            "Iteration [15980/20000] | d_real_loss: 0.0010 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0011\n",
            "Iteration [15990/20000] | d_real_loss: 0.0014 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0018\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration [16000/20000] | d_real_loss: 0.0005 | d_Y_loss: 0.0005 | d_X_loss: 0.0004 | d_fake_loss: 0.0009 | g_loss: 0.0009\n",
            "Saved /content/sample-016000-X-Y.png\n",
            "Saved /content/sample-016000-Y-X.png\n",
            "Iteration [16010/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0003 | d_X_loss: 0.0003 | d_fake_loss: 0.0006 | g_loss: 0.0008\n",
            "Iteration [16020/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0009\n",
            "Iteration [16030/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0001 | d_X_loss: 0.0001 | d_fake_loss: 0.0002 | g_loss: 0.0007\n",
            "Iteration [16040/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0008\n",
            "Iteration [16050/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0008\n",
            "Iteration [16060/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0008\n",
            "Iteration [16070/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0010\n",
            "Iteration [16080/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0008\n",
            "Iteration [16090/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0007\n",
            "Iteration [16100/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0007\n",
            "Iteration [16110/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0009\n",
            "Iteration [16120/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0011\n",
            "Iteration [16130/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0011\n",
            "Iteration [16140/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0008\n",
            "Iteration [16150/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0007\n",
            "Iteration [16160/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0003 | d_X_loss: 0.0000 | d_fake_loss: 0.0004 | g_loss: 0.0008\n",
            "Iteration [16170/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0008\n",
            "Iteration [16180/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0010\n",
            "Iteration [16190/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0001 | d_X_loss: 0.0002 | d_fake_loss: 0.0003 | g_loss: 0.0009\n",
            "Iteration [16200/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0002 | d_X_loss: 0.0001 | d_fake_loss: 0.0003 | g_loss: 0.0007\n",
            "Iteration [16210/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0010\n",
            "Iteration [16220/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0008\n",
            "Iteration [16230/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0009\n",
            "Iteration [16240/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0009\n",
            "Iteration [16250/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0007\n",
            "Iteration [16260/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0006\n",
            "Iteration [16270/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0012\n",
            "Iteration [16280/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0010\n",
            "Iteration [16290/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0007\n",
            "Iteration [16300/20000] | d_real_loss: 0.0005 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0002 | g_loss: 0.0007\n",
            "Iteration [16310/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0010\n",
            "Iteration [16320/20000] | d_real_loss: 0.0005 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0008\n",
            "Iteration [16330/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0001 | d_X_loss: 0.0001 | d_fake_loss: 0.0002 | g_loss: 0.0007\n",
            "Iteration [16340/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0002 | d_X_loss: 0.0000 | d_fake_loss: 0.0002 | g_loss: 0.0007\n",
            "Iteration [16350/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0008\n",
            "Iteration [16360/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0008\n",
            "Iteration [16370/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0001 | d_X_loss: 0.0002 | d_fake_loss: 0.0002 | g_loss: 0.0008\n",
            "Iteration [16380/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0008\n",
            "Iteration [16390/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0009\n",
            "Iteration [16400/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0009 | d_X_loss: 0.0002 | d_fake_loss: 0.0011 | g_loss: 0.0011\n",
            "Iteration [16410/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0001 | d_X_loss: 0.0001 | d_fake_loss: 0.0002 | g_loss: 0.0008\n",
            "Iteration [16420/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0010\n",
            "Iteration [16430/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0008 | d_X_loss: 0.0000 | d_fake_loss: 0.0008 | g_loss: 0.0015\n",
            "Iteration [16440/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0007\n",
            "Iteration [16450/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0004 | d_X_loss: 0.0000 | d_fake_loss: 0.0004 | g_loss: 0.0009\n",
            "Iteration [16460/20000] | d_real_loss: 0.0011 | d_Y_loss: 0.0012 | d_X_loss: 0.0000 | d_fake_loss: 0.0012 | g_loss: 0.0008\n",
            "Iteration [16470/20000] | d_real_loss: 0.0006 | d_Y_loss: 0.0014 | d_X_loss: 0.0000 | d_fake_loss: 0.0014 | g_loss: 0.0007\n",
            "Iteration [16480/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0007\n",
            "Iteration [16490/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0007\n",
            "Iteration [16500/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0010\n",
            "Iteration [16510/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0008\n",
            "Iteration [16520/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0009\n",
            "Iteration [16530/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0008\n",
            "Iteration [16540/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0008\n",
            "Iteration [16550/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0011\n",
            "Iteration [16560/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0007\n",
            "Iteration [16570/20000] | d_real_loss: 0.0006 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0007\n",
            "Iteration [16580/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0002 | d_X_loss: 0.0000 | d_fake_loss: 0.0002 | g_loss: 0.0007\n",
            "Iteration [16590/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0007\n",
            "Iteration [16600/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0005 | d_X_loss: 0.0000 | d_fake_loss: 0.0005 | g_loss: 0.0010\n",
            "Iteration [16610/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0003 | d_X_loss: 0.0001 | d_fake_loss: 0.0003 | g_loss: 0.0009\n",
            "Iteration [16620/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0002 | d_X_loss: 0.0001 | d_fake_loss: 0.0003 | g_loss: 0.0008\n",
            "Iteration [16630/20000] | d_real_loss: 0.0017 | d_Y_loss: 0.0001 | d_X_loss: 0.0016 | d_fake_loss: 0.0017 | g_loss: 0.0007\n",
            "Iteration [16640/20000] | d_real_loss: 0.0007 | d_Y_loss: 0.0000 | d_X_loss: 0.0003 | d_fake_loss: 0.0003 | g_loss: 0.0008\n",
            "Iteration [16650/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0001 | d_X_loss: 0.0004 | d_fake_loss: 0.0005 | g_loss: 0.0007\n",
            "Iteration [16660/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0008\n",
            "Iteration [16670/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0008\n",
            "Iteration [16680/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0011\n",
            "Iteration [16690/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0001 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0007\n",
            "Iteration [16700/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0007\n",
            "Iteration [16710/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0008\n",
            "Iteration [16720/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0007\n",
            "Iteration [16730/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0007\n",
            "Iteration [16740/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0009\n",
            "Iteration [16750/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0002 | d_X_loss: 0.0000 | d_fake_loss: 0.0002 | g_loss: 0.0008\n",
            "Iteration [16760/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0008\n",
            "Iteration [16770/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0007\n",
            "Iteration [16780/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0010\n",
            "Iteration [16790/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0008\n",
            "Iteration [16800/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0007\n",
            "Iteration [16810/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0008\n",
            "Iteration [16820/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0008\n",
            "Iteration [16830/20000] | d_real_loss: 0.0005 | d_Y_loss: 0.0002 | d_X_loss: 0.0000 | d_fake_loss: 0.0003 | g_loss: 0.0007\n",
            "Iteration [16840/20000] | d_real_loss: 0.0005 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0008\n",
            "Iteration [16850/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0009\n",
            "Iteration [16860/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0002 | d_X_loss: 0.0000 | d_fake_loss: 0.0002 | g_loss: 0.0011\n",
            "Iteration [16870/20000] | d_real_loss: 0.0006 | d_Y_loss: 0.0008 | d_X_loss: 0.0000 | d_fake_loss: 0.0008 | g_loss: 0.0007\n",
            "Iteration [16880/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0002 | d_X_loss: 0.0000 | d_fake_loss: 0.0002 | g_loss: 0.0008\n",
            "Iteration [16890/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0002 | g_loss: 0.0009\n",
            "Iteration [16900/20000] | d_real_loss: 0.0005 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0008\n",
            "Iteration [16910/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0002 | d_X_loss: 0.0000 | d_fake_loss: 0.0002 | g_loss: 0.0007\n",
            "Iteration [16920/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0002 | d_X_loss: 0.0000 | d_fake_loss: 0.0002 | g_loss: 0.0007\n",
            "Iteration [16930/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0006\n",
            "Iteration [16940/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0008\n",
            "Iteration [16950/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0002 | g_loss: 0.0009\n",
            "Iteration [16960/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0007\n",
            "Iteration [16970/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0010\n",
            "Iteration [16980/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0006\n",
            "Iteration [16990/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0008\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration [17000/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0009\n",
            "Saved /content/sample-017000-X-Y.png\n",
            "Saved /content/sample-017000-Y-X.png\n",
            "Iteration [17010/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0007\n",
            "Iteration [17020/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0006\n",
            "Iteration [17030/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0008\n",
            "Iteration [17040/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0007\n",
            "Iteration [17050/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0008\n",
            "Iteration [17060/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0007\n",
            "Iteration [17070/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0008\n",
            "Iteration [17080/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0007\n",
            "Iteration [17090/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0003 | d_X_loss: 0.0001 | d_fake_loss: 0.0005 | g_loss: 0.0007\n",
            "Iteration [17100/20000] | d_real_loss: 0.0007 | d_Y_loss: 0.0000 | d_X_loss: 0.0002 | d_fake_loss: 0.0002 | g_loss: 0.0007\n",
            "Iteration [17110/20000] | d_real_loss: 0.0009 | d_Y_loss: 0.0000 | d_X_loss: 0.0005 | d_fake_loss: 0.0005 | g_loss: 0.0008\n",
            "Iteration [17120/20000] | d_real_loss: 0.0067 | d_Y_loss: 0.0001 | d_X_loss: 0.0106 | d_fake_loss: 0.0107 | g_loss: 0.0113\n",
            "Iteration [17130/20000] | d_real_loss: 0.0033 | d_Y_loss: 0.0004 | d_X_loss: 0.0142 | d_fake_loss: 0.0146 | g_loss: 0.0045\n",
            "Iteration [17140/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0000 | d_X_loss: 0.0003 | d_fake_loss: 0.0003 | g_loss: 0.0027\n",
            "Iteration [17150/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0002 | g_loss: 0.0021\n",
            "Iteration [17160/20000] | d_real_loss: 0.0005 | d_Y_loss: 0.0001 | d_X_loss: 0.0001 | d_fake_loss: 0.0002 | g_loss: 0.0025\n",
            "Iteration [17170/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0015\n",
            "Iteration [17180/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0016\n",
            "Iteration [17190/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0016\n",
            "Iteration [17200/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0013\n",
            "Iteration [17210/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0012\n",
            "Iteration [17220/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0002 | d_X_loss: 0.0000 | d_fake_loss: 0.0002 | g_loss: 0.0011\n",
            "Iteration [17230/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0002 | d_X_loss: 0.0001 | d_fake_loss: 0.0003 | g_loss: 0.0012\n",
            "Iteration [17240/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0012\n",
            "Iteration [17250/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0013\n",
            "Iteration [17260/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0010\n",
            "Iteration [17270/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0009\n",
            "Iteration [17280/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0011\n",
            "Iteration [17290/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0011\n",
            "Iteration [17300/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0010\n",
            "Iteration [17310/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0010\n",
            "Iteration [17320/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0010\n",
            "Iteration [17330/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0009\n",
            "Iteration [17340/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0009\n",
            "Iteration [17350/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0010\n",
            "Iteration [17360/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0002 | d_X_loss: 0.0000 | d_fake_loss: 0.0002 | g_loss: 0.0008\n",
            "Iteration [17370/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0008\n",
            "Iteration [17380/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0008\n",
            "Iteration [17390/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0009\n",
            "Iteration [17400/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0009\n",
            "Iteration [17410/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0009\n",
            "Iteration [17420/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0008\n",
            "Iteration [17430/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0009\n",
            "Iteration [17440/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0009\n",
            "Iteration [17450/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0002 | d_X_loss: 0.0000 | d_fake_loss: 0.0002 | g_loss: 0.0008\n",
            "Iteration [17460/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0003 | d_X_loss: 0.0000 | d_fake_loss: 0.0003 | g_loss: 0.0013\n",
            "Iteration [17470/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0002 | d_X_loss: 0.0000 | d_fake_loss: 0.0002 | g_loss: 0.0010\n",
            "Iteration [17480/20000] | d_real_loss: 0.0011 | d_Y_loss: 0.0012 | d_X_loss: 0.0000 | d_fake_loss: 0.0012 | g_loss: 0.0011\n",
            "Iteration [17490/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0008\n",
            "Iteration [17500/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0010\n",
            "Iteration [17510/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0007 | d_X_loss: 0.0000 | d_fake_loss: 0.0007 | g_loss: 0.0009\n",
            "Iteration [17520/20000] | d_real_loss: 0.0012 | d_Y_loss: 0.0003 | d_X_loss: 0.0000 | d_fake_loss: 0.0003 | g_loss: 0.0014\n",
            "Iteration [17530/20000] | d_real_loss: 0.0010 | d_Y_loss: 0.0025 | d_X_loss: 0.0000 | d_fake_loss: 0.0025 | g_loss: 0.0010\n",
            "Iteration [17540/20000] | d_real_loss: 0.0008 | d_Y_loss: 0.0002 | d_X_loss: 0.0000 | d_fake_loss: 0.0002 | g_loss: 0.0008\n",
            "Iteration [17550/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0009\n",
            "Iteration [17560/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0008\n",
            "Iteration [17570/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0008\n",
            "Iteration [17580/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0008\n",
            "Iteration [17590/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0009\n",
            "Iteration [17600/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0007 | d_X_loss: 0.0000 | d_fake_loss: 0.0007 | g_loss: 0.0011\n",
            "Iteration [17610/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0009\n",
            "Iteration [17620/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0008\n",
            "Iteration [17630/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0007\n",
            "Iteration [17640/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0008\n",
            "Iteration [17650/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0009\n",
            "Iteration [17660/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0008\n",
            "Iteration [17670/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0007\n",
            "Iteration [17680/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0007\n",
            "Iteration [17690/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0007\n",
            "Iteration [17700/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0008\n",
            "Iteration [17710/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0008\n",
            "Iteration [17720/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0008\n",
            "Iteration [17730/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0008\n",
            "Iteration [17740/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0002 | d_X_loss: 0.0000 | d_fake_loss: 0.0002 | g_loss: 0.0007\n",
            "Iteration [17750/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0008\n",
            "Iteration [17760/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0009\n",
            "Iteration [17770/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0002 | g_loss: 0.0009\n",
            "Iteration [17780/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0008\n",
            "Iteration [17790/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0002 | d_X_loss: 0.0000 | d_fake_loss: 0.0002 | g_loss: 0.0009\n",
            "Iteration [17800/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0002 | d_fake_loss: 0.0003 | g_loss: 0.0008\n",
            "Iteration [17810/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0007\n",
            "Iteration [17820/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0010\n",
            "Iteration [17830/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0008\n",
            "Iteration [17840/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0007\n",
            "Iteration [17850/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0008\n",
            "Iteration [17860/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0008\n",
            "Iteration [17870/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0006\n",
            "Iteration [17880/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0008\n",
            "Iteration [17890/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0008\n",
            "Iteration [17900/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0008\n",
            "Iteration [17910/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0008\n",
            "Iteration [17920/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0009\n",
            "Iteration [17930/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0007\n",
            "Iteration [17940/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0011\n",
            "Iteration [17950/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0008\n",
            "Iteration [17960/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0002 | d_X_loss: 0.0000 | d_fake_loss: 0.0003 | g_loss: 0.0009\n",
            "Iteration [17970/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0009\n",
            "Iteration [17980/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0011\n",
            "Iteration [17990/20000] | d_real_loss: 0.0010 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0017\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float64 to uint8. Range [-1.0, 0.9982166290283203]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration [18000/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0007\n",
            "Saved /content/sample-018000-X-Y.png\n",
            "Saved /content/sample-018000-Y-X.png\n",
            "Iteration [18010/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0008\n",
            "Iteration [18020/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0010\n",
            "Iteration [18030/20000] | d_real_loss: 0.0005 | d_Y_loss: 0.0004 | d_X_loss: 0.0000 | d_fake_loss: 0.0004 | g_loss: 0.0007\n",
            "Iteration [18040/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0009\n",
            "Iteration [18050/20000] | d_real_loss: 0.0005 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0016\n",
            "Iteration [18060/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0012\n",
            "Iteration [18070/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0002 | d_X_loss: 0.0000 | d_fake_loss: 0.0002 | g_loss: 0.0011\n",
            "Iteration [18080/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0003 | d_X_loss: 0.0000 | d_fake_loss: 0.0003 | g_loss: 0.0008\n",
            "Iteration [18090/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0007\n",
            "Iteration [18100/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0001 | d_X_loss: 0.0001 | d_fake_loss: 0.0002 | g_loss: 0.0007\n",
            "Iteration [18110/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0004 | d_X_loss: 0.0000 | d_fake_loss: 0.0004 | g_loss: 0.0008\n",
            "Iteration [18120/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0002 | g_loss: 0.0008\n",
            "Iteration [18130/20000] | d_real_loss: 0.0005 | d_Y_loss: 0.0005 | d_X_loss: 0.0001 | d_fake_loss: 0.0006 | g_loss: 0.0010\n",
            "Iteration [18140/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0004 | d_X_loss: 0.0000 | d_fake_loss: 0.0004 | g_loss: 0.0007\n",
            "Iteration [18150/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0006 | d_X_loss: 0.0000 | d_fake_loss: 0.0006 | g_loss: 0.0008\n",
            "Iteration [18160/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0008\n",
            "Iteration [18170/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0007\n",
            "Iteration [18180/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0007\n",
            "Iteration [18190/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0007\n",
            "Iteration [18200/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0011\n",
            "Iteration [18210/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0003 | d_X_loss: 0.0000 | d_fake_loss: 0.0003 | g_loss: 0.0009\n",
            "Iteration [18220/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0007\n",
            "Iteration [18230/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0007\n",
            "Iteration [18240/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0007\n",
            "Iteration [18250/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0007\n",
            "Iteration [18260/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0008\n",
            "Iteration [18270/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0010\n",
            "Iteration [18280/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0002 | g_loss: 0.0007\n",
            "Iteration [18290/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0001 | d_X_loss: 0.0001 | d_fake_loss: 0.0002 | g_loss: 0.0007\n",
            "Iteration [18300/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0001 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0006\n",
            "Iteration [18310/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0003 | d_X_loss: 0.0000 | d_fake_loss: 0.0003 | g_loss: 0.0008\n",
            "Iteration [18320/20000] | d_real_loss: 0.0005 | d_Y_loss: 0.0017 | d_X_loss: 0.0000 | d_fake_loss: 0.0018 | g_loss: 0.0007\n",
            "Iteration [18330/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0004 | d_X_loss: 0.0000 | d_fake_loss: 0.0004 | g_loss: 0.0007\n",
            "Iteration [18340/20000] | d_real_loss: 0.0005 | d_Y_loss: 0.0002 | d_X_loss: 0.0001 | d_fake_loss: 0.0003 | g_loss: 0.0008\n",
            "Iteration [18350/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0006\n",
            "Iteration [18360/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0007\n",
            "Iteration [18370/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0008\n",
            "Iteration [18380/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0007\n",
            "Iteration [18390/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0007\n",
            "Iteration [18400/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0002 | d_X_loss: 0.0001 | d_fake_loss: 0.0002 | g_loss: 0.0007\n",
            "Iteration [18410/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0008\n",
            "Iteration [18420/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0001 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0009\n",
            "Iteration [18430/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0001 | d_X_loss: 0.0001 | d_fake_loss: 0.0002 | g_loss: 0.0009\n",
            "Iteration [18440/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0008\n",
            "Iteration [18450/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0001 | d_X_loss: 0.0002 | d_fake_loss: 0.0003 | g_loss: 0.0008\n",
            "Iteration [18460/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0006\n",
            "Iteration [18470/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0006\n",
            "Iteration [18480/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0008\n",
            "Iteration [18490/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0007\n",
            "Iteration [18500/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0009\n",
            "Iteration [18510/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0007\n",
            "Iteration [18520/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0009\n",
            "Iteration [18530/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0010\n",
            "Iteration [18540/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0008\n",
            "Iteration [18550/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0002 | d_X_loss: 0.0000 | d_fake_loss: 0.0002 | g_loss: 0.0008\n",
            "Iteration [18560/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0001 | d_X_loss: 0.0002 | d_fake_loss: 0.0002 | g_loss: 0.0009\n",
            "Iteration [18570/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0001 | d_X_loss: 0.0003 | d_fake_loss: 0.0003 | g_loss: 0.0007\n",
            "Iteration [18580/20000] | d_real_loss: 0.0012 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0008\n",
            "Iteration [18590/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0006\n",
            "Iteration [18600/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0004 | d_X_loss: 0.0000 | d_fake_loss: 0.0004 | g_loss: 0.0012\n",
            "Iteration [18610/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0003 | d_X_loss: 0.0000 | d_fake_loss: 0.0003 | g_loss: 0.0009\n",
            "Iteration [18620/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0003 | d_X_loss: 0.0000 | d_fake_loss: 0.0003 | g_loss: 0.0008\n",
            "Iteration [18630/20000] | d_real_loss: 0.0007 | d_Y_loss: 0.0005 | d_X_loss: 0.0001 | d_fake_loss: 0.0006 | g_loss: 0.0010\n",
            "Iteration [18640/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0007 | d_X_loss: 0.0001 | d_fake_loss: 0.0008 | g_loss: 0.0011\n",
            "Iteration [18650/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0007\n",
            "Iteration [18660/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0007\n",
            "Iteration [18670/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0008\n",
            "Iteration [18680/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0007\n",
            "Iteration [18690/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0002 | g_loss: 0.0008\n",
            "Iteration [18700/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0007\n",
            "Iteration [18710/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0008\n",
            "Iteration [18720/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0002 | d_X_loss: 0.0000 | d_fake_loss: 0.0002 | g_loss: 0.0007\n",
            "Iteration [18730/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0003 | d_X_loss: 0.0000 | d_fake_loss: 0.0003 | g_loss: 0.0007\n",
            "Iteration [18740/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0008\n",
            "Iteration [18750/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0003 | d_X_loss: 0.0000 | d_fake_loss: 0.0003 | g_loss: 0.0008\n",
            "Iteration [18760/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0002 | d_X_loss: 0.0000 | d_fake_loss: 0.0002 | g_loss: 0.0007\n",
            "Iteration [18770/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0007\n",
            "Iteration [18780/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0008\n",
            "Iteration [18790/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0007\n",
            "Iteration [18800/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0007\n",
            "Iteration [18810/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0007\n",
            "Iteration [18820/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0002 | d_X_loss: 0.0000 | d_fake_loss: 0.0002 | g_loss: 0.0009\n",
            "Iteration [18830/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0006\n",
            "Iteration [18840/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0002 | d_X_loss: 0.0000 | d_fake_loss: 0.0002 | g_loss: 0.0010\n",
            "Iteration [18850/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0007\n",
            "Iteration [18860/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0000 | d_X_loss: 0.0002 | d_fake_loss: 0.0003 | g_loss: 0.0007\n",
            "Iteration [18870/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0002 | d_X_loss: 0.0000 | d_fake_loss: 0.0002 | g_loss: 0.0007\n",
            "Iteration [18880/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0009\n",
            "Iteration [18890/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0003 | d_X_loss: 0.0000 | d_fake_loss: 0.0003 | g_loss: 0.0007\n",
            "Iteration [18900/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0005 | d_X_loss: 0.0000 | d_fake_loss: 0.0005 | g_loss: 0.0007\n",
            "Iteration [18910/20000] | d_real_loss: 0.0005 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0014\n",
            "Iteration [18920/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0003 | d_X_loss: 0.0001 | d_fake_loss: 0.0004 | g_loss: 0.0010\n",
            "Iteration [18930/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0008\n",
            "Iteration [18940/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0007\n",
            "Iteration [18950/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0000 | d_X_loss: 0.0003 | d_fake_loss: 0.0004 | g_loss: 0.0007\n",
            "Iteration [18960/20000] | d_real_loss: 0.0008 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0007\n",
            "Iteration [18970/20000] | d_real_loss: 0.0009 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0015\n",
            "Iteration [18980/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0007\n",
            "Iteration [18990/20000] | d_real_loss: 0.0009 | d_Y_loss: 0.0004 | d_X_loss: 0.0001 | d_fake_loss: 0.0004 | g_loss: 0.0008\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float64 to uint8. Range [-1.0, 0.9983035922050476]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration [19000/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0006 | d_X_loss: 0.0000 | d_fake_loss: 0.0007 | g_loss: 0.0007\n",
            "Saved /content/sample-019000-X-Y.png\n",
            "Saved /content/sample-019000-Y-X.png\n",
            "Iteration [19010/20000] | d_real_loss: 0.0005 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0002 | g_loss: 0.0013\n",
            "Iteration [19020/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0008 | d_X_loss: 0.0000 | d_fake_loss: 0.0008 | g_loss: 0.0010\n",
            "Iteration [19030/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0002 | d_X_loss: 0.0000 | d_fake_loss: 0.0002 | g_loss: 0.0007\n",
            "Iteration [19040/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0002 | d_X_loss: 0.0000 | d_fake_loss: 0.0002 | g_loss: 0.0007\n",
            "Iteration [19050/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0009\n",
            "Iteration [19060/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0006\n",
            "Iteration [19070/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0010\n",
            "Iteration [19080/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0007\n",
            "Iteration [19090/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0001 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0008\n",
            "Iteration [19100/20000] | d_real_loss: 0.0010 | d_Y_loss: 0.0000 | d_X_loss: 0.0004 | d_fake_loss: 0.0004 | g_loss: 0.0007\n",
            "Iteration [19110/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0001 | d_X_loss: 0.0002 | d_fake_loss: 0.0002 | g_loss: 0.0006\n",
            "Iteration [19120/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0002 | d_X_loss: 0.0001 | d_fake_loss: 0.0002 | g_loss: 0.0006\n",
            "Iteration [19130/20000] | d_real_loss: 0.0007 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0006\n",
            "Iteration [19140/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0001 | d_X_loss: 0.0005 | d_fake_loss: 0.0006 | g_loss: 0.0006\n",
            "Iteration [19150/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0006\n",
            "Iteration [19160/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0009\n",
            "Iteration [19170/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0008\n",
            "Iteration [19180/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0007\n",
            "Iteration [19190/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0007\n",
            "Iteration [19200/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0008\n",
            "Iteration [19210/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0011\n",
            "Iteration [19220/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0008\n",
            "Iteration [19230/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0006\n",
            "Iteration [19240/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0007\n",
            "Iteration [19250/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0007\n",
            "Iteration [19260/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0007\n",
            "Iteration [19270/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0004 | d_X_loss: 0.0000 | d_fake_loss: 0.0004 | g_loss: 0.0007\n",
            "Iteration [19280/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0006\n",
            "Iteration [19290/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0007\n",
            "Iteration [19300/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0007\n",
            "Iteration [19310/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0008\n",
            "Iteration [19320/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0007\n",
            "Iteration [19330/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0007\n",
            "Iteration [19340/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0006\n",
            "Iteration [19350/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0006\n",
            "Iteration [19360/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0008\n",
            "Iteration [19370/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0008\n",
            "Iteration [19380/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0010\n",
            "Iteration [19390/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0005\n",
            "Iteration [19400/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0007\n",
            "Iteration [19410/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0007\n",
            "Iteration [19420/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0006\n",
            "Iteration [19430/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0009\n",
            "Iteration [19440/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0007\n",
            "Iteration [19450/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0006\n",
            "Iteration [19460/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0006\n",
            "Iteration [19470/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0003 | d_X_loss: 0.0001 | d_fake_loss: 0.0004 | g_loss: 0.0010\n",
            "Iteration [19480/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0009\n",
            "Iteration [19490/20000] | d_real_loss: 0.0007 | d_Y_loss: 0.0002 | d_X_loss: 0.0000 | d_fake_loss: 0.0003 | g_loss: 0.0015\n",
            "Iteration [19500/20000] | d_real_loss: 0.0008 | d_Y_loss: 0.0003 | d_X_loss: 0.0003 | d_fake_loss: 0.0006 | g_loss: 0.0009\n",
            "Iteration [19510/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0000 | d_X_loss: 0.0002 | d_fake_loss: 0.0002 | g_loss: 0.0007\n",
            "Iteration [19520/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0003 | d_X_loss: 0.0000 | d_fake_loss: 0.0003 | g_loss: 0.0007\n",
            "Iteration [19530/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0007\n",
            "Iteration [19540/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0006\n",
            "Iteration [19550/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0006\n",
            "Iteration [19560/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0006\n",
            "Iteration [19570/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0008\n",
            "Iteration [19580/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0008\n",
            "Iteration [19590/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0006\n",
            "Iteration [19600/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0007\n",
            "Iteration [19610/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0002 | d_X_loss: 0.0000 | d_fake_loss: 0.0002 | g_loss: 0.0009\n",
            "Iteration [19620/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0007\n",
            "Iteration [19630/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0006\n",
            "Iteration [19640/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0009\n",
            "Iteration [19650/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0007\n",
            "Iteration [19660/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0006 | d_X_loss: 0.0000 | d_fake_loss: 0.0006 | g_loss: 0.0010\n",
            "Iteration [19670/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0002 | g_loss: 0.0013\n",
            "Iteration [19680/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0006 | d_X_loss: 0.0000 | d_fake_loss: 0.0006 | g_loss: 0.0009\n",
            "Iteration [19690/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0009\n",
            "Iteration [19700/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0007\n",
            "Iteration [19710/20000] | d_real_loss: 0.0003 | d_Y_loss: 0.0002 | d_X_loss: 0.0000 | d_fake_loss: 0.0002 | g_loss: 0.0007\n",
            "Iteration [19720/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0008\n",
            "Iteration [19730/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0007\n",
            "Iteration [19740/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0007\n",
            "Iteration [19750/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0002 | d_X_loss: 0.0000 | d_fake_loss: 0.0002 | g_loss: 0.0007\n",
            "Iteration [19760/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0002 | g_loss: 0.0007\n",
            "Iteration [19770/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0007\n",
            "Iteration [19780/20000] | d_real_loss: 0.0004 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 0.0007\n",
            "Iteration [19790/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0004 | d_X_loss: 0.0000 | d_fake_loss: 0.0005 | g_loss: 0.0007\n",
            "Iteration [19800/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0002 | d_X_loss: 0.0001 | d_fake_loss: 0.0002 | g_loss: 0.0009\n",
            "Iteration [19810/20000] | d_real_loss: 0.0005 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0008\n",
            "Iteration [19820/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0004 | d_X_loss: 0.0000 | d_fake_loss: 0.0004 | g_loss: 0.0009\n",
            "Iteration [19830/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0008\n",
            "Iteration [19840/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0008\n",
            "Iteration [19850/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0007\n",
            "Iteration [19860/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0008\n",
            "Iteration [19870/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0006\n",
            "Iteration [19880/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0006\n",
            "Iteration [19890/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0008\n",
            "Iteration [19900/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0007\n",
            "Iteration [19910/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0006\n",
            "Iteration [19920/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0008\n",
            "Iteration [19930/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0006\n",
            "Iteration [19940/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0007\n",
            "Iteration [19950/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0006\n",
            "Iteration [19960/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0007\n",
            "Iteration [19970/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0006\n",
            "Iteration [19980/20000] | d_real_loss: 0.0000 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 0.0009\n",
            "Iteration [19990/20000] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0007\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float64 to uint8. Range [-1.0, 0.9987512826919556]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration [20000/20000] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 0.0007\n",
            "Saved /content/sample-020000-X-Y.png\n",
            "Saved /content/sample-020000-Y-X.png\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGjWBRrA74G6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}