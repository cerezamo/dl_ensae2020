{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# conda environments:\n",
      "#\n",
      "base                  *  /home/cesar/anaconda3\n",
      "pyspark                  /home/cesar/anaconda3/envs/pyspark\n",
      "sat                      /home/cesar/anaconda3/envs/sat\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda env list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "import tarfile\n",
    "from six.moves.urllib.request import urlretrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed : 999\n"
     ]
    }
   ],
   "source": [
    "manualSeed = 999\n",
    "print(\"Random Seed :\", manualSeed)\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "trainning_loop = True\n",
    "\n",
    "nc = 3   # input image channels\n",
    "nz = 100 # size of the latent z vector\n",
    "ngf = 64 # n growth factor\n",
    "ndf = 64 # n decrease factor\n",
    "\n",
    "image_size = 32\n",
    "batch_size = 32\n",
    "niter = 50000\n",
    "num_workers = 0\n",
    "\n",
    "Diters = 5             # number of D iters per each G iter\n",
    "lrD = 0.0005          # learning rate for Critic\n",
    "lrG = 0.0005          # learning rate for Generator\n",
    "clamp_lower = -0.01\n",
    "clamp_upper = 0.01\n",
    "\n",
    "PATH_DATA = 'data'\n",
    "RESULTS_PATH = 'results/wdcgan'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(PATH_DATA, exist_ok=True)\n",
    "os.makedirs(RESULTS_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file(fname,\n",
    "             origin,\n",
    "             untar=False,\n",
    "             extract=False,\n",
    "             archive_format='auto',\n",
    "             cache_dir='data'):\n",
    "\n",
    "    datadir = os.path.join(cache_dir)\n",
    "    if not os.path.exists(datadir):\n",
    "        os.makedirs(datadir)\n",
    "\n",
    "    if untar:\n",
    "        untar_fpath = os.path.join(datadir, fname)\n",
    "        fpath = untar_fpath + '.tar.gz'\n",
    "    else:\n",
    "        fpath = os.path.join(data_dir, fname)\n",
    "    \n",
    "    print(fpath)\n",
    "\n",
    "    if not os.path.exists(fpath):\n",
    "        print(\"Downloading data from\", origin)\n",
    "\n",
    "        error_msg = \"URL fetch failure on {} : {} -- {}\"\n",
    "        try:\n",
    "            try:\n",
    "                urlretrieve(origin, fpath)\n",
    "            except URLError as e:\n",
    "                raise Exception(error_msg.format(origin, e.errno, e.reason))\n",
    "            except HTTPError as e:\n",
    "                raise Exception(error_msg.format(origin, e.code, e.msg))\n",
    "        except:\n",
    "            if os.path.exists(fpath):\n",
    "                os.remove(fpath)\n",
    "            raise\n",
    "\n",
    "    if untar:\n",
    "        if not os.path.exists(untar_fpath):\n",
    "            print(\"Extracting file.\")\n",
    "            with tarfile.open(fpath) as archive:\n",
    "                archive.extractall(datadir)\n",
    "            return untar_fpath\n",
    "\n",
    "    if extract:\n",
    "        _extract_archive(fpath, datadir, archive_format)\n",
    "\n",
    "    return fpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/emojis.tar.gz\n"
     ]
    }
   ],
   "source": [
    "data_fpath = get_file(fname='emojis', \n",
    "                      origin='http://www.cs.toronto.edu/~jba/emojis.tar.gz', \n",
    "                      untar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emoji_loader(emoji_type, image_size, batch_size, num_workers):\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(image_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "        ])\n",
    "\n",
    "    img_path = os.path.join('data/emojis', emoji_type)\n",
    "\n",
    "    dataset = dset.ImageFolder(img_path, transform)\n",
    "\n",
    "    dloader = DataLoader(dataset=dataset,\n",
    "                              batch_size=batch_size,\n",
    "                              shuffle=True,\n",
    "                              num_workers=num_workers)\n",
    "\n",
    "    return dloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = get_emoji_loader(\"Apple\", image_size, batch_size, num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "data = next(iter(dataloader))\n",
    "np_img = np.transpose(data[0][0].numpy(), (1, 2, 0))\n",
    "plt.imshow(np.clip(np_img, 0, 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DCGAN_D(nn.Module):\n",
    "    def __init__(self, isize, nz, nc, ndf):\n",
    "        super(DCGAN_D, self).__init__()\n",
    "        assert isize % 16 == 0, \"isize has to be a multiple of 16\"\n",
    "\n",
    "        main = nn.Sequential()\n",
    "        # input is nc x isize x isize\n",
    "        main.add_module('initial:{0}-{1}:conv'.format(nc, ndf),\n",
    "                        nn.Conv2d(nc, ndf, 4, 2, 1, bias=False))\n",
    "        main.add_module('initial:{0}:relu'.format(ndf),\n",
    "                        nn.LeakyReLU(0.2, inplace=True))\n",
    "        csize, cndf = isize / 2, ndf\n",
    "\n",
    "        while csize > 4:\n",
    "            in_feat = cndf\n",
    "            out_feat = cndf * 2\n",
    "            main.add_module('pyramid:{0}-{1}:conv'.format(in_feat, out_feat),\n",
    "                            nn.Conv2d(in_feat, out_feat, 4, 2, 1, bias=False))\n",
    "            main.add_module('pyramid:{0}:batchnorm'.format(out_feat),\n",
    "                            nn.BatchNorm2d(out_feat))\n",
    "            main.add_module('pyramid:{0}:relu'.format(out_feat),\n",
    "                            nn.LeakyReLU(0.2, inplace=True))\n",
    "            cndf = cndf * 2\n",
    "            csize = csize / 2\n",
    "\n",
    "        # state size. K x 4 x 4\n",
    "        main.add_module('final:{0}-{1}:conv'.format(cndf, 1),\n",
    "                        nn.Conv2d(cndf, 1, 4, 1, 0, bias=False))\n",
    "        self.main = main\n",
    "\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = self.main(input)    \n",
    "        output = output.mean(0)\n",
    "        return output.view(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DCGAN_G(nn.Module):\n",
    "    def __init__(self, isize, nz, nc, ngf):\n",
    "        super(DCGAN_G, self).__init__()\n",
    "        assert isize % 16 == 0, \"isize has to be a multiple of 16\"\n",
    "\n",
    "        cngf, tisize = ngf//2, 4\n",
    "        while tisize != isize:\n",
    "            cngf = cngf * 2\n",
    "            tisize = tisize * 2\n",
    "\n",
    "        main = nn.Sequential()\n",
    "        # input is Z, going into a convolution\n",
    "        main.add_module('initial:{0}-{1}:convt'.format(nz, cngf),\n",
    "                        nn.ConvTranspose2d(nz, cngf, 4, 1, 0, bias=False))\n",
    "        main.add_module('initial:{0}:batchnorm'.format(cngf),\n",
    "                        nn.BatchNorm2d(cngf))\n",
    "        main.add_module('initial:{0}:relu'.format(cngf),\n",
    "                        nn.ReLU(True))\n",
    "\n",
    "        csize, cndf = 4, cngf\n",
    "        while csize < isize//2:\n",
    "            main.add_module('pyramid:{0}-{1}:convt'.format(cngf, cngf//2),\n",
    "                            nn.ConvTranspose2d(cngf, cngf//2, 4, 2, 1, bias=False))\n",
    "            main.add_module('pyramid:{0}:batchnorm'.format(cngf//2),\n",
    "                            nn.BatchNorm2d(cngf//2))\n",
    "            main.add_module('pyramid:{0}:relu'.format(cngf//2),\n",
    "                            nn.ReLU(True))\n",
    "            cngf = cngf // 2\n",
    "            csize = csize * 2\n",
    "\n",
    "        main.add_module('final:{0}-{1}:convt'.format(cngf, nc),\n",
    "                        nn.ConvTranspose2d(cngf, nc, 4, 2, 1, bias=False))\n",
    "        main.add_module('final:{0}:tanh'.format(nc),\n",
    "                        nn.Tanh())\n",
    "        self.main = main\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = self.main(input)\n",
    "        return output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DCGAN_G(\n",
       "  (main): Sequential(\n",
       "    (initial:100-256:convt): ConvTranspose2d(100, 256, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
       "    (initial:256:batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (initial:256:relu): ReLU(inplace=True)\n",
       "    (pyramid:256-128:convt): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (pyramid:128:batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (pyramid:128:relu): ReLU(inplace=True)\n",
       "    (pyramid:128-64:convt): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (pyramid:64:batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (pyramid:64:relu): ReLU(inplace=True)\n",
       "    (final:64-3:convt): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (final:3:tanh): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "netG = DCGAN_G(image_size, nz, nc, ngf)\n",
    "netG.apply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DCGAN_D(\n",
       "  (main): Sequential(\n",
       "    (initial:3-64:conv): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (initial:64:relu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (pyramid:64-128:conv): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (pyramid:128:batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (pyramid:128:relu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (pyramid:128-256:conv): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (pyramid:256:batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (pyramid:256:relu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (final:256-1:conv): Conv2d(256, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "netD = DCGAN_D(image_size, nz, nc, ndf)\n",
    "netD.apply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.FloatTensor(batch_size, 3, image_size, image_size)\n",
    "noise = torch.FloatTensor(batch_size, nz, 1, 1)\n",
    "fixed_noise = torch.FloatTensor(batch_size, nz, 1, 1).normal_(0, 1)\n",
    "one = torch.FloatTensor([1])\n",
    "mone = one * -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    cuda_opt = True\n",
    "    netD.cuda()\n",
    "    netG.cuda()\n",
    "    input = input.cuda()\n",
    "    one, mone = one.cuda(), mone.cuda()\n",
    "    noise, fixed_noise = noise.cuda(), fixed_noise.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizerD = optim.RMSprop(netD.parameters(), lr=lrD)\n",
    "optimizerG = optim.RMSprop(netG.parameters(), lr=lrG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] Loss_D: -0.732012 Loss_G: 0.397354 Loss_D_real: -0.385385 Loss_D_fake 0.346628\n",
      "[100] Loss_D: -0.119897 Loss_G: 0.200913 Loss_D_real: -0.239352 Loss_D_fake -0.119455\n",
      "[200] Loss_D: -0.074271 Loss_G: 0.072006 Loss_D_real: -0.213446 Loss_D_fake -0.139175\n",
      "[300] Loss_D: -0.079528 Loss_G: 0.136222 Loss_D_real: -0.220373 Loss_D_fake -0.140846\n",
      "[400] Loss_D: -0.061325 Loss_G: 0.019688 Loss_D_real: -0.015201 Loss_D_fake 0.046124\n",
      "[500] Loss_D: -0.019084 Loss_G: 0.060692 Loss_D_real: -0.103467 Loss_D_fake -0.084383\n",
      "[600] Loss_D: -0.090209 Loss_G: 0.025649 Loss_D_real: 0.058163 Loss_D_fake 0.148372\n",
      "[700] Loss_D: -0.057698 Loss_G: -0.048196 Loss_D_real: -0.050278 Loss_D_fake 0.007420\n",
      "[800] Loss_D: -0.057519 Loss_G: -0.033722 Loss_D_real: -0.058452 Loss_D_fake -0.000933\n",
      "[900] Loss_D: -0.069872 Loss_G: 0.064152 Loss_D_real: -0.013175 Loss_D_fake 0.056697\n",
      "[1000] Loss_D: -0.045432 Loss_G: -0.051551 Loss_D_real: -0.108851 Loss_D_fake -0.063419\n",
      "[1100] Loss_D: -0.034450 Loss_G: 0.011960 Loss_D_real: 0.000330 Loss_D_fake 0.034781\n",
      "[1200] Loss_D: -0.060848 Loss_G: -0.033806 Loss_D_real: -0.044485 Loss_D_fake 0.016362\n",
      "[1300] Loss_D: 0.002005 Loss_G: -0.009502 Loss_D_real: -0.005285 Loss_D_fake -0.007291\n",
      "[1400] Loss_D: 0.004465 Loss_G: -0.000210 Loss_D_real: 0.008825 Loss_D_fake 0.004360\n",
      "[1500] Loss_D: 0.005965 Loss_G: -0.009768 Loss_D_real: -0.014118 Loss_D_fake -0.020083\n",
      "[1600] Loss_D: 0.005933 Loss_G: 0.018188 Loss_D_real: 0.021829 Loss_D_fake 0.015896\n",
      "[1700] Loss_D: -0.035285 Loss_G: 0.087676 Loss_D_real: -0.050130 Loss_D_fake -0.014845\n",
      "[1800] Loss_D: -0.034483 Loss_G: 0.080834 Loss_D_real: -0.070216 Loss_D_fake -0.035733\n",
      "[1900] Loss_D: -0.050449 Loss_G: 0.010471 Loss_D_real: -0.026349 Loss_D_fake 0.024099\n",
      "[2000] Loss_D: -0.001076 Loss_G: -0.027962 Loss_D_real: -0.044432 Loss_D_fake -0.043356\n",
      "[2100] Loss_D: -0.025115 Loss_G: 0.018430 Loss_D_real: -0.068484 Loss_D_fake -0.043368\n",
      "[2200] Loss_D: -0.000405 Loss_G: -0.010387 Loss_D_real: -0.011226 Loss_D_fake -0.010821\n",
      "[2300] Loss_D: -0.000629 Loss_G: -0.000854 Loss_D_real: -0.000990 Loss_D_fake -0.000361\n",
      "[2400] Loss_D: 0.001796 Loss_G: -0.013461 Loss_D_real: -0.005977 Loss_D_fake -0.007774\n",
      "[2500] Loss_D: 0.000034 Loss_G: 0.016442 Loss_D_real: 0.009052 Loss_D_fake 0.009018\n",
      "[2600] Loss_D: -0.000132 Loss_G: 0.002922 Loss_D_real: -0.000014 Loss_D_fake 0.000118\n",
      "[2700] Loss_D: 0.000380 Loss_G: 0.009940 Loss_D_real: 0.012052 Loss_D_fake 0.011672\n",
      "[2800] Loss_D: -0.010156 Loss_G: 0.022660 Loss_D_real: -0.000247 Loss_D_fake 0.009909\n",
      "[2900] Loss_D: -0.003390 Loss_G: 0.002060 Loss_D_real: -0.008383 Loss_D_fake -0.004993\n",
      "[3000] Loss_D: -0.000196 Loss_G: -0.001841 Loss_D_real: -0.002465 Loss_D_fake -0.002269\n",
      "[3100] Loss_D: -0.000225 Loss_G: -0.000642 Loss_D_real: -0.001048 Loss_D_fake -0.000823\n",
      "[3200] Loss_D: -0.021390 Loss_G: 0.118457 Loss_D_real: 0.105709 Loss_D_fake 0.127099\n",
      "[3300] Loss_D: -0.085706 Loss_G: 0.007826 Loss_D_real: -0.120194 Loss_D_fake -0.034488\n",
      "[3400] Loss_D: -0.037948 Loss_G: 0.090151 Loss_D_real: 0.028838 Loss_D_fake 0.066786\n",
      "[3500] Loss_D: -0.114760 Loss_G: 0.124949 Loss_D_real: -0.108970 Loss_D_fake 0.005789\n",
      "[3600] Loss_D: -0.060610 Loss_G: 0.108404 Loss_D_real: -0.036929 Loss_D_fake 0.023680\n",
      "[3700] Loss_D: -0.026239 Loss_G: 0.008777 Loss_D_real: -0.024681 Loss_D_fake 0.001557\n",
      "[3800] Loss_D: -0.063084 Loss_G: 0.105958 Loss_D_real: -0.057384 Loss_D_fake 0.005701\n",
      "[3900] Loss_D: -0.077152 Loss_G: 0.012312 Loss_D_real: -0.065588 Loss_D_fake 0.011564\n",
      "[4000] Loss_D: -0.107198 Loss_G: 0.060382 Loss_D_real: -0.056198 Loss_D_fake 0.051000\n",
      "[4100] Loss_D: -0.089668 Loss_G: 0.039249 Loss_D_real: -0.062311 Loss_D_fake 0.027358\n",
      "[4200] Loss_D: -0.055872 Loss_G: -0.010564 Loss_D_real: -0.006396 Loss_D_fake 0.049476\n",
      "[4300] Loss_D: -0.036955 Loss_G: 0.039262 Loss_D_real: -0.005793 Loss_D_fake 0.031162\n",
      "[4400] Loss_D: -0.050428 Loss_G: -0.016589 Loss_D_real: 0.036819 Loss_D_fake 0.087247\n",
      "[4500] Loss_D: -0.023449 Loss_G: 0.039816 Loss_D_real: -0.033424 Loss_D_fake -0.009975\n",
      "[4600] Loss_D: -0.036723 Loss_G: 0.057235 Loss_D_real: 0.031421 Loss_D_fake 0.068144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fd113a73b90>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cesar/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/cesar/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 939, in _shutdown_workers\n",
      "    self._shutdown_worker(worker_id)\n",
      "  File \"/home/cesar/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 895, in _shutdown_worker\n",
      "    q.put(None)\n",
      "  File \"/home/cesar/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 89, in put\n",
      "    self._notempty.notify()\n",
      "  File \"/home/cesar/anaconda3/lib/python3.7/threading.py\", line 351, in notify\n",
      "    for waiter in waiters_to_notify:\n",
      "  File \"/home/cesar/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/signal_handling.py\", line 66, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "RuntimeError: DataLoader worker (pid 30810) is killed by signal: Killed. \n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 30810) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    760\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    762\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    104\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mEmpty\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-9908d5798287>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclamp_lower\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclamp_upper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_iter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m             \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    839\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    806\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 808\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    809\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    772\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfailed_workers\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m                 \u001b[0mpids_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m', '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfailed_workers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 774\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DataLoader worker (pid(s) {}) exited unexpectedly'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpids_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    775\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmpty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid(s) 30810) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "gen_iterations = 0\n",
    "lossD_dict = []\n",
    "lossG_dict = []\n",
    "\n",
    "for epoch in range(niter):\n",
    "    \n",
    "    data_iter = iter(dataloader)\n",
    "    i = 0\n",
    "    errD_cum = 0\n",
    "    errG_cum = 0\n",
    "\n",
    "\n",
    "    while i < len(dataloader):\n",
    "        \n",
    "        ############################\n",
    "        # (1) Update D network\n",
    "        ###########################\n",
    "        \n",
    "        for p in netD.parameters(): # reset requires_grad\n",
    "            p.requires_grad = True # they are set to False below in netG update\n",
    "\n",
    "        # train the discriminator Diters times\n",
    "        if gen_iterations < 25 or gen_iterations % 500 == 0:\n",
    "            cDiters = 100\n",
    "        else:\n",
    "            cDiters = Diters\n",
    "        j = 0\n",
    "        \n",
    "        while j < cDiters and i < len(dataloader):\n",
    "            \n",
    "            j += 1\n",
    "\n",
    "            data = data_iter.next()\n",
    "            i += 1\n",
    "\n",
    "            # train with real\n",
    "            real_cpu, _ = data\n",
    "            netD.zero_grad()\n",
    "            batch_size = real_cpu.size(0)\n",
    "\n",
    "            if cuda_opt:\n",
    "                real_cpu = real_cpu.cuda()\n",
    "            input.resize_as_(real_cpu).copy_(real_cpu)\n",
    "            inputv = torch.autograd.Variable(input)\n",
    "\n",
    "            errD_real = netD(inputv)\n",
    "            errD_real.backward(one)\n",
    "\n",
    "            # train with fake\n",
    "            noise.resize_(batch_size, nz, 1, 1).normal_(0, 1)\n",
    "            noisev = torch.autograd.Variable(noise, volatile = True) # totally freeze netG\n",
    "            fake = torch.autograd.Variable(netG(noisev).data)\n",
    "            inputv = fake\n",
    "            errD_fake = netD(inputv)\n",
    "            errD_fake.backward(mone)\n",
    "            errD = errD_real - errD_fake\n",
    "            optimizerD.step()\n",
    "            \n",
    "            # clamp parameters to a cube\n",
    "            for p in netD.parameters():\n",
    "                p.data.clamp_(clamp_lower, clamp_upper)\n",
    "\n",
    "        ############################\n",
    "        # (2) Update G network\n",
    "        ###########################\n",
    "        for p in netD.parameters():\n",
    "            p.requires_grad = False # to avoid computation\n",
    "        netG.zero_grad()\n",
    "        # in case our last batch was the tail batch of the dataloader,\n",
    "        # make sure we feed a full batch of noise\n",
    "        noise.resize_(batch_size, nz, 1, 1).normal_(0, 1)\n",
    "        noisev = torch.autograd.Variable(noise)\n",
    "        fake = netG(noisev)\n",
    "        errG = netD(fake)\n",
    "        errG.backward(one)\n",
    "        optimizerG.step()\n",
    "        gen_iterations += 1\n",
    "            \n",
    "        errD_cum += errD\n",
    "        errG_cum += errG\n",
    "        \n",
    "    lossD_dict.append(errD_cum)\n",
    "    lossG_dict.append(errG_cum)\n",
    "    \n",
    "    if epoch % 1000 == 0:\n",
    "        real_cpu = real_cpu.mul(0.5).add(0.5)\n",
    "        vutils.save_image(real_cpu, '{0}/real_samples.png'.format(RESULTS_PATH))\n",
    "        fake = netG(torch.autograd.Variable(fixed_noise, volatile=True))\n",
    "        fake.data = fake.data.mul(0.5).add(0.5)\n",
    "        vutils.save_image(fake.data, '{0}/fake_samples_{1}.png'.format(RESULTS_PATH,\n",
    "                                                                       gen_iterations))\n",
    "        \n",
    "    if epoch % 100 == 0:\n",
    "        print('[%d] Loss_D: %f Loss_G: %f Loss_D_real: %f Loss_D_fake %f'\n",
    "            % (epoch, errD.data[0], errG.data[0], errD_real.data[0], errD_fake.data[0]))\n",
    "\n",
    "    if epoch % 1000 == 0:\n",
    "        torch.save(netG.state_dict(), '{0}/netG_epoch_{1}.pth'.format(RESULTS_PATH, epoch))\n",
    "        torch.save(netD.state_dict(), '{0}/netD_epoch_{1}.pth'.format(RESULTS_PATH, epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-2fc6766b5253>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mimg_gen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mimg_gen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mimg_gen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "rand = torch.empty(1, nz, 1, 1).normal_(mean=0, std=1).cuda()\n",
    "print(rand.size())\n",
    "img_gen = netG(rand).view(3, 32, 32).detach().cpu().numpy()\n",
    "img_gen = np.transpose(img_gen, (1, 2, 0))\n",
    "img_gen = np.clip(img_gen, 0, 1)\n",
    "plt.imshow(img_gen)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
